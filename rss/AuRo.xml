<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>自主机器人</title>
    <link>https://www.springer.com/journal/10514</link>
    <description>自主机器人 - RSSHub 用爱制作(https://github.com/DIYgod/RSSHub)</description>
    <lastBuildDate>Sat, 30 Dec 2023 15:07:16 GMT</lastBuildDate>
    <item>
      <title>BRAVER 的设计和控制：通过本体感受电机驱动的双足机器人</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10117-5</link>
      <description><![CDATA[BRAVER 的设计和控制：通过本体感受电动机驱动的双足机器人朱正国;朱伟良;马树根https://doi.org/10.1007/s10514-023-10117-5第 47 卷，第 8 期，2023 年 12 月本文介绍了高速运行的双足机器人 BRAVER 的设计和控制。该机器人重 8.6 千克，高 0.36 米，具有六个主动度，所有主动度均由定制的可反向驱动模块化执行器驱动，可实现高带宽力控制和本体感觉扭矩反馈。我们介绍了硬件设计的细节，包括执行器、腿、脚和板载控制系统，以及用于高动态任务和提高鲁棒性的运动控制器设计。我们通过一系列实验展示了 BRAVER 的性能，包括多地形行走、上下 15\(^{\circ }\) 坡度、推动恢复和跑步。 BRAVER的最高运行速度达到1.75米/秒。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10117-5</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:16 GMT</pubDate>
    </item>
    <item>
      <title>协同优化软体机器人爬行器的模拟到真实迁移</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10130-8</link>
      <description><![CDATA[协同优化软体机器人爬行器的模拟到真实迁移查尔斯·沙夫；奥黛丽·塞达尔；马修·沃尔特https://doi.org/10.1007/s10514-023-10130-8 第 47 卷，第 8 期，2023 年 12 月这项工作为软腿机器人的设计和控制的仿真、协同优化和模拟到真实的转换提供了一个完整的框架。软机器人具有“机械智能”：能够被动地表现出难以编程的行为。利用这种能力需要考虑设计和控制之间的耦合。协同优化提供了一种对这种耦合进行推理的方法。然而，要实现既足够准确以允许模拟到真实的转换又足够快以支持当代协同优化算法的模拟是很困难的。我们描述了一种模块化模型降阶算法，该算法可以提高仿真效率，同时保留学习有效的软机器人设计和控制所需的精度。我们提出了一种基于强化学习的协同优化框架，该框架识别了几种软爬行机器人，这些机器人在零样本模拟到真实迁移方面优于专家基线。我们研究该框架对新领域的泛化，以及域随机化作为改进模拟到真实转换的手段的有效性。
]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10130-8</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:15 GMT</pubDate>
    </item>
    <item>
      <title>用于四旋翼飞行器控制的基于事件的神经学习</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10115-7</link>
      <description><![CDATA[用于四旋翼飞行器控制的基于事件的神经学习Estéban Carvalho；皮埃尔·苏比埃勒；吉尔斯·S·迪邦戈耶https://doi.org/10.1007/s10514-023-10115-7 第 47 卷，第 8 期，2023 年 12 月简单且自适应的飞行控制器的设计是空中机器人技术中的真正挑战。简单的飞行控制器通常会产生较差的飞行跟踪性能。此外，自适应算法可能会耗费大量时间和资源，或者基于深度学习的方法可能会导致不稳定问题，例如在存在干扰的情况下。在本文中，我们提出了一种基于事件的神经学习控制策略，该策略结合使用由深度神经网络增强的标准级联飞行控制器，该网络可以学习干扰以提高跟踪性能。该策略依赖于两个事件：一是允许改善跟踪误差，二是确保闭环系统稳定性。在 ROS/Gazebo 模拟环境中对所提出的策略进行验证后，其有效性在存在风扰动的实际实验中得到了证实。
]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10115-7</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:15 GMT</pubDate>
    </item>
    <item>
      <title>资源受限的人类启发机器人视觉的空间变化和主动视觉机制概述</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10107-7</link>
      <description><![CDATA[资源受限的人类启发机器人视觉的空间变化和主动视觉机制概述&lt;小&gt;Rui Pimentel de Figueiredo；亚历山大·贝尔纳迪诺https://doi.org/10.1007/s10514-023-10107-7第 47 卷，第 8 期，2023 年 12 月按顺序为了有效地探索和理解周围环境，人类开发了一套空间变异的视觉机制，使他们能够主动关注周围环境中的不同位置，并补偿大脑中的记忆、神经元传输带宽和计算限制。同样，部署在日常环境中的人形机器人的机载资源有限，并且面临着日益复杂的任务，需要与以多种可能的空间配置排列的物体进行交互。这项工作的主要目标是描述和概述受生物学启发的、空间变异的人类视觉机制的好处，当与不同视觉任务（例如对象检测）的最先进算法相结合时，范围从低级硬连线注意力视觉（即中央凹视力）到高级视觉注意机制。我们概述了生物学上合理的空间变异资源受限视觉架构的最新技术，即用于主动识别和定位任务。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10107-7</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:14 GMT</pubDate>
    </item>
    <item>
      <title>FuseBot：通过多模态感知对刚性和可变形物体进行机械搜索</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10137-1</link>
      <description><![CDATA[FuseBot：通过多模态感知对刚性和可变形物体进行机械搜索塔拉·博鲁沙基；劳拉·多兹；法德尔·阿迪布https://doi.org/10.1007/s10514-023-10137-1第 47 卷，第 8 期，2023 年 12 月机械搜索是一个机器人问题，机器人需要检索被其相机部分或完全遮挡的目标物品。最先进的机械搜索方法要么需要昂贵的搜索过程来找到目标物品，要么需要使用射频识别标签（例如 RFID）来标记该物品，这使得他们的方法仅对标记的物品有利环境中的物品。我们推出了 FuseBot，这是第一个用于 RF-Visual 机械搜索的机器人系统，能够高效检索一堆带有 RF 标签和未标签的物品。 FuseBot 并不要求堆中的所有目标项目都带有 RF 标签，而是利用堆中 RF 标签项目的存在来使已标记和未标记的项目受益。我们的设计引入了两项关键创新。第一个是 RF-Visual 绘图，这是一种识别和定位一堆带有 RF 标签的物品的技术，并使用此信息构建 RF-Visual 占用分布图。第二个是 RF-Visual Extraction，这是一种被制定为优化问题的策略，通过考虑概率占用分布、预期抓取质量以及未来操作的预期信息增益，最大限度地减少提取目标对象所需的操作数量。我们在带有手持视觉和射频感知模块的 UR5e 机械臂上构建了系统的实时端到端原型。我们进行了 200 多项真实世界的实验试验来评估 FuseBot，并将其性能与名为 X-Ray 的最先进的基于视觉的系统进行比较（Danilczuk 等人，发表于：2020 年 IEEE/RSJ 国际智能机器人会议）和系统（IROS），IEEE，2020）。我们的实验结果表明，在成功机械搜索所需的操作数量方面，FuseBot 的效率比 X-Ray 高出 40% 以上。此外，与 X-Ray 84% 的成功率相比，FuseBot 在检索未标记物品方面实现了 95% 的成功率，首次证明 RF 感知的优势不仅仅局限于机械搜索问题中的标记物体。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10137-1</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:14 GMT</pubDate>
    </item>
    <item>
      <title>用于域自适应可遍历性预测的伪三边对抗训练</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10123-7</link>
      <description><![CDATA[领域自适应可遍历性预测的伪三边对抗训练郑晨；杜尔加坎特·普什普；刘兰涛https://doi.org/10.1007/s10514-023-10123-7第 47 卷，第 8 期，2023 年 12 月可遍历性预测是自主导航的基本感知能力。在过去的十年中，深度神经网络（DNN）已被广泛用于预测可遍历性。通过利用大量数据，DNN 的性能得到显着提升。然而，不同领域数据的多样性导致预测性能存在显着差距。在这项工作中，我们通过提出一种新颖的伪三边对抗模型来努力缩小差距，该模型采用从粗到细的对齐（CALI）来执行无监督域适应（UDA）。我们的目标是以高数据效率转移感知模型，消除昂贵的数据标签，并在从易于访问的源域到各种具有挑战性的目标域的适应过程中提高泛化能力。现有的UDA方法通常采用双边零和博弈结构。我们证明了我们的 CALI 模型——伪三边博弈结构优于现有的双边博弈结构。这项工作将理论分析和算法设计联系起来，从而形成一种高效的 UDA 模型，并且训练简单且稳定。我们进一步开发了 CALI 的变体——Informed CALI，它受到最近成功的混合数据增强技术的启发，并根据 CALI 的结果混合信息区域。这种混合步骤在两个领域之间提供了明确的桥梁，并在训练期间更多地暴露了表现不佳的类。我们在几个具有挑战性的领域适应设置中展示了我们提出的模型相对于多个基线的优越性。为了进一步验证我们提出的模型的有效性，我们将感知模型与视觉规划器结合起来构建导航系统，并展示我们的模型在复杂自然环境中的高可靠性。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10123-7</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:14 GMT</pubDate>
    </item>
    <item>
      <title>使用等变模型进行机器人抓取学习</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10112-w</link>
      <description><![CDATA[利用等变模型进行机器人抓取学习朱旭鹏;王殿;罗伯特·普拉特https://doi.org/10.1007/s10514-023-10112-w第 47 卷，第 8 期，2023 年 12 月真实-由于抓取动力学的随机性和硬件中的噪声，世界抓取检测具有挑战性。理想情况下，系统将通过直接在物理系统上进行训练来适应现实世界。然而，由于大多数掌握学习模型需要大量的训练数据，这通常很困难。在本文中，我们注意到平面抓取函数是 \(\textrm{SE}(2)\) 等变的，并证明该结构可用于约束学习过程中使用的神经网络。这会产生一种归纳偏差，可以显着提高抓取学习的样本效率，并能够在物理机器人上从头开始进行端到端训练，仅需 600 次抓取尝试。我们将这种方法称为对称抓取学习 (SymGrasp)，并表明它可以在不到 1.5 小时的物理机器人时间内“从头开始”学习抓取。本文是 Zhu 等人的会议论文的扩展和修订版本。 （2022）。
]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10112-w</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:14 GMT</pubDate>
    </item>
    <item>
      <title>化学机器人的大型语言模型</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10136-2</link>
      <description><![CDATA[化学机器人的大型语言模型Naruki Yoshikawa；玛尔塔·斯克雷塔； Animesh Garghttps://doi.org/10.1007/s10514-023-10136-2第 47 卷，第 8 期，2023 年 12 月本文提出了一种使用机器人自动化化学实验的方法，通过将自然语言指令翻译成机器人可执行计划，使用大型语言模型以及任务和运动规划。在自主化学实验系统中添加自然语言界面可以降低使用复杂机器人系统的障碍，并提高非专家用户的实用性，但将用户的自然语言实验描述翻译成低级机器人语言却并非易事。此外，虽然最近的进展已经使用大型语言模型来生成任务计划，但由具体代理在现实世界中可靠地执行这些计划仍然具有挑战性。为了实现自主化学实验并减轻化学家的工作量，机器人必须解释自然语言命令，感知工作空间，自主规划多步骤动作和动作，考虑安全预防措施，并与各种实验室设备交互。我们的方法 CLAIRify 将自动迭代提示与程序验证相结合，以确保采用包含环境约束的数据稀缺领域特定语言的语法有效的程序。生成的计划是通过使用 PDDLStream 求解器解决约束任务和运动规划问题来执行的，以防止化学实验室中的液体溢出和碰撞。我们展示了我们的方法在规划化学实验方面的有效性，并使用一系列机器人技能和实验室工具在真实的机器人上成功执行了计划。具体来说，我们展示了我们的框架在各种材料的浇注技能中的实用性以及材料合成的两个基本化学实验：溶解度和重结晶。有关 CLAIRify 的更多详细信息，请访问 https://ac-rad.github.io/clairify/。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10136-2</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:13 GMT</pubDate>
    </item>
    <item>
      <title>TidyBot：具有大型语言模型的个性化机器人协助</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10139-z</link>
      <description><![CDATA[TidyBot：具有大型语言模型的个性化机器人辅助Jimmy Wu;里卡·安东诺娃；托马斯·芬克豪瑟https://doi.org/10.1007/s10514-023-10139-z第 47 卷，第 8 期，2023 年 12 月对于机器人要有效地个性化物理援助，它必须学习用户的偏好，这些偏好可以普遍地重新应用于未来的场景。在这项工作中，我们研究了使用机器人进行家庭清洁的个性化，这些机器人可以通过捡起物体并将其收起来来整理房间。一个关键的挑战是确定放置每个物品的适当位置，因为人们的喜好可能会根据个人品味或文化背景而有很大差异。例如，一个人可能更喜欢将衬衫存放在抽屉里，而另一个人可能更喜欢将它们放在架子上。我们的目标是构建一个系统，可以通过之前与特定人的交互，从少数示例中学习此类偏好。我们证明，机器人可以将基于语言的规划和感知与大型语言模型的几次总结能力相结合，以推断广泛适用于未来交互的广义用户偏好。这种方法可以实现快速适应，并且对我们的基准数据集中未见过的物体实现 91.2% 的准确率。我们还在名为 TidyBot 的真实移动操纵器上演示了我们的方法，该机器人在真实测试场景中成功放置了 85.0% 的物体。]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10139-z</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:13 GMT</pubDate>
    </item>
    <item>
      <title>学习总结和回答有关虚拟机器人过去行为的问题</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10134-4</link>
      <description><![CDATA[学习总结和回答有关虚拟机器人过去行为的问题Chad德尚特；伊雷蒂亚约·阿基​​诺拉；丹尼尔·鲍尔https://doi.org/10.1007/s10514-023-10134-4第 47 卷，第 8 期，2023 年 12 月当机器人执行长动作序列时，用户会希望轻松可靠地找出他们做了什么。因此，我们演示了学习仅使用自然语言总结和回答有关机器人代理过去行为的问题的任务。一个以大型语言模型为核心的单一系统经过训练，可以在给定虚拟机器人的以自我为中心的视频帧和问题提示的情况下总结和回答有关动作序列的问题。为了进行问答训练，我们开发了一种方法来自动生成有关对象、动作以及虚拟环境中机器人动作期间动作发生的时间顺序的英语问题和答案。训练一个模型来总结和回答问题可以实现通过问答学习的对象表示的零样本迁移，从而改进动作总结。
]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10134-4</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:13 GMT</pubDate>
    </item>
    <item>
      <title>ProgPrompt：使用大型语言模型生成定位机器人任务规划的程序</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10135-3</link>
      <description><![CDATA[ProgPrompt：使用大语言模型生成定位机器人任务规划的程序伊希卡·辛格；瓦尔茨·布鲁基斯； Animesh Garghttps://doi.org/10.1007/s10514-023-10135-3第 47 卷，第 8 期，2023 年 12 月任务规划可能需要定义有关机器人需要行动的世界的无数领域知识。为了改善这一工作，可以使用大型语言模型 (LLM) 在任务规划期间对潜在的下一步动作进行评分，甚至在没有额外领域信息的自然语言指令的情况下直接生成动作序列。然而，此类方法要么需要枚举所有可能的后续步骤进行评分，要么生成自由格式的文本，其中可能包含给定机器人在当前上下文中不可能执行的操作。我们提出了一种程序化的 LLM 提示结构，可以跨情境环境、机器人功能和任务生成计划。我们的主要见解是通过环境中可用操作和对象的类似程序的规范以及可以执行的示例程序来提示法学硕士。我们通过消融实验对提示结构和生成约束提出了具体建议，展示了 VirtualHome 家庭任务中最先进的成功率，并将我们的方法部署在用于桌面任务的物理机器人手臂上。网站和代码位于 progprompt.github.io]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10135-3</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:12 GMT</pubDate>
    </item>
    <item>
      <title>通过注意力学习模块化语言条件机器人策略</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10129-1</link>
      <description><![CDATA[通过注意力学习模块化语言条件机器人策略周一帆；舒巴姆·索纳瓦尼；西蒙·斯特普蒂斯https://doi.org/10.1007/s10514-023-10129-1第 47 卷，第 8 期，2023 年 12 月训练语言有条件的政策通常是耗时且资源密集型的。此外，最终的控制器是针对它们所训练的特定机器人量身定制的，因此很难将它们转移到具有不同动力学的其他机器人上。为了应对这些挑战，我们提出了一种称为分层模块化的新方法，它可以实现更有效的培训以及随后在不同类型的机器人之间转移此类策略。该方法结合了监督注意力，通过实现功能构建块的重用，弥合了模块化学习和端到端学习之间的差距。在本次贡献中，我们以之前的工作为基础，通过扩展层次结构以包含新任务并引入用于合成大量新颖对象的自动化管道，展示了扩展的实用程序和改进的性能。我们通过广泛的模拟和现实世界的机器人操纵实验证明了这种方法的有效性。
]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10129-1</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:12 GMT</pubDate>
    </item>
    <item>
      <title>使用大型语言模型进行语义异常检测</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10132-6</link>
      <description><![CDATA[使用大型语言模型进行语义异常检测Amine Elhafsi;罗汉·辛哈；马可·帕沃内https://doi.org/10.1007/s10514-023-10132-6第 47 卷，第 8 期，2023 年 12 月作为机器人获得越来越复杂的技能并看到越来越复杂和多样化的环境，边缘情况或异常故障的威胁始终存在。例如，特斯拉汽车就出现了一些有趣的故障模式，从卡车携带的交通灯不活动导致的自动驾驶仪脱离，到路边广告牌上停车标志图像导致的幻影制动。这些系统级故障并不是由于自治堆栈的任何单个组件的故障造成的，而是由于语义推理方面的系统级缺陷造成的。这种边缘情况，我们称之为语义异常，对于人类来说很容易解开，但需要有洞察力的推理。为此，我们研究了具有广泛上下文理解和推理能力的大型语言模型（LLM）的应用，以识别此类边缘情况，并引入用于基于视觉的政策中的语义异常检测的监控框架。我们的实验将该框架应用于自动驾驶的有限状态机策略和对象操作的学习策略。这些实验表明，基于法学硕士的监视器可以以与人类推理一致的方式有效地识别语义异常。最后，我们对这种方法的优点和缺点进行了深入的讨论，并激发了我们如何进一步使用基础模型进行语义异常检测的研究前景。我们的项目网页可以在 https://sites.google.com/view/llm-anomaly-detection 找到。
]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10132-6</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:12 GMT</pubDate>
    </item>
    <item>
      <title>AuRo 机器人大语言模型特刊客座社论</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10153-1</link>
      <description><![CDATA[AuRo 关于机器人大语言模型客座社论的特刊https://doi.org/10.1007/s10514-023-10153-1第 47 卷，第 8 期，2023 年 12 月]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10153-1</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:11 GMT</pubDate>
    </item>
    <item>
      <title>整合行动知识和法学硕士，在开放世界中进行任务规划和情况处理</title>
      <link>https://link.springer.com/article/10.1007/s10514-023-10133-5</link>
      <description><![CDATA[将行动知识与法学硕士相结合，用于开放世界中的任务规划和情况处理严丁;张晓涵;张世奇https://doi.org/10.1007/s10514-023-10133-5第 47 卷，第 8 期，2023 年 12 月任务规划已经开发出一些系统来帮助机器人利用人类知识（关于动作）来完成长期任务。其中大多数是为“封闭世界”开发的，同时假设机器人拥有完整的世界知识。然而，现实世界通常是开放的，机器人经常遇到不可预见的情况，这可能会破坏规划器的完整性。我们能否利用预训练大型语言模型 (LLM) 的最新进展，使经典规划系统能够处理新情况？本文介绍了一种称为 COWP 的新颖框架，用于开放世界的任务规划和情况处理。 COWP 通过面向任务的常识知识动态增强机器人的动作知识，包括动作的前提条件和效果。 COWP 拥抱法学硕士的开放性，并通过行动知识扎根于特定领域。为了进行系统评估，我们收集了一个包含 1085 个执行时情况的数据集。每种情况对应于一个状态实例，其中机器人可能无法使用正常工作的解决方案完成任务。实验结果表明，我们的方法在服务任务的成功率方面优于文献中的竞争基线。此外，我们还使用移动机械手演示了 COWP。补充材料可在以下网址获取：https://cowplanning.github.io/]]></description>
      <guid>https://link.springer.com/article/10.1007/s10514-023-10133-5</guid>
      <pubDate>Sat, 30 Dec 2023 15:07:11 GMT</pubDate>
    </item>
    </channel>
</rss>