<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>Sage 期刊：目录</title>
    <link>https://journals.sagepub.com/?ai=2b4&mi=ehikzz&af=R</link>
    <description>国际机器人研究杂志的目录。印刷版之前的文章列表。</description>
    <lastBuildDate>Wed, 21 Feb 2024 09:09:36 GMT</lastBuildDate>
    <item>
      <title>从互联网视频中的人类手部动作中学习灵活性</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241227559?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 为了构建可以在多种环境中运行的通用机器人代理，机器人在现实世界中收集经验通常很有用。然而，由于安全、时间和硬件的限制，无引导的经验收集通常是不可行的。因此，我们建议利用下一个最好的东西作为现实世界的体验：人类用手的视频。为了利用这些视频，我们开发了一种方法，将人类手和手臂的任何第一人称或第三人称视频重新定位到机器人手和手臂轨迹。虽然重定向是一个难题，但我们的主要见解是仅依靠互联网人类手部视频来训练它。我们使用这种方法在两个领域展示结果：首先，我们构建了一个系统，使任何人都可以通过用自己的手演示动作来控制机器人手和手臂。机器人通过单个 RGB 摄像头观察人类操作员并实时模仿他们的动作。这使得机器人能够通过监督安全地收集现实世界的经验。请访问 https://robotic-telekinesis.github.io 查看这些结果。其次，我们将野外人类互联网视频重新定位为任务条件伪机器人轨迹，以用作人工机器人体验。该学习算法利用人类手部动作的动作先验、图像的视觉特征以及动力系统的物理先验来针对特定的机器人任务预训练典型的人类行为。我们表明，与许多其他方法相比，通过利用互联网人类手部经验，我们需要更少的机器人演示。请访问 https://video-dex.github.io 查看这些结果]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241227559?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:36 GMT</pubDate>
    </item>
    <item>
      <title>MARS-LVIG 数据集：用于 LiDAR-视觉-惯性-GNSS 融合的多传感器空中机器人 SLAM 数据集</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241227968?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 近年来，光探测和测距 (LiDAR) 技术的进步使 3D LiDAR 传感器变得更加紧凑、轻便且价格实惠。这一进展激发了人们对将 LiDAR 与惯性测量单元 (IMU) 和相机等传感器集成以进行同步定位和建图 (SLAM) 研究的兴趣。涵盖不同场景、平台和视点的公共数据集对于多传感器融合 SLAM 研究至关重要，但大多数数据集中于具有前视图或 360 度视图的手持或车载设备。具有向下视角的飞行器数据很少，现有的相关数据集通常具有低空特征，并且大多局限于小型校园环境。为了填补这一空白，我们引入了多传感器空中机器人 SLAM 数据集（MARS-LVIG 数据集），提供独特的空中下视 LiDAR-Visual-Inertial-GNSS 数据，其视点高度在 80 m 至 130 m 之间。该数据集不仅为测试和评估现有SLAM算法提供了新的方面，而且带来了新的挑战，可以促进更先进的SLAM算法的研究和开发。 MARS-LVIG 数据集包含 21 个序列，这些序列是在多样化的大区域环境中获取的，包括航空模型机场、岛屿、乡村城镇和山谷。在这些序列中，无人机的速度从 3 m/s 到 12 m/s 不等，扫描面积高达 577,000 m2，单次飞行的最大路径长度为 7.148 km。该数据集封装了由轻量级硬件同步传感器包收集的数据，其中包括固态 3D LiDAR、全局快门 RGB 相机、IMU 和全球导航卫星系统 (GNSS) 的原始消息接收器。对于算法评估，该数据集发布了定位和建图的地面实况，分别由机载实时运动（RTK）和DJI L1（由其支持软件DJI Terra进行后处理）获取。该数据集可从以下网址下载：https://mars.hku.hk/dataset.html。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241227968?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:35 GMT</pubDate>
    </item>
    <item>
      <title>麦克纳姆轮移动机器人滚轮上可变接触力的理论与实验研究</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241228607?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 文献中提出的滚轮、麦克纳姆轮和麦克纳姆轮移动机器人的建模结构均采用单接触力假设。该假设在模拟环境中可能会给出良好的结果；然而，它还不足以反映现实。为了做出改进，本研究提出了麦克纳姆轮模型的一个新方面。该模型考虑了可变的滚子接触力，并研究了它们对麦克纳姆轮移动机器人运动性能的影响。它使用每个滚轮弯曲形状上的所有点，因此也考虑了滑动现象，从而可以在实时操作中获得较小的位置估计误差。引入的建模结构旨在反映模拟和实际应用中的现实。为此研究开发了一个模拟环境。为了进行验证，设计并构建了一个实验装置，包括四麦克纳姆轮移动机器人、其机电硬件和软件基础设施以及地面实况系统。创建基于机器人操作系统（ROS）的控制系统并将其集成到实验系统中。不同类型的参考轨迹（包括直线、方形、Z 形和波浪（S）形）用于测试仿真和实验研究中提出的模型的性能。测试还使用涉及单一接触力假设的模型进行比较。本文详细介绍了提出的可变接触力模型、开发的模拟环境、建立的实验装置、模拟和实验研究、结果以及比较。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241228607?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:35 GMT</pubDate>
    </item>
    <item>
      <title>基于姿势和剪切的触觉伺服</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231225811?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 触觉伺服是一项重要技术，因为它使机器人能够精确地操纵物体，同时实时适应环境的变化。使用高分辨率软触觉传感器进行触觉伺服控制的一种方法是使用卷积神经网络（CNN）作为反馈信号来估计相对于物体表面的接触姿势。在本文中，我们研究了如何将表面姿态估计模型扩展到包括剪切力，并利用这些组合的姿态和剪切模型来开发触觉机器人系统，该系统可以针对各种非抓取操作任务进行编程，例如物体跟踪、表面跟随、单臂物体推动和双臂物体推动。为此，必须克服两个技术挑战。首先，使用包括剪切引起的滑动的触觉数据会导致容易出错的估计，不适合精确控制，因此我们将 CNN 修改为高斯密度神经网络，并使用判别性贝叶斯滤波器来改进预测利用机器人运动学的状态动力学模型。其次，为了在与物体交互时在 3D 空间中实现平滑的机器人运动，我们使用了基于 SE(3) 速度的伺服控制，这需要使用李群理论重新推导贝叶斯滤波器更新方程，因为许多标准假设不成立在非欧几里得流形上定义的状态变量。未来，我们相信基于姿势和剪切的触觉伺服将能够实现许多物体操纵任务以及多指触觉机器人手的完全灵巧利用。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231225811?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:34 GMT</pubDate>
    </item>
    <item>
      <title>惰性增量搜索，通过有界次优保证进行有效重新规划</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241227869?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 我们提出了一种惰性增量搜索算法 Lifelong-GLS (L-GLS) 及其有界次优版本 Bounded L-GLS (B-LGLS)，它将增量搜索算法的搜索效率与评估效率结合起来用于在边缘评估比顶点扩展更昂贵的问题域中快速重新规划的惰性搜索算法。所提出的算法在广义惰性搜索 (GLS) 框架内概括了终身规划 A* (LPA*) 及其有界次优版本截断 LPA* (TLPA*)，以便将昂贵的边缘评估仅限于当前最短子路径修复过程中会传播预期成本的不一致。我们还提出了 L-GLS 和 B-LGLS 算法的动态版本，分别称为广义 D* (GD*) 和有界广义 D* (B-GD*)，用于非平稳查询的高效重新规划，专为移动机器人的导航。我们证明所提出的算法在找到保证不超过用户选择的因素的最佳解决方案成本的解决方案方面是完整且正确的。我们的数值和实验结果支持这样的说法：当底层图表示经常变化时，与常规增量或常规惰性搜索算法相比，所提出的增量和惰性搜索框架的集成可以帮助更快地找到解决方案。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241227869?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:34 GMT</pubDate>
    </item>
    <item>
      <title>一种三自由度可切换阻抗肌电假肢腕</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241231298?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 手腕的灵活性对上肢运动任务的执行有很大贡献。尽管如此，目前的假肢手腕远不如其他人工关节先进。通常，假肢手腕提供有限的自由度（如果有的话），这迫使用户在执行任务期间执行补偿性运动。这种增加增加了重量和复杂性，这是上肢假肢中两个不受欢迎的因素。本文介绍了由单电机驱动的三自由度摩擦锁定假肢手腕的设计。该设计具有解锁时的适应性行为，促进与环境的温和交互，并使用户能够在预抓握阶段调整手部配置。所提出的系统与手假肢相结合进行了测试，并在执行功能性运动期间与商业旋转手腕进行了比较。实验涉及九名身体健全的受试者和一名假肢使用者。参与者还用他们的生物手腕（假肢使用者的完整手腕）作为对照进行了实验。结果显示，可锁定手腕的使用频率比商业解决方案高 20%，且不会影响用户的执行时间。交互测试表明，使用所提出的设计时，补偿运动会减少，从而与控制手腕的性能更加相似。所提议的手腕的平均满意度和可用性得分明显更高，表明其潜在的接受度。最后，该系统在假肢使用者进行的一系列日常生活活动中得到了验证。该研究有助于开发更直观、适应性更强的假肢，从而提高截肢者的生活质量。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241231298?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:33 GMT</pubDate>
    </item>
    <item>
      <title>UTIL：超宽带到达时间差室内定位数据集</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241230640?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 基于超宽带 (UWB) 到达时间差 (TDOA) 的定位已成为一种有前景、低成本且可扩展的室内定位解决方案，特别适合多机器人应用。然而，缺乏公共数据集来研究和基准杂乱的室内环境中的 UWB TDOA 定位技术。我们通过使用 Decawave 的 DWM1000 UWB 模块提供综合数据集来填补这一空白。为了表征各种视距 (LOS) 和非视距 (NLOS) 条件下的 UWB TDOA 测量性能，我们收集了信噪比 (SNR)、功率差值和原始 UWB TDOA鉴定实验期间的测量。我们还在定制的四旋翼飞行器平台上进行了累计约 150 分钟的真实飞行实验，以对移动机器人的 UWB TDOA 定位性能进行基准测试。命令四旋翼飞行器使用四个不同的 UWB 锚星座在无障碍和杂乱的环境中以 0.45 m/s 的平均速度飞行。在飞行过程中收集了原始传感器数据，包括 UWB TDOA、惯性测量单元 (IMU)、光流、飞行时间 (ToF) 激光高度和毫米级精度的地面真实机器人姿态。数据集和开发套件可从 https://utiasdsl.github.io/util-uwb-dataset/ 获取。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241230640?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:33 GMT</pubDate>
    </item>
    <item>
      <title>基于视觉测量的未知目标运动分析方位角方法</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241229172?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 基于视觉的移动目标运动估计通常被表述为仅方位估计问题，其中视觉测量被建模为方位向量。尽管仅方位方法已经研究了数十年，但这种方法的一个根本局限性是它需要观察者进行额外的横向运动以增强目标的可观测性。不幸的是，在许多任务中，额外的横向运动与观察者所需的运动相冲突。众所周知，一旦在图像中检测到目标，就可以获得围绕该目标的边界框。令人惊讶的是，这种常见的视觉测量尤其是其尺寸信息迄今为止尚未得到很好的探索。在本文中，我们提出了一种新的方位角方法，通过将图像边界框建模为方位角测量来估计目标的运动。理论分析和实验结果都表明，该方法可以在不依赖观察者额外横向运动的情况下显着增强可观测性。方位角方法的优点是无需额外成本，因为边界框是对象检测算法的标准输出。该方法只是利用过去尚未充分利用的信息。不需要额外的传感设备或特殊的检测算法。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241229172?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:33 GMT</pubDate>
    </item>
    <item>
      <title>关于社会意识机器人导航的调查：分类和未来的挑战</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241230562?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 随着送货和辅助机器人的增加，具有社交意识的机器人导航越来越受欢迎。自动驾驶汽车对社会意识导航技能的需求进一步推动了这项研究，以便在与人类共享的空间中安全、适当地移动。尽管其中大部分是地面机器人，但无人机也正在进入该领域。在本文中，我们对过去 10 年的社交意识机器人导航工作进行了文献调查。我们提出了四种不同的分类法来浏览文献并从四个不同的角度审视该领域。通过分类学回顾，我们讨论了当前的研究方向和在各个领域的应用扩展范围。此外，我们提出了当前研究机会的清单，并讨论了该领域未来可能出现的挑战。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241230562?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:32 GMT</pubDate>
    </item>
    <item>
      <title>机器人空间感知的基础：分层表示和实时系统</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241229725?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 3D 空间感知是使用传感器数据和先验知识实时构建和维护可操作且持久的环境表示的问题。尽管机器人感知取得了快速进展，但大多数现有方法要么构建纯几何地图（如传统 SLAM 中），要么构建“平面”度量语义地图，这些地图无法扩展到大型环境或大型语义标签词典。本文的第一部分涉及表示：我们表明空间感知的可扩展表示本质上需要是分层的。分层表示可以有效地存储，并产生具有小树宽的分层图，从而可以证明有效的推理。然后我们介绍一个室内环境分层表示的示例，即 3D 场景图，并讨论其结构和属性。本文的第二部分重点介绍在机器人探索环境时增量构建 3D 场景图的算法。我们的算法结合了 3D 几何（例如，将自由空间聚类为位置图）、拓扑（将位置聚类为房间）和几何深度学习（例如，对机器人正在移动的房间类型进行分类）。本文的第三部分重点讨论在长期运行过程中维护和纠正 3D 场景图的算法。我们提出了用于循环闭合检测的分层描述符，并描述了如何通过解决 3D 场景图优化问题来响应循环闭合来校正场景图。我们通过将所提出的感知算法结合到 Hydra 中来结束本文，Hydra 是一种实时空间感知系统，可以根据视觉惯性数据实时构建 3D 场景图。我们展示了 Hydra 在逼真模拟以及由 Clearpath Jackal 机器人和 Unitree A1 机器人收集的真实数据方面的表现。我们在 https://github.com/MIT-SPARK/Hydra 发布了 Hydra 的开源实现。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241229725?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:32 GMT</pubDate>
    </item>
    <item>
      <title>表面边缘探索器 (SEE)：下一个最佳视图规划的直接测量方法</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241230098?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 对现实世界的高质量观​​察对于各种应用至关重要，包括生产小规模场景的 3D 打印复制品和对大型基础设施进行检查。这些 3D 观测结果通常是通过组合来自不同视图的多个传感器测量值来获得的。指导选择合适的视图称为下一个最佳视图 (NBV) 规划问题。大多数 NBV 方法都使用刚性数据结构（例如表面网格或体素网格）来推理测量。这简化了下一个最佳视图的选择，但计算成本可能很高，降低了现实世界的保真度，并将下一个最佳视图的选择与最终的数据处理结合起来。本文介绍了 Surface Edge Explorer (SEE)，这是一种 NBV 方法，可以直接从以前的传感器测量中选择新的观测值，而不需要严格的数据结构。 SEE 使用测量密度来提出下一个最佳视图，从而增加对观察不足的表面的覆盖范围，同时避免潜在的遮挡。模拟实验的统计结果表明，与评估的小尺度和大尺度场景的体积方法相比，SEE 可以以更少的观测时间和行进距离获得相似或更好的表面覆盖。现实世界的实验表明，SEE 使用固定在机械臂上的 3D 传感器自主观察鹿雕像。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241230098?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:31 GMT</pubDate>
    </item>
    <item>
      <title>INSANE 数据集：大量传感器，用于在火星模拟、室外和室外/室内转换场景中进行具有挑战性的无人机飞行</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241227245?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 对于现实世界的应用，自主移动机器人平台必须能够在多种不同的动态环境中安全导航，而准确而强大的定位是关键先决条件。为了支持该领域的进一步研究，我们提出了 INSANE 数据集（增加了用于开发高级和新颖估计器的传感器数量）——用于跨环境定位的多功能微型飞行器 (MAV) 数据集的集合。这些数据集为定位方法提供了具有多个难度阶段的各种场景。这些场景范围从室内运动捕捉设施的受控环境中的轨迹，到车辆执行室外机动并过渡到建筑物中（需要改变传感器模式）的实验，一直到在具有挑战性的火星模拟环境中进行纯室外飞行机动模拟当前和未来的火星直升机需要执行的场景。所提出的工作旨在提供反映现实世界场景和传感器效果的数据。广泛的传感器套件包括各种传感器类别，包括多个惯性测量单元 (IMU) 和摄像头。传感器数据以未经处理的测量形式提供，每个数据集都提供高度准确的地面实况，包括户外实验，其中双实时运动 (RTK) 全球导航卫星系统 (GNSS) 设置提供亚度和厘米精度（1-sigma） ）。该传感器套件还包括一个专用的高速 IMU，用于捕获飞行器在飞行过程中的所有振动动态，以支持基于机器学习的新型传感器信号增强方法的研究，以改进定位。数据集和后处理工具可在以下网址获取：https://sst.aau.at/cns/datasets/insane-dataset/]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241227245?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:31 GMT</pubDate>
    </item>
    <item>
      <title>使用李亚普诺夫重新设计的磁针转向控制</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241231600?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 使用可操纵针来实现路线校正和弯曲轨迹可以改善许多临床干预措施的手术结果，包括用于深部脑刺激的电极放置。在这项工作中，主动转向磁尖针的物理激励运动学模型用于闭环控制来执行插入轨迹。应用的控制律是通过李亚普诺夫重新设计导出的。仿真结果表明，这种控制方法在包括随机目标轨迹在内的各种条件下都是准确的。在脑组织模型中通过实验对初始位置偏移恢复和弯曲轨迹进行控制。收敛误差结果与目标轨迹的平均误差为 0.52 毫米。仿真结果证明了控制实施的稳健性，而实验结果超出了目标应用所需的准确性，鼓励未来在临床环境中的使用。除了针插入之外，这项工作对一般车辆转向也有影响，因为这种模型和控制可以应用于具有类似运动学的系统，例如可以从宽松的滑动约束中受益的船只和轮式车辆。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241231600?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:31 GMT</pubDate>
    </item>
    <item>
      <title>具有人工神经肌肉系统的经肱骨假体：Sim2real 引导的设计、建模和控制</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231218719?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 在这项工作中，我们介绍了一种新型的仿人上肢假肢。人工神经肌肉假体 (ANP) 在顺应性、反向驱动性、自然运动、本体感觉和运动觉方面模仿人类神经肌肉系统。为了实现这一具有挑战性的目标，我们引入了一种新颖的受人启发和基于仿真的开发范例来设计与人体相对应的假肢机电一体化。 ANP 提供身体感知、接触感知和类人接触响应，通过浮动底座刚体模型、扰动观察器和关节阻抗控制（从现有的最先进的机器人技术中已知的概念）实现。 ANP 机电一体化的特点是具有四自由度 (dof) 扭矩控制的类人运动学、肌腱驱动的 2 自由度手腕以及重量为 1.7 kg 的空间方向感测（不含手和电池）。本文仅在单个原型中按照最初定义的要求对该设备类型进行严格的数学建模、控制、设计和评估。所提出的系统和抓取能力在实验室条件下由未受损的用户进行了验证。未来的工作将提高下一代设备的技术准备水平，其中将对受损用户进行人体研究。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231218719?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:30 GMT</pubDate>
    </item>
    <item>
      <title>RoBUTCHER：新型机器人肉类工厂单元平台</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241234035?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[国际机器人研究杂志，印刷前。 自动化对于肉类生产的可持续发展至关重要，对人类劳动力的严重依赖是一个日益严峻的挑战。在这项工作中，新型机器人肉类工厂单元（MFC）平台为猪肉加工（尤其是屠宰场）的非常规自动化提供了机会。它没有遵循当今主要选择的基于生产线的方法，而是使用机器人技术和人工智能 (AI) 对整个未冷冻猪肉屠体执行复杂的切割和操纵操作，并了解生物变异和变形。 MFC 的长期目标是以猪胴体为输入，产生七种原始输出：火腿、猪肩肉、马鞍肉、猪肚和整套器官。然而，MFC 平台正在不断开发 - 因此，本文旨在通过一个特定的用例来演示它：肩部去除。该系统根据测试和开发会议（2022 年 6 月至 11 月）的数据进行评估，总共进行了 34 次肩部移除尝试。除了成功率和流程时序模型之外，还提供了有关 MFC 处理变化能力的数据。还讨论了熟练屠夫的定性反馈。作者提出，除了平台的技术开发之外，考虑将非常规系统与传统系统进行比较的新方法也很重要。创新的制造系统所能提供的不仅仅是原始速度和产量；灵活性、稳健性和可扩展性等特征——尤其是经济可扩展性——应该发挥重要作用。未来的立法和标准还必须鼓励创新，而不是阻碍创新的机器人解决方案。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241234035?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Wed, 21 Feb 2024 09:09:30 GMT</pubDate>
    </item>
    </channel>
</rss>