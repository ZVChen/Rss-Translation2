<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>SAGE Publications Ltd STM：国际机器人研究杂志：目录</title>
    <link>https://journals.sagepub.com/loi/ijra?ai=2b4&mi=ehikzz&af=R</link>
    <description>国际机器人研究杂志的目录。最新期和提前印刷期的文章列表。</description>
    <lastBuildDate>Thu, 04 Apr 2024 06:10:09 GMT</lastBuildDate>
    <item>
      <title>从互联网视频中的人类手部动作中学习灵活性</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241227559?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 4 期，第 513-532 页，2024 年 4 月。为了构建可以在多种环境中运行的通用机器人代理，机器人收集现实世界中的经验通常很有用。然而，由于安全、时间和硬件的限制，无引导的经验收集通常是不可行的。因此，我们建议利用下一个最好的东西作为现实世界的体验：人类用手的视频。为了利用这些视频，我们开发了一种方法，将人类手和手臂的任何第一人称或第三人称视频重新定位到机器人手和手臂轨迹。虽然重定向是一个难题，但我们的主要见解是仅依靠互联网人类手部视频来训练它。我们使用这种方法在两个领域展示结果：首先，我们构建了一个系统，使任何人都可以通过用自己的手演示动作来控制机器人手和手臂。机器人通过单个 RGB 摄像头观察人类操作员并实时模仿他们的动作。这使得机器人能够通过监督安全地收集现实世界的经验。请访问 https://robotic-telekinesis.github.io 查看这些结果。其次，我们将野外人类互联网视频重新定位为任务条件伪机器人轨迹，以用作人工机器人体验。该学习算法利用人类手部动作的动作先验、图像的视觉特征以及动力系统的物理先验来针对特定的机器人任务预训练典型的人类行为。我们表明，与许多其他方法相比，通过利用互联网人类手部经验，我们需要更少的机器人演示。请访问 https://video-dex.github.io 查看这些结果]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241227559?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:09 GMT</pubDate>
    </item>
    <item>
      <title>RoboCraft：学习使用图网络在 3D 中查看、模拟和塑造弹塑性物体</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231219020?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 4 期，第 533-549 页，2024 年 4 月。 建模和操纵弹塑性物体是机器人执行复杂的工业和家庭交互任务（例如包饺子）的基本能力、卷寿司、制作陶器）。然而，由于弹塑性物体的高自由度，机器人操纵管道的几乎每个方面都存在重大挑战，例如状态表示、动力学建模和控制信号合成。我们建议通过在基于模型的规划框架中采用基于粒子的弹塑性物体表示来应对这些挑战。我们的系统 RoboCraft 仅假设可以访问原始 RGBD 视觉观察结果。它将感知数据转换为粒子，并使用图神经网络（GNN）学习基于粒子的动力学模型来捕获底层系统的结构。然后可以将学习到的模型与模型预测控制（MPC）算法相结合来规划机器人的行为。我们通过实验证明，只需 10 分钟的现实世界机器人交互数据，我们的机器人就可以学习动力学模型，该模型可用于合成控制信号，将弹塑性物体变形为各种复杂的目标形状，包括机器人具有的形状以前从未遇到过。我们在模拟和现实世界中进行系统评估，以展示机器人的操纵能力。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231219020?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:09 GMT</pubDate>
    </item>
    <item>
      <title>Kernel-GPA：闭式可变形 SLAM 的全局最优解</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231195380?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 4 期，第 456-484 页，2024 年 4 月。我们研究广义 Procrustes 分析 (GPA)，作为同时定位和建图 (SLAM) 问题的最小表述。我们提出了 Kernel-GPA，这是一种新颖的全局配准技术，用于解决可变形环境中的 SLAM。我们提出了可变形变换的概念，它对纠缠姿态和变形进行编码。我们使用核方法定义可变形变换，并表明可变形变换和环境贴图都可以以封闭形式全局求解，直至全局尺度模糊。我们通过最大化刚性的优化公式来解决尺度模糊性。我们使用高斯核演示了 Kernel-GPA，并使用各种数据集验证了 Kernel-GPA 的优越性。代码和数据可在 https://bitbucket.org/FangBai/deformableprocrustes 获取。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231195380?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:08 GMT</pubDate>
    </item>
    <item>
      <title>具有完整任务空中自主性的多机器人、多传感器探索多样化环境</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231203342?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 4 期，第 485-512 页，2024 年 4 月。我们提出了一种用于密闭环境的多传感器探索的协调自主管道。我们同时解决了先前工作中通常被忽视的四大挑战：（a）有效利用距离和视觉传感模式，（b）在广泛的环境中进行这种探索，（c）对不良事件具有弹性， (d) 执行机载物理机器人团队。我们的解决方案以行为树架构为中心，它可以在涉及协调探索和响应不良事件的各种行为之间自适应切换。我们的探索策略利用了视觉和距离传感器的优势，以及基于通用前沿的探索算法和基于 OpenVDB 的地图处理管道。我们的本地规划器利用动态可行的轨迹库和基于 GPU 的欧几里德距离变换图，可以快速安全地导航穿过狭窄的门口和广阔的空间。自主管道通过一系列广泛的现场实验进行了评估，最多三个机器人组成的团队在密闭空间中飞行速度高达 3 m/s，距离超过 1 km。我们总结了各种现场实验，并详细说明了所出现的弹性行为：操纵狭窄的门口、适应意外的环境变化以及紧急着陆。 DARPA 地下挑战赛中还详细介绍了实验，其中我们提出的自主管道为我们赢得了“探索最多的领域”奖。我们对经验教训进行了广泛的讨论，以开源方式发布软件，并提供了一段视频来说明我们广泛的现场试验。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231203342?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:08 GMT</pubDate>
    </item>
    <item>
      <title>迭代残差策略：用于可变形对象的目标条件动态操作</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231201201?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 4 期，第 389-404 页，2024 年 4 月。本文解决了可变形物体的目标条件动态操纵的任务。由于其复杂的动力学（由物体变形和高速动作引入）和严格的任务要求（由精确的目标规范定义），该任务极具挑战性。为了应对这些挑战，我们提出了迭代残差策略（IRP），这是一种适用于具有复杂动态的可重复任务的通用学习框架。 IRP 通过 Delta 动态学习隐式策略，而不是对整个动力系统进行建模并从该模型推断操作，IRP 学习 Delta 动态，预测 Delta 操作对先前观察到的轨迹的影响。当与自适应动作采样相结合时，系统可以快速在线优化其动作以达到指定的目标。我们展示了 IRP 在两项任务上的有效性：鞭打绳子以击中目标点和摆动布料以达到目标姿势。尽管仅在固定机器人设置上进行模拟训练，但 IRP 能够有效地泛化到嘈杂的现实世界动态、具有看不见的物理属性的新对象，甚至不同的机器人硬件实施例，展示了其相对于替代方法的出色泛化能力。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231201201?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:07 GMT</pubDate>
    </item>
    <item>
      <title>通过非平稳高斯过程进行自适应机器人信息收集</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231184498?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 4 期，第 405-436 页，2024 年 4 月。机器人信息收集 (RIG) 是一个基础研究主题，它回答了机器人（团队）如何收集信息数据以高效构建机器人机器人实施例约束下未知目标函数的精确模型。 RIG 有许多应用，包括但不限于自主勘探和测绘、3D 重建或检查、搜索和救援以及环境监测。 RIG 系统依靠概率模型的预测不确定性来识别信息数据收集的关键区域。具有固定核的高斯过程（GP）已被广泛用于空间建模。然而，现实世界的空间数据通常是非平稳的——不同位置不具有相同程度的可变性。因此，预测不确定性不能准确揭示预测误差，限制了 RIG 算法的成功。我们提出了一系列名为 Attentive Kernel (AK) 的非平稳内核，它简单且健壮，可以将任何现有内核扩展为非平稳内核。我们在高程测绘任务中评估了新内核，其中 AK 比常用的固定内核和领先的非固定内核提供了更好的准确性和不确定性量化。改进的不确定性量化引导下游信息规划者在高误差区域周围收集更多有价值的数据，进一步提高预测准确性。现场实验表明，所提出的方法可以指导自主地面车辆（ASV）优先考虑空间变化较大的位置的数据收集，使模型能够表征显着的环境特征。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231184498?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:07 GMT</pubDate>
    </item>
    <item>
      <title>用于可变形对象操作的动作条件隐式视觉动力学</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231191222?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 4 期，第 437-455 页，2024 年 4 月。 在现实世界中操纵体积可变形物体（例如毛绒玩具和披萨面团），由于无限的形状变化而带来了巨大的挑战，非刚性运动和部分可观察性。我们引入了 ACID，一种基于结构化隐式神经表示的体积可变形物体的动作条件视觉动力学模型。 ACID 集成了两种新技术：动作条件动力学的隐式表示和基于测地线的对比学习。为了从部分 RGB-D 观测中表示可变形动力学，我们学习了占用和基于流的前向动力学的隐式表示。为了准确识别大非刚性变形下的状态变化，我们通过一种新颖的基于测地线的对比损失来学习对应嵌入场。为了评估我们的方法，我们开发了一个用于在现实场景中操纵复杂可变形形状的模拟框架，以及一个包含超过 17,000 个动作轨迹（包括六种毛绒玩具和 78 种变体）的基准。与现有方法相比，我们的模型在几何、对应和动力学预测方面实现了最佳性能。 ACID 动力学模型成功应用于目标条件变形操作任务，使任务成功率比最强基线提高了 30%。此外，我们将模拟训练的 ACID 模型直接应用于现实世界的对象，并成功地将它们操纵为目标配置。 https://b0ku1.github.io/acid/]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231191222?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:07 GMT</pubDate>
    </item>
    <item>
      <title>使用端到端学习为社交机器人生成非语言社交行为</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231207974?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 5 期，第 716-728 页，2024 年 4 月。 社交机器人通过握手或拥抱等非语言行为促进改善人机交互。然而，依赖于预编码运动的传统方法是可预测的，并且可能会损害机器人作为交互式代理的感知。为了解决这个问题，我们引入了一种基于 Seq2Seq 的神经网络模型，该模型以端到端的方式从人与人的交互中学习社会行为。为了降低长期行为生成过程中无效姿势序列的风险，我们采用了生成对抗网络（GAN）。该方法在模拟环境中使用人形机器人 Pepper 进行了测试。考虑到评估社会行为生成成功与否的挑战，我们设计了新的指标来量化生成的行为与真实行为之间的差异。我们的分析揭示了不同网络对行为生成性能的影响，并比较了学习多种行为与单一行为的功效。我们预计我们的方法将在各个领域得到应用，包括家庭服务、导游、送货、教育和虚拟机器人，从而增强用户互动和享受。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231207974?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:06 GMT</pubDate>
    </item>
    <item>
      <title>RSS2022 论文精选</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649241236273?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 4 期，第 387-388 页，2024 年 4 月。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649241236273?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:06 GMT</pubDate>
    </item>
    <item>
      <title>用于奖励学习和优化的基于主动偏好的高斯过程回归</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231208729?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 5 期，第 665-684 页，2024 年 4 月。设计奖励函数是人工智能和机器人领域的一项艰巨任务。直接指定机器人需要优化的所有理想行为的复杂任务对于人类来说通常具有挑战性。一种流行的解决方案是使用专家演示来学习奖励函数。然而，这种方法充满了许多挑战。一些方法需要高度结构化的模型，例如，在某些预定义的特征集中呈线性的奖励函数，而其他方法则采用可能需要大量数据的结构化程度较低的奖励函数。而且，人类很难提供高自由度的机器人演示，甚至难以量化给定轨迹的奖励值。为了应对这些挑战，我们提出了一种基于偏好的学习方法，其中人类反馈以轨迹之间比较的形式进行。我们不假设奖励函数具有高度受限的结构。相反，我们采用高斯过程对奖励函数进行建模，并提出一种数学公式，仅使用人类偏好来主动拟合模型。我们的方法使我们能够在基于偏好的学习框架内解决不灵活性和数据效率低下的问题。我们进一步分析我们的算法，与奖励优化的几个基线进行比较，其目标是以数据有效的方式找到最佳机器人轨迹，而不是学习每个可能轨迹的奖励函数。我们在三个不同的模拟实验和用户研究中的结果表明，我们的方法可以有效地学习机器人任务的表达奖励函数，并且在奖励学习和奖励优化方面都优于基线。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231208729?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:05 GMT</pubDate>
    </item>
    <item>
      <title>Quatro++：利用地面分割实现 LiDAR SLAM 中环路闭合的鲁棒全局配准</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231207654?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 5 期，第 685-715 页，2024 年 4 月。全局配准是一项基本任务，用于估计 3D 点云两个视点之间的相对位姿。然而，有两个问题会降低LiDAR SLAM中全局配准的性能：一是稀疏性问题，二是退化问题。稀疏性问题是由机械旋转 LiDAR 传感器中 3D 点云测量的稀疏特性引起的。有时会出现简并问题，因为异常值拒绝方法拒绝了太多的对应关系，留下了少于三个内部值。随着 3D 点云的两个视点之间的姿态差异变得更大，这两个问题变得更加严重。为了解决这些问题，我们提出了一个强大的全局注册框架，称为 Quatro++。扩展我们之前仅关注全局配准本身的工作，我们在 LiDAR SLAM 的闭环方面解决了稳健的全局配准问题。为此，利用地面分割来实现稳健的全局配准。通过实验，我们证明我们提出的方法比最先进的全局配准方法具有更高的成功率，克服了稀疏性和简并性问题。此外，我们表明地面分割显着有助于提高地面车辆的成功率。最后，我们将我们提出的方法应用于 LiDAR SLAM 中的环路闭合模块，并确认环路约束的质量得到了提高，显示出更精确的建图结果。因此，实验证据证实了我们的方法作为闭环初始对齐的适用性。我们的代码可在 https://quatro-plusplus.github.io 获取。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231207654?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:05 GMT</pubDate>
    </item>
    <item>
      <title>群体机器人的最佳虚拟管规划和控制</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231210012?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 5 期，第 602-627 页，2024 年 4 月。本文提出了一种有效解决杂乱环境中群体机器人轨迹规划问题的新方法。最近的研究表明，在杂乱环境中，群体机器人的实时局部轨迹规划具有很高的成功率，但优化每个机器人的轨迹在计算上仍然昂贵，计算复杂度从 [math] 到 [math]，其中 [math] 是参数化轨迹中参数的数量，[math]是精度，[math]是相对于[math]和[math]的迭代次数。此外，蜂群很难作为一个整体移动。为了解决这个问题，我们定义并构建最优虚拟管，其中包括无限条最优轨迹。在一定条件下，最优虚拟管中的任意最优轨迹都可以表示为有限个最优轨迹的凸组合，计算复杂度为[math]。随后，提出了一种分层方法，包括最小化能量的最优虚拟管规划方法和分布式模型预测控制。在模拟和实验中，所提出的方法得到了验证，并通过比较证明了其相对于其他方法的有效性。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231210012?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:04 GMT</pubDate>
    </item>
    <item>
      <title>“流体雅可比行列式”：对流体驱动软机器人中的力-运动关系进行建模</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231210592?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 5 期，第 628-645 页，2024 年 4 月。在本文中，我们介绍了流体雅可比行列式的概念，它描述了机器人之间的动力传输。软机器人系统中的流体和机械领域。它可以理解为传统运动学雅可比行列式的推广，它将关节空间扭矩和速度与机器人的任务空间力和速度联系起来。以类似的方式，流体雅可比行列式将流体压力与任务空间力相关联，并将流体流量与任务空间速度相关联。此外，流体雅可比行列式也可以被视为流体驱动气缸中活塞横截面积的推广，扩展到复杂的几何形状和多个维度。下面，我们提出该框架的理论推导，重点关注重要的特殊情况，并通过四个简短的例子说明流体雅可比行列式的意义和实际适用性。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231210592?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:04 GMT</pubDate>
    </item>
    <item>
      <title>具有莫尔效应光学本体感应和电粘附制动的线性静电执行器</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231210593?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 5 期，第 646-664 页，2024 年 4 月。动机、耗散和本体感受组件存在于一个完整的集合中，以实现多功能和精确的操纵任务。我们提出了这样一个系统，即集成了传感和制动组件的线性静电致动器套件。我们的模块化执行器设计由这些执行器薄膜和介电流体组成，我们从理论上和实验上检查了所提出系统的性能。此外，我们还引入了一种利用执行器表面固有生成的莫尔图案的光学本体感知传感机制，可以在无噪声的情况下高分辨率读取执行器的位置。光学传感器还能够测量致动器施加的力。最后，我们在封装中添加了一个与执行器并行的电粘附制动器，引入了一种利用所有三个组件的模式切换方法，并通过机器人手臂进行了控制演示。我们的驱动系统紧凑且灵活，可以轻松与各种机器人应用集成。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231210593?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:04 GMT</pubDate>
    </item>
    <item>
      <title>MAgro 数据集：农业环境中同步定位和测绘的数据集</title>
      <link>https://journals.sagepub.com/doi/abs/10.1177/02783649231210011?ai=2b4&mi=ehikzz&af=R</link>
      <description><![CDATA[《国际机器人研究杂志》，第 43 卷，第 5 期，第 591-601 页，2024 年 4 月。 得益于计算机视觉和深度学习的最新创新，农业产业正在发生转变。然而，缺乏在自然农业环境中收集的特定数据集可以说是新发现和基准测试的主要瓶颈。目前的工作提供了一个新颖的数据集 Magro 和一个扩展数据收集的框架。我们推出了 Magro 数据集 V1.0 的第一个版本，由九个 ROS 包（以及相应的原始数据）组成，其中包含在苹果和梨作物中收集的数据。收集数据，在不同的日期、不同的光照和天气条件下重复固定的轨迹。为了支持闭环算法的评估，轨迹被设计为具有闭环，从不同的角度重新审视一些地方。我们使用 Clearpath 的 Jackal 机器人，配备指向前方和左侧的立体摄像头、3D LIDAR、三个惯性测量单元 (IMU) 和车轮编码器。此外，我们还提供可用作地面实况的校准 RTK GPS 数据。我们的数据集是公开可用的，并将更新以获取更多数据和可变性。最后，我们在我们的新数据集上测试了两种现有的最先进的视觉和基于点云的定位和映射算法，以验证数据集的可用性。]]></description>
      <guid>https://journals.sagepub.com/doi/abs/10.1177/02783649231210011?ai=2b4&mi=ehikzz&af=R</guid>
      <pubDate>Thu, 04 Apr 2024 06:10:03 GMT</pubDate>
    </item>
    </channel>
</rss>