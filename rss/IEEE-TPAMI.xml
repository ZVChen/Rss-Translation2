<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE关于模式分析和机器智能的交易 - 新的TOC</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>TOC警报出版＃34</description>
    <lastBuildDate>Tue, 08 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>ICCV 2021特别部分编辑介绍</title>
      <link>http://ieeexplore.ieee.org/document/10958762</link>
      <description><![CDATA[无效的]]></description>
      <guid>http://ieeexplore.ieee.org/document/10958762</guid>
      <pubDate>Tue, 08 Apr 2025 13:17:49 GMT</pubDate>
    </item>
    <item>
      <title>UNI-MOE：与专家混合的统一统一的多模式LLM</title>
      <link>http://ieeexplore.ieee.org/document/10887014</link>
      <description><![CDATA[多模式大语言模型（MLLM）的最新进展强调了可扩展模型和数据以提高性能的重要性，但这通常会带来实质性的计算成本。尽管专家（MOE）体系结构的混合已采用有效地扩展大型语言或视觉语言模型，但这些努力通常涉及更少的专家和有限的方式。为了解决这个问题，我们的工作提出了开拓与Moe Architecture的统一MLLM的开创性尝试，该架构名为Uni-Moe，可以处理各种方式。具体而言，它具有特定于模态的编码器，并带有连接器，用于统一的多模式表示。我们还在LLMS内实施了稀疏的MOE体系结构，以通过模态级数据并行性和专家级模型并行性进行有效的培训和推断。为了增强多期专家的协作和概括，我们提出了一种渐进培训策略：1）使用具有不同跨模式数据的各种连接器的交叉模式对准，2）培训特定于模式的专家，具有交叉模式指导数据，以激活专家的偏好，以及3）使用低率适应（混合LORA）的整个Uni-MoE框架上的整个Uni-MoE框架）上的多个指令（Multimod Condustration）上）。我们在一组全面的多模式数据集上评估了指令调整的Uni-MoE。广泛的实验结果表明，Uni-MoE在处理混合多模式数据集中显着降低性能偏见以及改进的多型专家协作和泛化的主要优势。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10887014</guid>
      <pubDate>Thu, 13 Feb 2025 13:17:53 GMT</pubDate>
    </item>
    <item>
      <title>ccdplus：朝着精确的角色到字符蒸馏文本识别</title>
      <link>http://ieeexplore.ieee.org/document/10887029</link>
      <description><![CDATA[现有的场景文本识别方法利用大规模标记的合成数据（LSD）来减少对劳动密集型注释任务的依赖，并提高现实情况下的识别能力。但是，合成域间隙的出现仍然限制了它们的效率和鲁棒性。因此，考虑到包含文本的图像的普遍性，收集未标记的真实数据（URD）的有意义的内在品质非常重要。针对目标，最近的努力集中在通过序列到序列的自学学习进行预训练，然后通过监督学习对LSD进行微调。然而，它们遇到了三个重要问题：粗糙的表示单位，僵化的数据增强和新兴的实际到同步领域漂移。为了克服这些挑战，我们提出了CCDPlus，这是一种精确的角色到字符蒸馏方法，用于场景文本识别，并具有共同监督和自我监督的学习框架。具体而言，CCDPLU是针对文本图像量身定制的，通过转移从LSD Online中学到的知识来描述URD上的细颗粒角色结构。在不需要额外的边界框或像素级注释的情况下，此过程允许CCDPLUS通过多功能数据增强灵活地启用字符到字符蒸馏，从而有效地提取了一般的现实世界角色级特征表示。同时，统一的框架将乌尔德的自学学习与LSD的监督学习相结合，有效地解决了域的不一致并提高了识别绩效。广泛的实验表明，CCDPLU的表现优于先前的先前的先前监督（SOTA），分别对标准数据集的监督，半监督和自我监督方法的平均分别为1.8％，0.6％和1.1％。此外，它在更具挑战性的14M-L数据集方面提高了6.1％。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10887029</guid>
      <pubDate>Thu, 13 Feb 2025 13:17:53 GMT</pubDate>
    </item>
    <item>
      <title>少量全部重建的隐式形状和外观先验</title>
      <link>http://ieeexplore.ieee.org/document/10879346</link>
      <description><![CDATA[采用基于坐标神经表示的学习技术的最新进步在多视图3D重建任务中取得了显着的结果。但是，这些方法通常需要大量的输入视图（通常几个）和计算密集的优化程序才能达到其有效性。在本文中，我们专门解决了这些局限性，这些局限性是针对完整3D头部重建的问题。我们通过将概率的形状和外观合并到基于坐标的表示中来实现这一目标，从而在仅使用少数输入图像（即使是单个图像的低）时，可以更快地收敛并改善概括。在测试过程中，我们在使用可区分渲染器的签名距离函数的拟合过程之前利用这一点。通过将统计先验与可行的可行射线追踪和动态的缓存策略结合在一起，我们实现了一种有效而准确的方法来进行几次完整的3D头部重建。此外，我们扩展了H3DS数据集，该数据集现在包括60个高分辨率3D全头扫描及其相应的姿势图像和掩码，我们将其用于评估目的。通过利用该数据集，我们证明了我们方法在实现最新的几何形状重建方面的显着能力，同时比以前的方法更快地构建了数量级。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10879346</guid>
      <pubDate>Mon, 10 Feb 2025 13:16:47 GMT</pubDate>
    </item>
    <item>
      <title>Bridgenet：通过桥梁功能进行多任务密集预测的全面有效的功能交互</title>
      <link>http://ieeexplore.ieee.org/document/10870147</link>
      <description><![CDATA[多任务密集的预测旨在在统一网络中处理多个像素的预测任务，以同时了解视觉场景的理解。但是，当前方法的交叉任务特征交互仍然遭受不完整的表示级别，功能参与者中的歧视性语义较少以及效率低下的配对任务交互过程。为了解决这些爆炸不足的问题，我们提出了一个新颖的Bridgenet框架，该框架提取了全面和歧视性的中间桥梁特征，并基于它们进行了相互作用。具体而言，首先应用任务模式传播（TPP）模块，以确保为高度语义任务特定的特征参与者准备以进行后续交互，并且桥梁特征提取器（BFE）经过专门设计，以选择性地整合高级和低级表示形式，以生成全面的桥梁功能。然后，开发了任务功能炼油厂（TFR），而不是进行重型配对交叉任务相互作用，以有效地从桥梁功能中获得指导并形成最终任务预测。据我们所知，这是考虑到交叉任务互动中功能参与者的完整性和质量的第一部作品。广泛的实验是在NYUD-V2，CityScapes和Pascal Context基准上进行的，并且出色的性能表明，所提出的体系结构在同时促进不同密集的预测任务方面有效且有力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10870147</guid>
      <pubDate>Mon, 03 Feb 2025 13:16:20 GMT</pubDate>
    </item>
    <item>
      <title>细分的结构和统计纹理知识蒸馏和学习</title>
      <link>http://ieeexplore.ieee.org/document/10858405</link>
      <description><![CDATA[低级纹理特征/知识对于表征局部结构模式和全球统计属性（例如边界，平滑度，规律性和颜色对比度）也至关重要，这可能无法通过高级深层特征来很好地解决。在本文中，我们旨在重新强调深网中的低级纹理信息，以进行语义细分和相关的知识蒸馏任务。为此，我们充分利用了结构和统计纹理知识，并提出了用于语义细分的新型结构和统计纹理知识蒸馏（SSTKD）框架。具体而言，引入了Contourlet分解模块（CDM），以分解具有迭代laplacian金字塔和定向过滤器库的低级特征，以挖掘结构性纹理知识，而纹理强度均衡模块（TIEM）旨在提取和增强统计质地知识，并增强统计质地知识，并具有相应的量化量化祝贺损失（QDL）。此外，我们提出了共发生的TIEM（C-TIEM）和通用分割框架，即Stlnet ++和U-SSNet，以使现有的分割网络更有效地收获结构和统计纹理信息。对三个分割任务的广泛实验结果分别证明了所提出的方法的有效性及其在七个流行的基准数据集上的最先进性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10858405</guid>
      <pubDate>Thu, 30 Jan 2025 13:17:01 GMT</pubDate>
    </item>
    <item>
      <title>Mulfs-CAP：无注册红外可见图像融合的多模式融合访问跨模式对齐感</title>
      <link>http://ieeexplore.ieee.org/document/10856402</link>
      <description><![CDATA[在这项研究中，我们提出了多模式融合监督的交叉模式对准感知（Mulfs-CAP），这是一种新型的框架，用于单级未注册的红外可见图像。传统的两阶段方法取决于明确的注册算法以空间对齐源图像，通常会增加复杂性。相比之下，Mulfs-CAP无缝将隐式注册与融合融合在一起，简化了过程并增强了对实际应用的适用性。 Mulfs-CAP利用共享的浅特征编码器在一个阶段合并未注册的红外可见图像。为了满足特征级别对齐和融合的特定要求，我们通过可学习的模态词典开发了一致的特征学习方法。该词典提供了单峰特征的互补信息，从而保持了单个和融合的多模式特征之间的一致性。结果，Mulfs-CAP有效地降低了模态差异对跨模式特征比对的影响，从而可以同时进行注册和融合。此外，在Mulfs-CAP中，我们推进了一种新型的跨模式比对方法，从而创建了一个相关矩阵，以详细介绍源图像之间的像素关系。该矩阵有助于对齐红外和可见图像的特征，从而进一步完善融合过程。上述设计使Mulfs帽更轻巧，有效且明确的注册。来自不同数据集的实验结果证明了我们提出的方法的有效性及其在最先进的两阶段方法上的优势。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10856402</guid>
      <pubDate>Tue, 28 Jan 2025 13:16:59 GMT</pubDate>
    </item>
    <item>
      <title>对齐，自动编码和促使大型语言模型用于新型疾病报告</title>
      <link>http://ieeexplore.ieee.org/document/10854911</link>
      <description><![CDATA[给定放射学图像，自动放射学报告的生成旨在产生报告疾病的信息文本。它可以使当前的诊断放射学实践受益。现有方法通常依赖于临床医生注释的大型医疗数据集来培训理想的模型。但是，对于新型疾病，通常无法获得足够的培训数据。我们提出了一个基于及时的深度学习框架，即促进，以对齐，自动码并提示（大）语言模型，以准确有效地生成新颖疾病的报告。我们的方法包括三个主要步骤：1）将视觉图像和文本报告对齐，以从疾病中学习跨疾病的通用知识，而标记数据足够的疾病，2）使用新型疾病的未标记数据自动编码LLM，以学习新颖疾病的特定知识和编写新颖疾病的特定知识和写作样式，以及3）促使LLM促使知识和写作风格的新型疾病，以报道新颖的功能，包括新颖的图像。通过上述三个步骤，具有有限的新型疾病标签，我们表明，提示可以迅速学习相应的知识以获得准确的新型疾病报告。关于COVID-19和多样化胸部疾病的实验表明，我们的方法利用1％的训练数据，与以前的方法相比实现了理想的性能。它表明我们的方法使我们能够放松对现有方法共有的标记数据的依赖。在新型疾病的早期阶段，它可能对数据分析产生现实影响。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10854911</guid>
      <pubDate>Mon, 27 Jan 2025 13:17:31 GMT</pubDate>
    </item>
    <item>
      <title>通过感知流形的曲率预测和增强DNN的公平性</title>
      <link>http://ieeexplore.ieee.org/document/10854901</link>
      <description><![CDATA[为了应对长尾分类的挑战，研究人员提出了几种减少模型偏见的方法，其中大多数假定样本很少的类是薄弱的类。但是，最近的研究表明，尾部类别并不总是很难学习，并且在样本平衡数据集上观察到了模型偏差，这表明存在其他影响模型偏差的因素。在这项工作中，我们首先建立了分析模型公平性的几何观点，然后系统地提出了一系列深层神经网络中感知流形的几何测量。随后，我们全面探讨了感知流形的几何特征对分类难度以及学习如何塑造感知流形的几何特征的影响。一个意外的发现是，阶级准确性与感知流形的分离程度之间的相关性逐渐降低，而与曲率的负相关逐渐增加，这意味着曲率失衡会导致模型偏见。我们在多个网络和数据集中彻底验证了这一发现，为未来的研究提供了坚实的实验基础。我们还研究了损耗函数和曲率不平衡之间的收敛一致性，这表明现有优化目标缺乏曲率约束。在这些观察结果的基础上，我们提出了曲率正则化，以促进模型学习曲率平衡和平坦的感知流形。对多个长尾和非长尾数据集的评估表明，我们方法的表现和令人兴奋的通用性，尤其是在基于当前最新技术的基于当前的最新性能改进方面。我们的工作对模型偏差开辟了几何分析观点，并提醒研究人员注意对非长尾甚至样品平衡数据集的模型偏差。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10854901</guid>
      <pubDate>Mon, 27 Jan 2025 13:17:31 GMT</pubDate>
    </item>
    <item>
      <title>sIndiffusion：从单个自然图像中学习扩散模型</title>
      <link>http://ieeexplore.ieee.org/document/10855351</link>
      <description><![CDATA[我们提出了sindiffusion，利用deno的扩散模型从单个自然图像中捕获斑块的内部分布。先前基于GAN的方法在此问题上的默认方法是在渐进式增长量表上训练多个模型，这导致错误的积累并在生成的结果中导致特征性伪像。在本文中，我们发现，渐进式增长量表的多个模型对于从单个图像学习并提出Sindiffusion并不是必不可少的，这是一种基于单个扩散的模型，该模型以单个量表进行了训练，这更适合该任务。此外，我们确定一个贴片级的接受场对于捕获图像贴片统计量的扩散模型至关重要且有效，因此我们重新设计了通过贴片的denoisising网络，以进行sindiffusion。与基于GAN的方法相比，这两种设计结合了这两种设计，可以从单个图像中产生更多的影像图像。 Sindiffusion也可以应用于各种应用程序，即文本引导的图像生成，图像超出了Singan的能力。在广泛的图像上进行了广泛的实验，证明了对斑块分布进行建模的sidifusion的优势。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10855351</guid>
      <pubDate>Mon, 27 Jan 2025 13:17:31 GMT</pubDate>
    </item>
    <item>
      <title>通用时间扭曲不变的词典学习时间序列分类和聚类</title>
      <link>http://ieeexplore.ieee.org/document/10855328</link>
      <description><![CDATA[字典学习是时间序列数据的模式识别和分类的有效工具。但是，现实世界中的时间序列数据通常由于时间延迟，缩放或其他时间变换而表现出时间误差，这对有效的字典学习构成了重大挑战。动态时间扭曲（DTW）通常用于处理此类未对准问题。然而，DTW在对齐时间序列数据中的离散性质导致过度适应或信息丢失。为了解决这个问题，我们在本文中提出了一种广义的时间扭曲词典学习算法。我们的方法具有广义的时间翘曲操作员，该操作员由连续基础函数的线性组合组成，以促进连续的时间翘曲。提出的操作员和字典学习的集成被提出为优化问题，其中使用块坐标下降方法共同优化翘曲路径，词典和稀疏系数。然后，优化的结果用作饲料分类和聚类算法的超空间距离度量。与各种基准方法相比，通过十组公共数据集验证了拟议方法在字典学习，分类和聚类方面的优越性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10855328</guid>
      <pubDate>Mon, 27 Jan 2025 13:17:31 GMT</pubDate>
    </item>
    <item>
      <title>数量质量增强的自我训练网络，用于弱监督点云语义细分</title>
      <link>http://ieeexplore.ieee.org/document/10851436</link>
      <description><![CDATA[点云语义细分对于理解3D场景至关重要。当代技术通常需要广泛的注释培训数据，但是为点云获得点的注释是耗时且费力的。弱监督方法的最新发展试图通过使用有限的注释生成伪标签来减轻此问题。但是，这些伪标签经常遭受数量不足或质量较低。为了克服这些障碍，我们引入了一个数量质量增强的自我训练网络，以进行弱监督的点云语义细分（Q2E）。具体而言，提出了图像辅助的伪标签发生器来利用2D图像以扩展伪标签以扩展到点云。此外，开发了层次伪标签优化器，以通过将它们分层分组为更广泛的类别来完善伪标签的质量。关于扫描仪V2，S3DIS，Semantic3D和Semantickitti数据集的大量实验表明，Q2E的表现优于最先进的弱监督方法，并且竞争对手完全监督了点云语义段的方法。值得注意的是，从2024年2月2日的最初提交开始，我们的方法在Scannet-V2基准的各种设置中排名第一。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10851436</guid>
      <pubDate>Thu, 23 Jan 2025 13:16:30 GMT</pubDate>
    </item>
    <item>
      <title>通过像素逐像素密度分布建模的半监督计数</title>
      <link>http://ieeexplore.ieee.org/document/10848320</link>
      <description><![CDATA[本文着重于半监督的人群计数，其中只有一小部分培训数据被标记了。我们为像素的密度值制定为概率分布，而不是单个确定性值。在此基础上，我们提出了一个半监督的人群计数模型。首先，我们设计了一个像素分布匹配损失，以测量预测和地面真相之间像素密度分布的差异；其次，我们通过使用密度令牌来增强变压器解码器，以专门化解码器的前部W.R.T.不同的密度间隔；第三，我们设计了一个交织的一致性自我监督的学习机制，以有效地从未标记的数据中学习。在四个数据集上进行了广泛的实验，以表明我们的方法在各种标记的比率设置下显然优于竞争对手。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10848320</guid>
      <pubDate>Tue, 21 Jan 2025 13:15:59 GMT</pubDate>
    </item>
    <item>
      <title>通过旋转拉普拉斯分布在SO（3）上进行强大的概率建模</title>
      <link>http://ieeexplore.ieee.org/document/10848321</link>
      <description><![CDATA[从单个RGB图像估算3DOF旋转是一个重要但具有挑战性的问题。作为一种流行的方法，与单个预测旋转回归相比，概率旋转模型还带有预测不确定性信息。为了建模$ \ text {so}（3）$（3）上的概率分布，自然使用类似高斯的宾汉和矩阵Fisher是很自然的，但是它们被证明对异常预测很敏感，例如$ 180^\ circe $ $180∘错误，因此很难与最佳性能融合。在本文中，我们从多元拉普拉斯分布中汲取灵感，并在$ \ text {so}（3）$ so（3）上提出一种新颖的旋转拉普拉斯分布。我们的旋转拉普拉斯分布对异常值的干扰是可靠的，并且可以对其可以改善的低误差区域进行大量梯度。此外，我们表明我们的方法还表现出对小声音的鲁棒性，从而忍受不完善的注释。有了这个好处，我们证明了它在半监督的旋转回归中的优势，其中伪标签是嘈杂的。为了进一步捕获对称对象的多模式旋转解决方案空间，我们将分布扩展到旋转拉普拉斯混合模型并证明其有效性。我们的广泛实验表明，我们提出的分布和混合模型在概率和非稳定基线的所有旋转回归实验中都达到了最先进的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10848321</guid>
      <pubDate>Tue, 21 Jan 2025 13:15:58 GMT</pubDate>
    </item>
    <item>
      <title>在室外4D点云上进行弱监督的细分，并进行了4D分组</title>
      <link>http://ieeexplore.ieee.org/document/10848336</link>
      <description><![CDATA[最近，已经提出了一些弱监督的3D点云分割方法，以开发有效的模型，并以最小的注释工作。我们以前的工作W4DTS提出了一项具有挑战性的任务，该任务仅利用室外点云数据集中的0.001％点来实现有效的分割模型。但是，在非常有限的注释预算下，W4DTS产生的伪标签质量并不令人满意，这限制了这种情况下的细分性能。为了解决这个问题，我们提出了一种渐进的4D分组方法，以将带注释和未经注释的点分组，这可以生成具有非常稀疏的注释点的高质量伪标签。此外，为了进一步改善我们的渐进式4D分组方法，我们设计了跨框架对比学习和本地一致性学习，以提高4D分组的质量。实验结果表明，只有0.001％的注释，我们的解决方案明显优于先前的Semantickitti最佳方法。我们还在Semanticposs数据集和ScribbleKitti数据集上评估了我们的框架，并在我们完全监督的骨干模型上实现表演。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10848336</guid>
      <pubDate>Tue, 21 Jan 2025 13:15:58 GMT</pubDate>
    </item>
    </channel>
</rss>