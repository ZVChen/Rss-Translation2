<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 模式分析与机器智能学报 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物 # 34 的目录提醒</description>
    <lastBuildDate>Thu, 03 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>用于快照高光谱成像的非串行量化感知深度光学</title>
      <link>http://ieeexplore.ieee.org/document/10591456</link>
      <description><![CDATA[深度光学一直致力于捕捉动态场景的高光谱图像，其中光学编码器在决定成像性能方面起着至关重要的作用。我们的关键见解是，深度光学系统的光学编码器有望保持制造友好性和解码器友好性，分别在实施阶段忠实实现并在设计阶段与解码器充分交互。在本文中，我们提出了非串行量化感知深度光学（NSQDO），它由制造友好的量化感知模型（QAM）和解码​​器友好的非串行方式（NSM）组成。QAM将量化过程集成到优化中并自适应地调整每个量化级别的物理高度，通过对DOE物理结构的量化操作的感知和适应来减少物理编码器与数值模拟的偏差。NSM通过双向提示连接将编码器和解码器完全交互地桥接起来，并通过门控机制灵活化连接，增强深度光学中联合优化的能力。所提出的 NSQDO 提高了编码器的制造友好性和解码器友好性，并使深度光学框架变得更加实用和强大。大量的综合仿真和真实硬件实验证明了所提方法的优越性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10591456</guid>
      <pubDate>Tue, 09 Jul 2024 13:16:13 GMT</pubDate>
    </item>
    <item>
      <title>Flare7K++：混合合成数据集和真实数据集，用于夜间耀斑去除及其他用途</title>
      <link>http://ieeexplore.ieee.org/document/10541091</link>
      <description><![CDATA[人造光通常会在夜间拍摄的图像上留下强烈的镜头眩光伪影，降低视觉质量和视觉算法的性能。现有的眩光去除方法主要侧重于去除白天的眩光，而不适用于夜间。由于人造光具有独特的亮度和光谱，眩光的模式和图像退化程度也各不相同，因此夜间眩光去除具有挑战性。夜间眩光去除数据集的稀缺限制了这一重要任务的研究。在本文中，我们介绍了第一个全面的夜间眩光去除数据集Flare7K++，它包含962张真实拍摄的眩光图像（Flare-R）和7000张合成眩光（Flare7K）。与Flare7K相比，Flare7K++在消除光源周围的复杂退化方面特别有效，而单独使用合成眩光是无法解决这个问题的。此外，之前的眩光去除流程依赖于手动阈值和模糊核设置来提取光源，当光源很小或曝光不足时，这种方法可能会失败。为了解决这个问题，我们在 Flare7K++ 中额外提供了光源的注释，并提出了一种新的端到端流程，在去除镜头眩光的同时保留光源。我们的数据集和流程为未来研究夜间眩光去除提供了宝贵的基础和基准。大量实验表明，Flare7K++ 补充了现有眩光数据集的多样性，并将夜间眩光去除的前沿推向了真实场景。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10541091</guid>
      <pubDate>Wed, 29 May 2024 13:16:15 GMT</pubDate>
    </item>
    <item>
      <title>DeepMesh：可微分等值面提取</title>
      <link>http://ieeexplore.ieee.org/document/10506652</link>
      <description><![CDATA[随着连续深度隐式场的出现，几何深度学习最近取得了显著进展。它们允许对任意拓扑的防水表面进行详细建模，而无需依赖 3D 欧几里得网格，从而实现可学习的参数化，其分辨率不受限制。不幸的是，这些方法通常不适用于需要显式基于网格的表面表示的应用程序，因为将隐式场转换为这种表示依赖于 Marching Cubes 算法，该算法无法相对于底层隐式场进行区分。在这项工作中，我们消除了这一限制，并引入了一种可区分的方法来从深度隐式场生成显式表面网格表示。我们的主要见解是，通过推理隐式场扰动如何影响局部表面几何形状，最终可以区分表面样本相对于底层深度隐式场的 3D 位置。我们利用这一点来定义 DeepMesh——一种可以改变其拓扑的端到端可区分网格表示。我们通过多种应用验证了我们的理论见解：通过可微分渲染进行单视图 3D 重建、物理驱动形状优化、从扫描进行全场景 3D 重建和端到端训练。在所有情况下，我们的端到端可微分参数化都使我们比最先进的算法更具优势。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10506652</guid>
      <pubDate>Mon, 22 Apr 2024 13:16:00 GMT</pubDate>
    </item>
    <item>
      <title>用于 3D 物体检测的完全稀疏融合</title>
      <link>http://ieeexplore.ieee.org/document/10506794</link>
      <description><![CDATA[目前流行的多模态 3D 检测方法依赖于密集检测器，这些检测器通常使用密集的鸟瞰图 (BEV) 特征图。然而，这种 BEV 特征图的成本是检测范围的二次方，因此无法扩展到远程检测。最近，仅 LiDAR 的全稀疏架构因其在远程感知中的高效率而备受关注。在本文中，我们研究如何开发多模态全稀疏检测器。具体而言，我们提出的检测器将经过充分研究的 2D 实例分割集成到 LiDAR 侧，这与仅 LiDAR 基线中的 3D 实例分割部分平行。所提出的基于实例的融合框架在克服与仅 LiDAR 全稀疏检测器相关的限制的同时保持了完全稀疏性。我们的框架在广泛使用的 nuScenes 数据集、Waymo Open Dataset 和远程 Argoverse 2 数据集上展示了最先进的性能。值得注意的是，我们提出的方法在长距离感知设置下的推理速度比其他最先进的多模态 3D 检测方法快 2.7 倍。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10506794</guid>
      <pubDate>Mon, 22 Apr 2024 13:16:00 GMT</pubDate>
    </item>
    <item>
      <title>通过设计简约视频质量模型分析视频质量数据集</title>
      <link>http://ieeexplore.ieee.org/document/10499199</link>
      <description><![CDATA[盲视频质量评估 (BVQA) 在监控和改善各种现实世界中支持视频的媒体应用中的最终用户的观看体验方面发挥着不可或缺的作用。作为一个实验领域，BVQA 模型的改进主要在少数人工评级的 VQA 数据集上进行测量。因此，为了正确评估 BVQA 的当前进展，更好地了解现有的 VQA 数据集至关重要。为了实现这一目标，我们通过设计极简的 BVQA 模型对 VQA 数据集进行了前所未有的计算分析。通过极简，我们将我们的 BVQA 模型系列限制为仅基于基本块构建：视频预处理器（用于积极的时空下采样）、空间质量分析器、可选的时间质量分析器和质量回归器，所有这些都具有最简单的实例。通过在八个具有真实失真的 VQA 数据集上比较不同模型变体的质量预测性能，我们发现几乎所有数据集都存在不同严重程度的简单数据集问题，其中一些数据集甚至允许盲图像质量评估 (BIQA) 解决方案。我们还通过比较我们的模型在这些 VQA 数据集上的泛化能力，并通过消除与基本构建块相关的一组令人眼花缭乱的 BVQA 设计选择来证明我们的说法是正确的。我们的结果对 BVQA 的当前进展提出了质疑，同时为构建下一代 VQA 数据集和模型的良好实践提供了启示。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10499199</guid>
      <pubDate>Tue, 16 Apr 2024 13:16:00 GMT</pubDate>
    </item>
    <item>
      <title>论最优传输对课程强化学习的益处</title>
      <link>http://ieeexplore.ieee.org/document/10502148</link>
      <description><![CDATA[课程强化学习 (CRL) 允许通过生成定制的学习任务序列来解决复杂任务，从简单的任务开始，然后逐渐增加难度。尽管 RL 中的课程潜力已在各种工作中得到清晰展示，但如何为给定的学习环境生成课程尚不清楚，因此产生了各种旨在自动化此任务的方法。在这项工作中，我们专注于将课程设计为任务分布之间的插值，这之前已被证明是一种可行的 CRL 方法。确定现有方法的关键问题后，我们将课程生成设计为任务分布之间的受限最优传输问题。基准测试表明，这种课程生成方式可以改进现有的 CRL 方法，在具有不同特征的各种任务中取得优异的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10502148</guid>
      <pubDate>Tue, 16 Apr 2024 13:16:00 GMT</pubDate>
    </item>
    <item>
      <title>连接视觉和文本语义：实现无偏场景图生成的一致性</title>
      <link>http://ieeexplore.ieee.org/document/10502321</link>
      <description><![CDATA[场景图生成 (SGG) 旨在检测图像中的视觉关系。然而，由于长尾偏差，SGG 远未实用。大多数方法严重依赖统计共现的帮助来生成平衡的数据集，因此它们仅限于特定于数据集并且易受噪声的影响。根本原因是 SGG 被简化为分类任务而不是推理任务，因此捕捉细粒度细节的能力有限并且处理歧义的难度增加。通过模仿认知心理学中的双重过程的方式，提出了一种视觉文本语义一致性网络 (VTSCN)，将 SGG 任务建模为推理过程，并显著缓解长尾偏差。在 VTSCN 中，作为快速自主过程 (Type1 过程)，我们设计了一个混合联合表示 (HUR) 模块，该模块分为两个步骤，用于空间感知和工作记忆建模。此外，作为高阶推理过程（Type2 过程），设计了一个全局文本语义建模 (GTS) 模块，用于使用成对对象的词向量单独建模文本上下文。作为认知的最终联想过程，设计了一个异构语义一致性 (HSC) 模块来平衡 type1 过程和 type2 过程。最后，我们的 VTSCN 通过充分考虑人类的认知过程，为 SGG 模型设计提供了一种新方法。在 Visual Genome、GQA 和 PSG 数据集上的实验表明我们的方法优于最先进的方法，而消融研究验证了我们的 VTSCN 的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10502321</guid>
      <pubDate>Tue, 16 Apr 2024 13:15:59 GMT</pubDate>
    </item>
    <item>
      <title>学习素描：流数据中项目频率估计的神经方法</title>
      <link>http://ieeexplore.ieee.org/document/10499867</link>
      <description><![CDATA[最近，有一种趋势是设计神经数据结构，利用数据分布模式来提高准确性和适应性，以超越手工制作的数据结构。草图是实时网络分析、网络监控和自动驾驶中广泛使用的数据结构，用于估计有限空间内数据流的项目频率。然而，现有的草图尚未充分利用数据流分布的模式，因此很难将它们与擅长记忆模式信息的神经网络紧密结合。从前提开始，我们设想一个纯神经数据结构作为基础草图，我们称之为元草图，以重塑传统草图的基本结构。元草图在预训练阶段从遵循 Zipf 分布的合成数据集构成的元任务中学习基本的草图能力，并且可以在适应阶段快速适应真实（倾斜）分布。元草图不仅在绘制传统数据流方面超越其竞争对手，而且在支持更复杂的流数据（如多媒体和图形流场景）方面也具有良好的潜力。大量实验证明了元草图的优越性并提供了对其工作机制的见解。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10499867</guid>
      <pubDate>Mon, 15 Apr 2024 13:16:47 GMT</pubDate>
    </item>
    <item>
      <title>RDFC-GAN：用于室内深度补全的 RGB-深度融合 CycleGAN</title>
      <link>http://ieeexplore.ieee.org/document/10497905</link>
      <description><![CDATA[由于传感器和环境的固有限制，在室内场景中捕获的原始深度图像经常会出现大量缺失值。例如，透明材料经常会被深度传感器检测到；由于表面的抛光纹理、较长的距离以及与传感器的倾斜入射角，表面可能会引入测量误差。不完整深度图的存在给后续的视觉应用带来了重大挑战，促使人们开发了许多深度补全技术来缓解这一问题。许多方法擅长从稀疏样本中重建密集深度图，但它们在面对大量连续的缺失深度值区域时往往会失败，这是室内环境中普遍存在的关键挑战。为了克服这些挑战，我们设计了一种新颖的双分支端到端融合网络 RDFC-GAN，它将一对 RGB 和不完整的深度图像作为输入来预测密集和完整的深度图。第一个分支采用编码器-解码器结构，遵循曼哈顿世界假设并利用来自 RGB-D 信息的法线图作为指导，从原始深度图中回归局部密集深度值。另一个分支应用了 RGB 深度融合 CycleGAN，擅长将 RGB 图像转换为详细的纹理深度图，同时通过循环一致性确保高保真度。我们通过名为 W-AdaIN 的自适应融合模块融合这两个分支，并在伪深度图的帮助下训练模型。对 NYU-Depth V2 和 SUN RGB-D 数据集的综合评估表明，我们的方法显著提高了深度完成性能，尤其是在真实的室内环境中。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10497905</guid>
      <pubDate>Fri, 12 Apr 2024 13:16:19 GMT</pubDate>
    </item>
    <item>
      <title>校准光度立体成像及其他领域的深度学习方法</title>
      <link>http://ieeexplore.ieee.org/document/10497891</link>
      <description><![CDATA[光度立体成像从具有不同阴影线索的多幅图像中恢复物体的表面法线，即对每个像素的表面方向和强度之间的关系进行建模。光度立体成像在卓越的每像素分辨率和精细的重建细节方面占优势。然而，由于非朗伯表面反射率引起的非线性关系，这是一个复杂的问题。最近，各种深度学习方法在针对非朗伯表面的光度立体成像环境中表现出强大的能力。本文全面回顾了现有的基于深度学习的校准光度立体成像方法，这些方法利用正交相机和定向光源。我们首先从不同角度分析这些方法，包括输入处理、监督和网络架构。我们总结了深度学习光度立体模型在最广泛使用的基准数据集上的性能。这证明了基于深度学习的光度立体方法的先进性能。最后，我们根据现有模型的局限性提出建议并提出未来的研究趋势。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10497891</guid>
      <pubDate>Fri, 12 Apr 2024 13:16:19 GMT</pubDate>
    </item>
    <item>
      <title>集成预测器：多元时间序列分类的共形预测器的可能性组合</title>
      <link>http://ieeexplore.ieee.org/document/10497903</link>
      <description><![CDATA[在本文中，我们提出了一个概念框架来研究共形预测器 (CP) 的集合，我们称之为集合预测器 (EP)。我们的方法受到信息融合中不精确概率应用的启发。基于所提出的框架，我们首次在文献中研究了一般环境中 CP 集合的理论特性，重点关注简单且常用的可能性组合规则。我们还说明了所提出的方法在多变量时间序列分类环境中的适用性，表明这些方法在 UCR 时间序列档案中的大量基准测试中比标准分类算法和文献中提出的其他组合规则提供了更好的性能（在稳健性、保守性、准确性和运行时间方面）。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10497903</guid>
      <pubDate>Fri, 12 Apr 2024 13:16:19 GMT</pubDate>
    </item>
    <item>
      <title>多维度敏感度感知密度估计</title>
      <link>http://ieeexplore.ieee.org/document/10497882</link>
      <description><![CDATA[我们制定了一个优化问题，以在以不均匀概率采样的多维问题背景下估计概率密度。它将探测器灵敏度视为异质密度，并利用网格上样条提供的计算速度和灵活边界条件。我们选择通过核范数对样条的 Hessian 进行正则化以促进稀疏性。因此，该方法具有空间自适应性，并且对于起带宽作用的正则化参数的选择是稳定的。我们在标准密度上测试了我们的计算管道并提供软件。我们还提出了一种新的 PET 重新分组方法作为我们框架的应用。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10497882</guid>
      <pubDate>Fri, 12 Apr 2024 13:16:01 GMT</pubDate>
    </item>
    <item>
      <title>IG2：特征归因的迭代梯度路径上的积分梯度</title>
      <link>http://ieeexplore.ieee.org/document/10497902</link>
      <description><![CDATA[特征归因通过提供输入特征对模型预测贡献的重要性分数，在实例级别解释人工智能 (AI)。积分梯度 (IG) 是一种用于深度神经网络的著名路径归因方法，涉及沿从解释输入 (解释项) 到反事实实例 (基线) 的路径对梯度进行积分。当前的 IG 变体主要关注解释项输出的梯度。然而，我们的研究表明，反事实输出的梯度也会显著影响特征归因。为了实现这一点，我们提出了迭代梯度路径积分梯度 (IG2)，同时考虑了两个梯度。IG2 将反事实梯度迭代地合并到积分路径中，生成一条新路径 (GradPath) 和一条新基线 (GradCF)。这两个新的 IG 组件有效地解决了早期 IG 方法中的归因噪声和任意基线选择的问题。作为一种路径方法，IG2 满足许多理想的公理，这些公理在论文中得到了理论上的证明。 XAI 基准、ImageNet、MNIST、TREC 问答、晶圆图故障模式和 CelebA 人脸属性上的实验结果验证了 IG2 与最先进的技术相比提供了更卓越的特征归因。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10497902</guid>
      <pubDate>Fri, 12 Apr 2024 13:16:01 GMT</pubDate>
    </item>
    <item>
      <title>局部非刚性运动结构问题的闭式成对解</title>
      <link>http://ieeexplore.ieee.org/document/10492858</link>
      <description><![CDATA[非刚性运动结构 (NRSfM) 的最新趋势是表达图像对之间的局部、差分约束，通过求解多项式方程组，可以从中获得任意一点的表面法线。虽然这种方法比依赖全局约束的方法更成功，但由此产生的方法面临两个主要问题：首先，它们制定的大多数方程组都是高阶的，必须使用计算量大的多项式求解器来求解。一些方法使用多项式简化策略来简化系统，但这会增加一些幻影解。无论如何，都会采用额外的机制来选择最佳解决方案，这会增加计算量，但无法保证解决方案的可靠性。其次，这些方法制定了一对图像之间的约束。即使它们之间有足够的运动，它们也可能受到局部退化的影响，导致得到的估计值不可靠，没有任何警告机制。在本文中，我们为等距/共形 NRSfM 解决了这些问题。我们表明，在广泛适用的假设下，我们可以推导出一个关于表面法线的新方程组，其两个解可以以闭式获得，并且可以轻松地在局部消除歧义。我们的形式化方法还使我们能够评估估计的局部法线的可靠性，如果不可靠，则将其丢弃。我们的实验表明，从两个或更多视图获得的重建比最先进的方法准确得多，同时也更快。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10492858</guid>
      <pubDate>Thu, 04 Apr 2024 13:19:33 GMT</pubDate>
    </item>
    <item>
      <title>面向盲图像恢复的深度变分网络</title>
      <link>http://ieeexplore.ieee.org/document/10433564</link>
      <description><![CDATA[盲图像恢复 (IR) 是计算机视觉中一个常见但具有挑战性的问题。经典的基于模型的方法和最近的基于深度学习 (DL) 的方法代表了解决此问题的两种不同方法，每种方法都有各自的优点和缺点。在本文中，我们提出了一种新颖的盲图像恢复方法，旨在整合它们的优点。具体而言，我们为盲 IR 构建了一个通用的贝叶斯生成模型，该模型明确描述了退化过程。在该模型中，采用逐像素非独立同分布高斯分布来拟合图像噪声。它比大多数传统方法中采用的简单独立同分布高斯或拉普拉斯分布具有更大的灵活性，从而可以处理图像退化中包含的更复杂的噪声类型。为了解决该模型，我们设计了一种变分推理算法，其中所有预期的后验分布都被参数化为深度神经网络，以提高其模型能力。值得注意的是，这种推理算法引入了一个统一的框架来共同处理退化估计和图像恢复的任务。此外，前一个任务中估计的退化信息被用来指导后一个IR过程。在两个典型的盲IR任务，即图像去噪和超分辨率上的实验表明，所提出的方法取得了优于当前最先进的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10433564</guid>
      <pubDate>Tue, 13 Feb 2024 13:17:59 GMT</pubDate>
    </item>
    </channel>
</rss>