<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 模式分析和机器智能汇刊 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物 TOC 提醒# 34</description>
    <lastBuildDate>Tue, 05 Dec 2023 05:00:00 GMT</lastBuildDate>
    <item>
      <title>自动注视分析：基于深度学习的方法综述</title>
      <link>http://ieeexplore.ieee.org/document/10319064</link>
      <description><![CDATA[眼睛注视分析是计算机视觉和人机交互领域的一个重要研究问题。即使在过去 10 年中取得了显着进展，由于眼睛外观、眼头相互作用、遮挡、图像质量和照明条件的独特性，自动注视分析仍然具有挑战性。有几个悬而未决的问题，包括在没有先验知识的情况下在不受约束的环境中解释注视方向的重要线索是什么，以及如何实时编码它们。我们回顾了一系列凝视分析任务和应用的进展，以阐明这些基本问题，确定凝视分析的有效方法，并提供未来可能的方向。我们根据最新的注视估计和分割方法的优点和报告的评估指标，分析了它们的优点，特别是在无监督和弱监督领域。我们的分析表明，鲁棒且通用的注视分析方法的开发仍然需要解决现实世界的挑战，例如无约束的设置和较少监督的学习。最后，我们讨论了设计现实世界注视分析系统的未来研究方向，该系统可以传播到其他领域，包括计算机视觉、增强现实 (AR)、虚拟现实 (VR) 和人机交互 (HCI)。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10319064</guid>
      <pubDate>Wed, 15 Nov 2023 13:16:33 GMT</pubDate>
    </item>
    <item>
      <title>研究图像现实主义的机器学习范式：康斯特布尔的云有多准确？</title>
      <link>http://ieeexplore.ieee.org/document/10286060</link>
      <description><![CDATA[英国风景画家约翰·康斯特布尔被认为是 19 世纪欧洲绘画现实主义运动的奠基人。尤其是康斯特布尔画的天空，被他的同时代人认为非常准确，今天许多观众也有同样的印象。然而，即使对于专业艺术史学家来说，评估像康斯特布尔这样的现实主义绘画的准确性也是主观或直观的，因此很难确定康斯特布尔的天空与同时代的天空有何不同。我们的目标是帮助人们更客观地理解康斯特布尔的现实主义。我们提出了一种新的基于机器学习的范式，以可解释的方式研究图像现实主义。我们的框架通过测量康斯特布尔等以天空闻名的艺术家所画的云彩与云彩照片之间的相似性来评估现实主义。云分类的实验结果表明，康斯特布尔比他的同时代人更接近他画作中实际云的形式特征。这项研究作为一种新颖的跨学科方法，结合了计算机视觉和机器学习、气象学和艺术史，是对绘画现实主义进行更广泛和更深入分析的跳板。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10286060</guid>
      <pubDate>Mon, 16 Oct 2023 13:17:28 GMT</pubDate>
    </item>
    <item>
      <title>点云中 3D 单对象跟踪的有效的以运动为中心的范式</title>
      <link>http://ieeexplore.ieee.org/document/10285389</link>
      <description><![CDATA[LiDAR 点云 (LiDAR SOT) 中的 3D 单目标跟踪在自动驾驶中发挥着至关重要的作用。当前的方法都遵循基于外观匹配的暹罗范例。然而，激光雷达点云通常无纹理且不完整，这阻碍了有效的外观匹配。此外，以前的方法极大地忽略了目标之间的关键运动线索。在这项工作中，除了 3D 连体跟踪之外，我们还引入了一种以运动为中心的范例，从新的角度处理 LiDAR SOT。遵循这个范式，我们提出了一种无匹配的两级跟踪器 M$^{2}$2-Track。在第一阶段，$M^{2}$M2-Track 通过运动变换将目标定位在连续帧内。然后，它在第二阶段通过运动辅助形状完成来细化目标框。由于以运动为中心的性质，我们的方法在有限的训练标签下显示出令人印象深刻的通用性，并为端到端循环训练提供了良好的可区分性。这激励我们通过结合基于伪标签的运动增强和自监督损失项来探索半监督 LiDAR SOT。在完全监督的设置下，大量实验证实 $M^{2}$M2-Track 在三个大型数据集上显着优于先前的最先进技术，同时以 57FPS 运行（$\sim$∼ 3%， KITTI、NuScenes 和 Waymo 开放数据集上的精度分别提高了 $\sim$∼ 11% 和 $\sim$∼ 22%）。在半监督设置下，我们的方法使用不到一半的 KITTI 标签，其性能与完全监督的方法相当甚至超过了完全监督的方法。进一步的分析验证了每个组件的有效性，并显示了以运动为中心的范式在自动标记和无监督域适应方面的巨大潜力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10285389</guid>
      <pubDate>Fri, 13 Oct 2023 13:16:29 GMT</pubDate>
    </item>
    <item>
      <title>持续学习，快与慢</title>
      <link>http://ieeexplore.ieee.org/document/10285461</link>
      <description><![CDATA[根据神经科学中的互补学习系统（CLS）理论（McClelland et al. 1995），人类通过两个互补系统进行有效的持续学习：一个以海马体为中心的快速学习系统，用于快速学习具体细节、个人经验；另一个以海马体为中心的快速学习系统，用于快速学习具体细节和个人经验；位于新皮质的缓慢学习系统用于逐渐获取有关环境的结构化知识。受这一理论的启发，我们提出了 DualNets（双网络），这是一种通用的持续学习框架，包括一个用于监督学习特定任务的模式分离表示的快速学习系统和一个用于通过任务无关的通用表示进行表示学习的慢速学习系统自我监督学习（SSL）。 DualNets 可以将两种表示类型无缝地整合到一个整体框架中，以促进深度神经网络更好的持续学习。通过大量的实验，我们展示了 DualNets 在各种持续学习协议上的有希望的结果，从标准的离线、任务感知设置到具有挑战性的在线、无任务场景。值得注意的是，在 CTrL（Veniat 等人，2020 年）基准测试中，任务与视觉图像截然不同，而 DualNet 可以通过现有最先进的动态架构策略实现具有竞争力的性能（Ostapenko 等人，2021 年）。此外，我们还进行了全面的消融研究，以验证 DualNet 的功效、稳健性和可扩展性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10285461</guid>
      <pubDate>Fri, 13 Oct 2023 13:16:29 GMT</pubDate>
    </item>
    <item>
      <title>Booster：镜面和透明表面图像深度的基准</title>
      <link>http://ieeexplore.ieee.org/document/10278453</link>
      <description><![CDATA[如今，从图像估计深度在域内准确性和泛化方面都产生了出色的结果。然而，我们发现该领域仍然存在两个主要挑战：处理非朗伯材料和有效处理高分辨率图像。我们特意提出了一个新颖的数据集，其中包括高分辨率的准确且密集的地面实况标签，其中包含多个镜面和透明表面的场景。我们的采集管道利用新颖的深度时空立体框架，能够以亚像素精度轻松准确地进行标记。该数据集由在 85 个不同场景中收集的 606 个样本组成，每个样本包括一个高分辨率对 (12 Mpx) 以及一个不平衡立体声对（左：12 Mpx，右：1.1 Mpx），这是现代移动设备的典型特征安装具有不同分辨率的传感器。此外，我们还提供手动注释的材料分割掩模和 15 K 未标记的样本。该数据集由一个训练集和两个测试集组成，后者专门用于评估立体和单目深度估计网络。我们的实验强调了该领域的开放挑战和未来的研究方向。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10278453</guid>
      <pubDate>Wed, 11 Oct 2023 13:17:45 GMT</pubDate>
    </item>
    <item>
      <title>通过堆叠混合单元的紧凑神经网络</title>
      <link>http://ieeexplore.ieee.org/document/10275036</link>
      <description><![CDATA[作为网络压缩的有效工具，剪枝技术已被广泛用于减少深度神经网络（NN）中的大量参数。然而，非结构化剪枝在处理稀疏和不规则的权重方面存在局限性。相比之下，结构化剪枝可以帮助消除这个缺点，但它需要复杂的标准来确定要剪枝的组件。因此，本文提出了一种称为BUnit-Net的新方法，该方法通过堆叠设计的基本单元直接构造紧凑的神经网络，而不再需要额外的判断标准。给定各种架构的基本单元，将它们系统地组合和堆叠以构建紧凑的神经网络，由于单元之间的独立性，该神经网络涉及较少的权重参数。这样，BUnit-Net可以达到与非结构化剪枝相同的压缩效果，同时权重张量仍然可以保持规则和密集。我们在不同的流行主干网络中制定了 BUnit-Net，与不同基准数据集上最先进的剪枝方法进行比较。此外，提出了两个新指标来评估压缩性能的权衡。实验结果表明，BUnit-Net 可以实现相当的分类精度，同时节省约 80% 的 FLOP 和 73% 的参数。也就是说，堆叠基本单元为网络压缩提供了一种新的有前途的方式。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10275036</guid>
      <pubDate>Tue, 10 Oct 2023 13:17:24 GMT</pubDate>
    </item>
    <item>
      <title>数据集蒸馏：全面回顾</title>
      <link>http://ieeexplore.ieee.org/document/10275116</link>
      <description><![CDATA[深度学习最近的成功很大程度上归功于用于训练深度神经网络的大量数据。尽管取得了前所未有的成功，但不幸的是，海量数据显着增加了存储和传输的负担，并进一步导致了繁琐的模型训练过程。此外，依赖原始数据进行训练本身就会产生对隐私和版权的担忧。为了缓解这些缺点，引入了数据集蒸馏（DD），也称为数据集压缩（DC），并且最近引起了社区的广泛研究关注。给定原始数据集，DD 的目标是导出包含合成样本的小得多的数据集，基于该数据集，经过训练的模型产生的性能与在原始数据集上训练的模型相当。在本文中，我们对DD及其应用的最新进展进行了全面的回顾和总结。我们首先正式介绍该任务，并提出一个整体算法框架，然后提出所有现有的 DD 方法。接下来，我们提供该领域当前方法的系统分类，并讨论它们的理论互连。我们还通过广泛的实证研究提出了 DD 当前的挑战，并展望了未来工作的可能方向。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10275116</guid>
      <pubDate>Tue, 10 Oct 2023 13:17:23 GMT</pubDate>
    </item>
    <item>
      <title>具有在线拉普拉斯逼近的贝叶斯联邦学习框架</title>
      <link>http://ieeexplore.ieee.org/document/10274722</link>
      <description><![CDATA[联邦学习（FL）允许多个客户端通过模型聚合和本地模型训练的循环来协作学习全局共享模型，而无需共享数据。大多数现有的FL方法在不同的客户端上分别训练本地模型，然后简单地平均它们的参数以获得服务器端的集中模型。然而，这些方法通常会遭受较大的聚合错误和严重的局部遗忘，这在异构数据设置中尤其糟糕。为了解决这些问题，在本文中，我们提出了一种新颖的 FL 框架，该框架使用在线拉普拉斯近似来近似客户端和服务器端的后验。在服务器端，采用多元高斯乘积机制来构造和最大化全局后验，大大减少了局部模型之间的巨大差异引起的聚合误差。在客户端，使用从服务器传递的全局后验概率参数的先验损失被设计来指导本地训练。绑定来自其他客户端的此类学习约束使我们的方法能够减轻局部遗忘。最后，我们在多个基准测试中取得了最先进的结果，清楚地证明了所提出方法的优势。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10274722</guid>
      <pubDate>Mon, 09 Oct 2023 13:17:56 GMT</pubDate>
    </item>
    <item>
      <title>通过自监督交互学习时人工神经网络中少样本学习能力的发展</title>
      <link>http://ieeexplore.ieee.org/document/10274870</link>
      <description><![CDATA[大多数用于对象识别的人工神经网络都是在完全监督的设置中进行训练的。这不仅消耗资源，因为它需要大量标记示例数据集，而且与人类的学习方式有很大不同。我们使用的设置是，人工智能代理首先通过自我监督、好奇心驱动的探索在模拟世界中学习。在这一初始学习阶段之后，学习到的表示可用于快速关联语义概念，例如使用一个或多个标记示例的不同类型的门。为此，我们使用一种称为快速概念映射的方法，该方法使用神经元的相关放电模式来定义和检测语义概念。这种关联在很少有标记的例子的情况下立即起作用，类似于我们在人类中观察到的一种称为快速映射的现象。引人注目的是，我们已经可以用少至一个标记的示例来识别对象，这突显了通过与世界交互而自我监督学习的编码的质量。因此，它提出了一种在没有太多监督的情况下学习概念的可行策略，并表明通过纯粹的交互可以学习环境的有意义的表示，这比非交互方法更适合短时间学习。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10274870</guid>
      <pubDate>Mon, 09 Oct 2023 13:17:56 GMT</pubDate>
    </item>
    <item>
      <title>数据集蒸馏的全面调查</title>
      <link>http://ieeexplore.ieee.org/document/10273632</link>
      <description><![CDATA[深度学习技术在过去十年中得到了前所未有的发展，并已成为许多应用领域的首选。这一进展主要归功于系统性的协作，快速增长的计算资源鼓励先进的算法处理海量数据。然而，用有限的计算能力来处理无限增长的数据逐渐变得具有挑战性。为此，提出了多种方法来提高数据处理效率。数据集蒸馏是一种数据集约简方法，通过从大量数据合成小型典型数据集来解决这个问题，并引起了深度学习界的广泛关注。现有的数据集蒸馏方法可以根据它们是否明确模仿目标数据的性能来分类为元学习和数据匹配框架。尽管数据集蒸馏在压缩数据集方面表现出了令人惊讶的性能，但仍然存在一些限制，例如提取高分辨率数据或具有复杂标签空间的数据。本文从蒸馏框架和算法、分解数据集蒸馏、性能比较和应用等多个方面全面介绍了数据集蒸馏。最后，我们讨论了进一步促进数据集蒸馏未来研究的挑战和有希望的方向。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10273632</guid>
      <pubDate>Fri, 06 Oct 2023 13:16:59 GMT</pubDate>
    </item>
    <item>
      <title>用于时间序列建模的深度高效连续流形学习</title>
      <link>http://ieeexplore.ieee.org/document/10266751</link>
      <description><![CDATA[随着深度神经网络在各个领域取得前所未有的成功，非欧几里德数据建模正在引起广泛关注。特别是，由于对称正定矩阵能够学习有益的统计表示，因此在计算机视觉、信号处理和医学图像分析领域正在积极研究。然而，由于其严格的约束，它仍然对优化问题和低效的计算成本具有挑战性，特别是当将其与深度学习框架结合时。在本文中，我们提出了一个利用黎曼流形和 Cholesky 空间之间的微分同胚映射的框架，通过该框架，不仅可以有效解决优化问题，而且可以大大降低计算成本。此外，对于时间序列数据的动态建模，我们通过系统地集成流形常微分方程和门控递归神经网络来设计连续流形学习方法。值得注意的是，由于 Cholesky 空间中矩阵的良好参数化，训练我们提出的配备黎曼几何度量的网络非常简单。我们通过对规则和不规则时间序列数据集的实验证明，我们提出的模型可以有效、可靠地进行训练，并且在各种时间序列任务中优于现有的流形方法和最先进的方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10266751</guid>
      <pubDate>Thu, 28 Sep 2023 13:16:52 GMT</pubDate>
    </item>
    <item>
      <title>语义图像分割的领域自适应和可推广网络架构和训练策略</title>
      <link>http://ieeexplore.ieee.org/document/10266755</link>
      <description><![CDATA[无监督域适应 (UDA) 和域泛化 (DG) 使在源域上训练的机器学习模型能够在未标记甚至看不见的目标域上表现良好。由于之前的 UDA&amp;DG 语义分割方法大多基于过时的网络，因此我们对更新的架构进行了基准测试，揭示了 Transformer 的潜力，并设计了为 UDA&amp;DG 量身定制的 DAFormer 网络。它通过三种训练策略来实现，以避免对源域的过度拟合：(1) 稀有类采样减轻了对常见源域类的偏差，(2) 事物类 ImageNet 特征距离和 (3) 学习率预热促进来自 ImageNet 预训练的特征转移。由于 UDA 和 DG 通常是 GPU 内存密集型，因此之前的大多数方法都会缩小或裁剪图像。然而，低分辨率预测通常无法保留精细细节，而使用裁剪图像训练的模型在捕获长范围、域鲁棒性上下文信息方面却达不到要求。因此，我们提出了 HRDA，一种用于 UDA 和 DG 的多分辨率框架，它结合了小型高分辨率裁剪的优点来保留精细分割细节和大型低分辨率裁剪的优点，以通过学习的尺度注意力来捕获远程上下文依赖性。 DAFormer 和 HRDA 在 5 个不同的基准上将最先进的 UDA&amp;DG 显着提高了 10 mIoU 以上。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10266755</guid>
      <pubDate>Thu, 28 Sep 2023 13:16:52 GMT</pubDate>
    </item>
    <item>
      <title>深度场景流学习：从 2D 图像到 3D 点云</title>
      <link>http://ieeexplore.ieee.org/document/10264132</link>
      <description><![CDATA[场景流描述场景中的 3D 运动。它可以建模为单个任务，也可以建模为深度、相机运动和光流估计等辅助任务的组合。近年来深度学习的出现拓宽了估计这些任务的新方法的视野，无论是作为单独的任务还是作为重建场景流的联合任务。相机合成或捕获的图像序列用作这些方法的输入，这些方法面临着处理图像中的各种情况以提供最准确的运动（例如图像质量）的挑战。如今，图像已被点云取代，点云提供 3D 信息，从而加快和增强估计的运动。在本文中，我们深入研究了深度学习时代的场景流估计。我们全面概述了有关基于图像和基于点云的方法的重要主题。此外，我们还介绍了每个类别的方法，重点介绍了网络架构。此外，我们还对这些方法在性能和效率方面进行了比较。最后，我们通过对开放问题和未来研究方向的见解和讨论来结束本次调查。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10264132</guid>
      <pubDate>Tue, 26 Sep 2023 13:16:36 GMT</pubDate>
    </item>
    <item>
      <title>通过学习分解将元学习情境化</title>
      <link>http://ieeexplore.ieee.org/document/10256146</link>
      <description><![CDATA[元学习已成为基于支持集构建目标模型的有效方法。例如，元学习嵌入通过将实例拉近其同类邻居，可以为特定任务构建目标最近邻分类器。然而，单个实例可以通过各种潜在属性进行注释，使得支持集内部或跨支持集的视觉上相似的实例具有不同的标签以及与其他实例的不同关系。因此，用于从支持集中推断目标模型的统一元学习策略无法捕获实例方面的模糊相似性。为此，我们提出学习分解网络（LeadNet）来将元学习的“支持目标”策略情境化，利用支持集中具有一个或混合潜在属性的实例的上下文。特别是，实例之间的比较关系被分解为w.r.t。多个嵌入空间。 LeadNet 学习通过将跨上下文的比较变化与多义嵌入结合起来，自动选择与正确属性相关的策略。我们展示了 LeadNet 在各种应用中的优越性，包括探索混乱数据的多种视图、分布外识别和少样本图像分类。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10256146</guid>
      <pubDate>Wed, 20 Sep 2023 14:10:47 GMT</pubDate>
    </item>
    <item>
      <title>DualRC：具有视觉对应邻域共识的双分辨率学习框架</title>
      <link>http://ieeexplore.ieee.org/document/10255317</link>
      <description><![CDATA[我们解决在两个图像之间建立准确对应关系的问题。我们提出了一个灵活的框架，可以轻松适应几何和语义匹配。我们的贡献包括三个部分。首先，我们提出了一个端到端的可训练框架，该框架使用从粗到细的匹配策略来准确地找到对应关系。我们生成两个分辨率级别的特征图，通过 4D 卷积对粗特征图强制邻域一致性约束，并使用生成的相关图来调节精细特征图的匹配。其次，我们提出了该模型的三种变体，各有不同的侧重点。即，一种名为 DualRC 的通用对应模型，适用于几何和语义匹配；一种名为 DualRC-L 的高效模型，专为几何匹配而定制，具有轻量级邻域共识模块，可显着加速高分辨率输入图像的流程；以及 DualRC -D 模型，其中我们提出了一种新颖的动态自适应邻域共识模块（DyANC），该模块动态选择具有适当邻域大小的最合适的非各向同性 4D 卷积核，以考虑尺度变化。最后，我们对几何和语义匹配的公共基准进行了彻底的实验，在这两种情况下都显示出卓越的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10255317</guid>
      <pubDate>Tue, 19 Sep 2023 14:02:27 GMT</pubDate>
    </item>
    </channel>
</rss>