<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 模式分析和机器智能汇刊 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物 TOC 提醒# 34</description>
    <lastBuildDate>Fri, 03 Nov 2023 04:00:00 GMT</lastBuildDate>
    <item>
      <title>相关循环单元：一种用于提高时间序列数据预测性能的新型神经架构</title>
      <link>http://ieeexplore.ieee.org/document/10264112</link>
      <description><![CDATA[时间序列预测（TSF）是人工智能领域的传统问题，循环神经网络、长短期记忆、门循环单元等模型有助于提高其预测精度。此外，还提出了模型结构来结合时间序列分解方法，例如使用 LOESS 进行季节趋势分解。然而，这种方法是在每个组件的独立模型中学习的，因此它无法学习时间序列组件之间的关系。在这项研究中，我们提出了一种称为相关循环单元（CRU）的新神经架构，它可以在神经单元内执行时间序列分解并学习每个分解组件之间的相关性（自相关和相关）。使用四个单变量和四个多元时间序列数据集，通过与之前的研究进行比较实验来评估所提出的神经架构。结果显示，长期和短期预测性能提高了 10% 以上。实验结果表明，与其他神经架构相比，所提出的 CRU 是解决 TSF 问题的优秀方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10264112</guid>
      <pubDate>Tue, 26 Sep 2023 13:16:37 GMT</pubDate>
    </item>
    <item>
      <title>Bailando++：具有编排记忆的 3D 舞蹈 GPT</title>
      <link>http://ieeexplore.ieee.org/document/10264209</link>
      <description><![CDATA[我们提出的音乐到舞蹈框架 Bailando++ 解决了驱动 3D 角色以遵循编舞规范约束并保持与不同音乐流派的时间一致性的方式跳舞的挑战。 Bailando++ 由两个组件组成：一个舞蹈记忆，用于学习从 3D 姿势序列中总结有意义的舞蹈单元；以及一个演员评论家生成预训练变形器 (GPT)，用于将这些单元组合成与音乐连贯的流畅舞蹈。特别是，为了同步不同的运动节奏和音乐节拍，我们向 GPT 引入了一种基于演员评论家的强化学习方案，并具有新颖的节拍对齐奖励功能。此外，我们考虑在旋转域中学习人类舞蹈姿势，以避免与人类形态不兼容的身体扭曲，并引入音乐上下文编码，使运动 GPT 能够掌握长期的音乐模式。我们在标准基准上的实验表明，Bailando++ 在定性和定量上都实现了最先进的性能，并具有在编舞记忆中无监督地发现人类可解释的舞蹈风格姿势的额外好处。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10264209</guid>
      <pubDate>Tue, 26 Sep 2023 13:16:36 GMT</pubDate>
    </item>
    <item>
      <title>用于部分人员重新识别的属性引导协作学习</title>
      <link>http://ieeexplore.ieee.org/document/10239469</link>
      <description><![CDATA[部分行人重识别（ReID）旨在解决由于遮挡或视野外导致的图像空间错位问题。尽管通过引入附加信息（例如人体姿势地标、掩模图和空间信息）取得了重大进展，但由于噪声关键点和易受影响的行人表示，部分人物 ReID 仍然具有挑战性。为了解决这些问题，我们提出了一种统一的属性引导的部分行人 ReID 协作学习方案。具体来说，我们引入了一种自适应阈值引导的掩模图卷积网络，它可以动态删除不可信的边缘以抑制噪声关键点的扩散。此外，我们结合了人类属性并设计了一种循环异构图卷积网络，通过图内和图间交互有效地融合跨模式行人信息，从而产生稳健的行人表示。最后，为了增强关键点表示学习，我们根据人体的轴对称特性设计了一种新颖的基于部位的相似性约束。对多个公共数据集的广泛实验表明，与其他最先进的基线相比，我们的模型实现了卓越的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10239469</guid>
      <pubDate>Tue, 05 Sep 2023 14:02:30 GMT</pubDate>
    </item>
    <item>
      <title>通过 3D 人脸重建进行模板反转攻击的人脸识别系统综合漏洞评估</title>
      <link>http://ieeexplore.ieee.org/document/10239446</link>
      <description><![CDATA[在本文中，我们使用 3D 人脸重建全面评估了最先进的人脸识别系统对模板反转攻击的脆弱性。我们提出了一种新方法（称为 GaFaR），使用预训练的几何感知面部生成网络从面部模板重建 3D 面部，并训练从面部模板到面部生成网络的中间潜在空间的映射。我们使用真实和合成的面部图像，通过半监督方法来训练我们的映射。对于真实的人脸图像，我们使用基于生成对抗网络（GAN）的框架来学习生成器中间潜在空间的分布。对于合成面部图像，我们直接学习从面部模板到生成器中间潜在代码的映射。此外，为了提高攻击成功率，我们对GNeRF模型的相机参数采用了两种优化方法。我们在针对人脸识别系统的白盒和黑盒攻击中提出了我们的方法，并将我们的攻击的可转移性与 MOBIO 和 LFW 数据集上其他人脸识别系统的最先进方法进行了比较。我们还使用数字屏幕回放和打印照片对人脸识别系统进行实际的演示攻击，并评估人脸识别系统对不同模板反转攻击的脆弱性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10239446</guid>
      <pubDate>Tue, 05 Sep 2023 14:02:29 GMT</pubDate>
    </item>
    <item>
      <title>使用 Transformer 进行从粗到细的多场景姿势回归</title>
      <link>http://ieeexplore.ieee.org/document/10236469</link>
      <description><![CDATA[绝对相机位姿回归器仅根据捕获的图像来估计相机的位置和方向。通常，具有多层感知器 (MLP) 头的卷积主干使用图像和姿势标签进行训练，以一次嵌入单个参考场景。最近，通过用一组全连接层替换 MLP 头，该方案被扩展为学习多个场景。在这项工作中，我们建议使用 Transformer 学习多场景绝对相机姿势回归，其中编码器用于聚合具有自注意力的激活图，解码器将潜在特征和场景编码转换为姿势预测。这使得我们的模型能够专注于为本地化提供信息的一般特征，同时并行嵌入多个场景。我们扩展了 Shavit 等人之前的 MS-Transformer 方法。 （2021）通过引入混合分类回归架构来提高定位精度。我们的方法在常见的基准室内和室外数据集上进行了评估，并且已被证明超过了多场景和最先进的单场景绝对姿势回归器。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10236469</guid>
      <pubDate>Thu, 31 Aug 2023 14:03:08 GMT</pubDate>
    </item>
    <item>
      <title>拓扑数据分析中的向量化方法综述</title>
      <link>http://ieeexplore.ieee.org/document/10235748</link>
      <description><![CDATA[将拓扑信息合并到监督学习任务中的尝试已经产生了几种用于矢量化持久同源条形码的技术。在本文中，我们研究了十三种这样的方法。除了描述这些方法的组织框架之外，我们还针对三个众所周知的分类任务对它们进行了全面的基准测试。令人惊讶的是，我们发现性能最好的方法是简单的向量化，它仅包含一些基本的汇总统计数据。最后，我们提供了一个方便的 Web 应用程序，旨在促进各种矢量化方法的探索和实验。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10235748</guid>
      <pubDate>Wed, 30 Aug 2023 14:01:58 GMT</pubDate>
    </item>
    <item>
      <title>点云分割中域适应的组合语义混合</title>
      <link>http://ieeexplore.ieee.org/document/10234713</link>
      <description><![CDATA[当使用不同传感器捕获的数据或由于域转移而在不同环境中进行训练和测试时，3D 点云语义分割的深度学习模型表现出有限的泛化能力。可以采用域适应方法来减轻这种域转移，例如，通过模拟传感器噪声、开发与域无关的生成器或训练点云补全网络。通常，这些方法是针对范围视图地图量身定制的，或者需要多模式输入。相反，图像域中的域自适应可以通过样本混合来执行，这强调输入数据操作而不是采用不同的自适应模块。在本研究中，我们引入了用于点云域自适应的组合语义混合，代表了第一个基于语义和几何样本混合的点云分割无监督域自适应技术。我们提出了一种两分支对称网络架构，能够同时处理来自源域（例如合成）的点云和来自目标域（例如现实世界）的点云。每个分支通过集成来自另一域的选定数据片段并利用从源标签和目标（伪）标签导出的语义信息在一个域内运行。此外，我们的方法可以利用有限数量的人类点级注释（半监督）来进一步提高性能。我们使用 LiDAR 数据集在合成到真实和真实到真实场景中评估我们的方法，并证明它在无监督和半监督设置中都显着优于最先进的方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10234713</guid>
      <pubDate>Wed, 30 Aug 2023 14:01:58 GMT</pubDate>
    </item>
    <item>
      <title>用于弱监督对象定位的背景感知分类激活图</title>
      <link>http://ieeexplore.ieee.org/document/10234096</link>
      <description><![CDATA[弱监督对象定位（WSOL）通过使用图像级注释来监督学习过程，放宽了对象定位密集注释的要求。然而，大多数WSOL方法只专注于迫使目标分类器在目标部分上产生高激活分数，而没有考虑背景位置的影响，导致过度的背景激活和不良姿势背景分数搜索。基于这一点，我们的工作提出了一种称为背景感知分类激活图（B-CAM）的新机制，为 WSOL 训练添加背景感知。除了聚合对象图像级特征以进行监督之外，我们的 B-CAM 还生成额外的背景图像级特征来表示纯背景样本。这一附加功能可以为对象分类器提供背景线索，以抑制对象定位图上的背景激活。此外，我们的 B-CAM 还训练了具有图像级注释的背景分类器，以在确定二进制定位掩模时产生自适应背景分数。实验表明所提出的 B-CAM 在四种不同类型的 WSOL 基准上的有效性，包括 CUB-200、ILSVRC、OpenImages 和 VOC2012 数据集。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10234096</guid>
      <pubDate>Tue, 29 Aug 2023 14:02:46 GMT</pubDate>
    </item>
    <item>
      <title>AdaPoinTr：使用自适应几何感知变压器完成多样化点云</title>
      <link>http://ieeexplore.ieee.org/document/10232862</link>
      <description><![CDATA[在本文中，我们提出了一种名为 PoinTr 的 Transformer 编码器-解码器架构，它将点云补全重新表述为集合到集合的转换问题，并采用几何感知块来显式地建模局部几何关系。 Transformers 的迁移使我们的模型能够更好地学习结构知识并保留点云补全的详细信息。朝着更复杂和多样化的情况迈出了一步，我们通过开发自适应查询生成机制并在完成点云期间设计新颖的去噪任务，进一步提出了 AdaPoinTr。将这两种技术结合起来使我们能够高效且有效地训练模型：我们减少了训练时间（15 倍或更多）并提高了完成性能（超过 20%）。此外，我们提出了两个更具挑战性的基准，具有更多样化的不完整点云，可以更好地反映现实世界的场景，以促进未来的研究。我们还表明，通过设计新的几何增强语义场景完成框架，我们的方法可以扩展到场景级点云完成场景。对现有数据集和新提出的数据集的大量实验证明了我们的方法的有效性，在 PCN 上达到了 6.53 CD，在 ShapeNet-55 上达到了 0.81 CD，在现实世界 KITTI 上达到了 0.392 MMD，大大超过了其他工作并建立了新的状态在各种基准上都是最先进的。最值得注意的是，与之前实践中的最佳方法相比，AdaPoinTr 可以通过更高的吞吐量和更少的 FLOP 实现如此有前途的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10232862</guid>
      <pubDate>Mon, 28 Aug 2023 14:05:00 GMT</pubDate>
    </item>
    <item>
      <title>ActiveZero++：混合域学习立体和基于置信度的零注释深度完成</title>
      <link>http://ieeexplore.ieee.org/document/10219021</link>
      <description><![CDATA[基于学习的立体方法通常需要具有深度的大规模数据集，然而在真实域中获得准确的深度很困难，但在模拟域中很容易获得真实深度。在本文中，我们提出了一个新框架 ActiveZero++，它是一种用于主动立体视觉系统的混合域学习解决方案，不需要现实世界的深度注释。在模拟领域，我们在形状基元数据集上结合使用监督视差损失和自监督损失。相比之下，在真实领域，我们仅在训练模拟数据或测试真实数据的分布外的数据集上使用自监督损失。为了提高难以感知区域的重投影损失的鲁棒性和准确性，我们的方法引入了一种新颖的自监督损失，称为时间 IR 重投影。此外，我们提出了基于置信度的深度完成模块，该模块使用立体网络的置信度通过深度法线一致性来识别和改进深度预测中的错误区域。对现实世界数据的广泛定性和定量评估展示了最先进的结果，甚至可以超越商业深度传感器。此外，我们的方法可以显着缩小基于最先进学习的 6D 姿态估计算法的深度图的 Sim2Real 域差距。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10219021</guid>
      <pubDate>Tue, 15 Aug 2023 14:01:52 GMT</pubDate>
    </item>
    <item>
      <title>面向AUC的领域适应：从理论到算法</title>
      <link>http://ieeexplore.ieee.org/document/10214222</link>
      <description><![CDATA[ROC 曲线下面积 (AUC) 是机器学习的一个关键指标，对于疾病预测和欺诈检测等数据集通常表现出长尾性质的应用来说，这通常是一个合理的选择。然而，现有的大多数面向AUC的学习方法都假设训练数据和测试数据来自相同的分布。如何应对域名转移仍然存在广泛的争议。本文提出了一种攻击面向 AUC 的无监督域适应 (UDA)（以下简称 AUCUDA）的早期试验。具体来说，我们首先构建一个泛化界限，利用 AUC 的新分布差异。关键的挑战是 AUC 风险无法表示为独立损失项的总和，使得标准理论技术不可用。我们提出了一个新的结果，它不仅解决了相互依赖问题，而且还通过对损失函数的较弱假设带来了更清晰的界限。将理论付诸实践，原来的差异需要对目标域进行完整注释，这与 UDA 不兼容。为了解决这个问题，我们提出了一种伪标签策略并提出了一个端到端的训练框架。最后，对五个现实世界数据集的实证研究证明了我们框架的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10214222</guid>
      <pubDate>Thu, 10 Aug 2023 14:01:09 GMT</pubDate>
    </item>
    <item>
      <title>基于 HMM 的异常检测的对抗性数据增强</title>
      <link>http://ieeexplore.ieee.org/document/10210524</link>
      <description><![CDATA[在这项工作中，我们专注于检测在物理世界中运行的系统中的异常行为，并且通常不可能提前拥有所有可能异常的完整集合。我们提出了一种基于对抗性学习的数据增强和再训练方法，以改进异常检测。特别是，我们首先定义了一种基于隐马尔可夫模型（HMM）为异常检测器生成对抗性示例的方法。然后，我们提出了一种数据增强和再训练技术，该技术使用这些对抗性示例来提高异常检测性能。最后，我们在四个数据集上评估了我们的对抗性数据增强和再训练方法，表明它实现了统计上显着的性能改进，并增强了对抗性攻击的鲁棒性。与最先进的对抗性数据增强的主要区别在于对多变量时间序列（与图像相反）、一类分类的背景（与标准多类分类相反）的关注以及使用HMM（与神经网络相反）。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10210524</guid>
      <pubDate>Mon, 07 Aug 2023 14:03:35 GMT</pubDate>
    </item>
    <item>
      <title>实例相关标签噪声的参数化模型</title>
      <link>http://ieeexplore.ieee.org/document/10209198</link>
      <description><![CDATA[在标签噪声学习中，估计转移矩阵是一个热门话题，因为该矩阵在构建统计上一致的分类器中发挥着重要作用。传统上，从干净标签到噪声标签的转换（即干净标签转换矩阵（CLTM））已被广泛用于类相关标签噪声（其中干净类中的所有样本共享相同的标签转换矩阵）。然而，CLTM 无法很好地处理更常见的依赖于实例的标签噪声（其中需要通过考虑输入质量在实例级别估计干净到噪声的标签转换矩阵）。由于分类器大多输出贝叶斯最优标签进行预测，在本文中，我们研究直接建模从贝叶斯最优标签到噪声标签的过渡（即贝叶斯标签转换矩阵（BLTM））并学习分类器进行预测贝叶斯最优标签。请注意，仅给定噪声数据，估计 CLTM 或 BLTM 都是不合适的。但有利的是，贝叶斯最优标签与干净标签相比没有不确定性，即贝叶斯最优标签的类后验是one-hot向量，而干净标签的类后验不是。这使得估计 BLTM 具有两个优点，即（a）可以从噪声数据中收集一组理论上保证贝叶斯最优标签的示例； (b) 可行解空间小得多。通过利用这些优点，这项工作提出了一种参数模型，通过采用深度神经网络来估计实例相关的标签噪声转换矩阵，从而获得更好的泛化和卓越的分类性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10209198</guid>
      <pubDate>Fri, 04 Aug 2023 14:01:23 GMT</pubDate>
    </item>
    <item>
      <title>使用事件摄像机进行动作识别和基准测试</title>
      <link>http://ieeexplore.ieee.org/document/10198747</link>
      <description><![CDATA[近年来，基于视频的动作识别取得了令人瞩目的成就。除了传统的基于帧的相机之外，事件相机是仿生视觉传感器，仅记录像素级的亮度变化而不是亮度值。然而，在基于事件的动作识别方面却做得很少，而且大规模的公共数据集也几乎不可用。在本文中，我们提出了一种基于事件的动作识别框架，称为 EV-ACT。首次提出可学习多重融合表示（LMFR），以可学习的方式集成多个事件信息。具有双时间粒度的 LMFR 被馈送到基于事件的慢-快网络中，以融合外观和运动特征。引入时空注意力机制，进一步增强动作识别的学习能力。为了促进这一方向的研究，我们收集了最大的基于事件的动作识别基准，名为 THUE-ACT-50 以及具有挑战性的环境下随附的 THUE-ACT-50-CHL 数据集，包括来自 50 个动作类别的总共 12,830 多个记录，是之前最大数据集大小的 4 倍多。实验结果表明，与之前在四个基准上的工作相比，我们提出的框架可以实现超过 14.5%、7.6%、11.2% 和 7.4% 的改进。我们还在移动平台上部署了我们提出的 EV-ACT 框架，以验证其实用性和效率。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10198747</guid>
      <pubDate>Tue, 01 Aug 2023 14:04:37 GMT</pubDate>
    </item>
    <item>
      <title>CALDA：通过对比对抗性学习改进多源时间序列域适应</title>
      <link>http://ieeexplore.ieee.org/document/10192359</link>
      <description><![CDATA[无监督域适应 (UDA) 提供了一种在数据丰富（目标）域中提高机器学习性能的策略，这些域中的真实标签无法访问，但可以在相关（源）域中找到。在可以获得标签分布等元域信息的情况下，弱监督可以进一步提高性能。我们提出了一个新颖的框架 CALDA 来解决这两个问题。 CALDA 协同结合了对比学习和对抗学习的原理，以稳健地支持时间序列数据的多源 UDA (MS-UDA)。与之前的方法类似，CALDA 利用对抗性学习来对齐源和目标特征表示。与之前的方法不同，CALDA 还利用跨域的跨源标签信息。 CALDA 将具有相同标签的示例相互靠近，同时将具有不同标签的示例分开，通过对比学习重塑空间。与之前的对比适应方法不同，CALDA 既不需要数据增强，也不需要伪标记，这对于时间序列来说可能更具挑战性。我们凭经验验证了我们提出的方法。根据人类活动识别、肌电图和合成数据集的结果，我们发现利用跨源信息可以比之前的时间序列和对比方法提高性能。即使存在噪声，弱监督也能进一步提高性能，从而使 CALDA 能够为 MS-UDA 提供通用策略。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10192359</guid>
      <pubDate>Mon, 24 Jul 2023 14:02:24 GMT</pubDate>
    </item>
    </channel>
</rss>