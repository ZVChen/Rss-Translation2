<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 模式分析和机器智能汇刊 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物 TOC 提醒# 34</description>
    <lastBuildDate>Mon, 08 Jan 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>通过免训练和基于理论的指标理解和加速神经架构搜索</title>
      <link>http://ieeexplore.ieee.org/document/10337787</link>
      <description><![CDATA[这项工作的目标是设计一个原则性的、统一的、免训练的神经架构搜索（NAS）框架，具有高性能、低成本和深入的解释。 NAS 已被广泛研究以自动发现性能最佳的神经网络，但其资源消耗严重，并且经常因训练或近似被截断而产生搜索偏差。最近的 NAS 作品 Mellor 等人。 2021，陈等人。 2021，阿卜杜勒法塔等人。 2021年开始探索无需训练即可预测网络性能的指标。然而，他们要么利用了深度网络的有限特性，要么其免训练指标的好处没有应用于更广泛的搜索方法。通过严格的相关性分析，我们提出了一个统一的框架来理解和加速 NAS，通过解开搜索网络的“TEG”特征——可训练性、表达性、泛化性——所有这些特征都以免训练的方式进行评估。 TEG 指标可以扩展并与各种 NAS 搜索方法集成，包括超网和单路径 NAS 方法。广泛的研究验证了我们的 TEG-NAS 框架的有效和高效的指导，从而提高了搜索准确性并减少了 56% 以上的搜索时间成本。此外，我们将“TEG”特征的三个景观上的搜索轨迹可视化，观察到由于其简单的拓扑，在 NAS-Bench-201 上更容易找到良好的局部最小值，而在 DARTS 空间上平衡“TEG”特征则要困难得多，因为其复杂的景观几何形状。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10337787</guid>
      <pubDate>Fri, 01 Dec 2023 13:19:20 GMT</pubDate>
    </item>
    <item>
      <title>不流畅的合成目标语言数据改善神经机器翻译</title>
      <link>http://ieeexplore.ieee.org/document/10321682</link>
      <description><![CDATA[当可用于训练神经机器翻译的并行句子数量稀缺时，常见的做法是从中生成新的合成训练样本。已经提出了许多方法来生成与可用并行数据中的句子相似的合成并行句子。这些方法的工作原理是假设不流畅的目标端合成训练样本可能是有害的，并且可能会降低翻译性能。即便如此，在本文中，我们证明，如果将具有不流畅目标句子的合成训练样本像另一种语言的句子一样用于多语言机器翻译框架中，则可以提高翻译性能。我们对十个低资源和四个高资源翻译任务进行了实验，发现与生成类似于语料库中的合成训练样本的最先进方法相比，这种简单的方法持续提高了翻译性能。此外，这种改进与原始训练语料库的大小无关，所得系统对于域转移更加鲁棒，并且产生更少的幻觉。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10321682</guid>
      <pubDate>Fri, 17 Nov 2023 13:19:01 GMT</pubDate>
    </item>
    <item>
      <title>具有可控和自适应长度级别的图像字幕</title>
      <link>http://ieeexplore.ieee.org/document/10310015</link>
      <description><![CDATA[图像字幕是计算机视觉的核心挑战，引起了广泛关注。传统方法优先考虑字幕质量，往往忽视风格控制。我们的研究增强了方法的可控性，从而能够描述不同的细节。通过将长度级别嵌入集成到当前模型中，他们可以生成详细或简洁的标题，从而增加多样性。我们引入了长度级别的重新排序转换器来关联图像和文本的复杂性，优化标题长度以提供信息而无需冗余。此外，随着字幕长度的增加，由于现有方法的自回归（AR）设计，计算复杂性也会增加。为了解决这个问题，我们的非自回归 (NAR) 模型无论字幕长度如何都保持恒定的复杂性。我们开发了一种训练方法，包括细化序列训练和序列级知识蒸馏，以缩小 NAR 和 AR 模型之间的性能差距。在测试中，我们的模型为 MS COCO 数据集上的字幕质量设定了新标准，并提供了增强的可控性和多样性。我们的 NAR 模型在这些方面优于 AR 模型，并且在较长的字幕上显示出更高的效率。凭借先进的训练技术，我们的 NAR 的字幕质量可与领先的 AR 模型相媲美。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10310015</guid>
      <pubDate>Mon, 06 Nov 2023 13:18:22 GMT</pubDate>
    </item>
    <item>
      <title>可推广的异构联合互相关和实例相似性学习</title>
      <link>http://ieeexplore.ieee.org/document/10295990</link>
      <description><![CDATA[联邦学习是一种重要的隐私保护多方学习范式，涉及与他人的协作学习和私有数据的本地更新。模型异质性和灾难性遗忘是两个关键挑战，极大地限制了适用性和泛化性。本文提出了一种新颖的 FCCL+、联合相关性和非目标蒸馏的相似性学习，促进了域内可区分性和域间泛化。对于异构性问题，我们利用不相关的未标记的公共数据来进行异构参与者之间的通信。我们构建互相关矩阵并在逻辑和特征层面上对齐实例相似度分布，这有效地克服了通信障碍并提高了泛化能力。针对本地更新阶段的灾难性遗忘，FCCL+引入了联邦非目标蒸馏，在保留域间知识的同时避免优化冲突问题，通过描述后验类关系充分蒸馏特权域间信息。考虑到在相同设置下没有评估现有异构联邦学习的标准基准，我们提出了在四种领域转移场景下具有广泛代表性方法的综合基准，支持异构和同质联邦设置。实证结果证明了我们的方法的优越性和模块在各种场景下的效率。用于重现我们结果的基准代码可在 https://github.com/WenkeHuang/FCCL 上找到。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10295990</guid>
      <pubDate>Wed, 25 Oct 2023 13:16:36 GMT</pubDate>
    </item>
    <item>
      <title>使用图学习进行区块链数据挖掘：一项调查</title>
      <link>http://ieeexplore.ieee.org/document/10296043</link>
      <description><![CDATA[区块链数据挖掘有潜力揭示区块链系统中匿名参与者的运行状态和行为模式，从而为系统运行和参与者行为提供有价值的见解。然而，传统的区块链分析方法由于数据量大、结构复杂而存在无法处理的问题。图学习凭借强大的计算和分析能力，通过单独处理每个节点的特征和链接关系，从图的角度探索数据的隐含属性，可以解决当前的问题。本文系统地回顾了基于图学习方法的区块链数据挖掘任务。首先，我们研究了区块链数据获取方法，整合了当前可用的数据分析工具，并将采样方法分为基于规则和基于集群的技术。其次，我们将图构建分为基于交易的区块链和基于账户的方法，并综合分析现有的区块链特征提取方法。第三，我们比较了区块链上现有的图学习算法，并将其分为基于传统机器学习的方法、基于图表示的方法和基于图深度学习的方法。最后，我们提出了未来的研究方向和有希望解决的开放问题。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10296043</guid>
      <pubDate>Wed, 25 Oct 2023 13:16:36 GMT</pubDate>
    </item>
    <item>
      <title>具有多对多泼溅和空间选择性细化的视频帧插值</title>
      <link>http://ieeexplore.ieee.org/document/10294102</link>
      <description><![CDATA[在这项工作中，我们首先提出了一个完全可微的多对多（M2M）splatting框架来有效地插值帧。给定帧对，我们估计多个双向流，以在融合任何重叠像素之前将像素直接转发到所需的时间步长。这样做时，每个源像素渲染多个目标像素，并且每个目标像素可以从更大的视觉上下文区域合成，从而建立对不良伪影具有鲁棒性的多对多泼溅方案。对于每个输入帧对，M2M 在插入任意数量的中间帧时具有极小的计算开销，从而实现快速多帧插值。然而，直接扭曲和融合强度域中的像素对运动估计的质量敏感，并且可能会受到较低有效表示能力的影响。为了提高插值精度，我们通过引入灵活的空间选择性细化（SSR）组件进一步扩展了 M2M++ 框架，该组件允许以计算效率换取插值质量，反之亦然。 SSR 不细化整个插值帧，而是仅处理在估计误差图的指导下选择的困难区域，从而避免冗余计算。对多个基准数据集的评估表明，我们的方法能够在保持有竞争力的视频插值质量的同时提高效率，并且可以根据需要调整以使用更多或更少的计算。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10294102</guid>
      <pubDate>Tue, 24 Oct 2023 13:17:55 GMT</pubDate>
    </item>
    <item>
      <title>无监督光流中的成本函数展开</title>
      <link>http://ieeexplore.ieee.org/document/10294105</link>
      <description><![CDATA[最速下降算法常用于深度学习，使用梯度作为下降方向，可以按原样使用，也可以在使用预处理进行方向转换后使用。在许多场景中，由于复杂或不可微的成本函数，特别是在奇异点附近，计算梯度在数值上是困难的。这个问题通常可以通过增加 DNN 模型大小和复杂性来克服。在这项工作中，我们提出了一种称为“成本展开”的新颖机制，用于提高给定 DNN 模型求解复杂成本函数的能力，而无需修改其架构或增加计算复杂性。我们重点关注无监督成本函数中常用的总变分 (TV) 平滑度约束的推导。我们引入了 TV 平滑度约束的迭代可微替代方案，事实证明，它可以在训练期间产生更稳定的梯度，实现更快的收敛并改进给定 DNN 模型的预测。我们在多项任务中测试我们的方法，包括图像去噪和无监督光流。在 DNN 训练期间用损失替换 TV 平滑度约束，我们报告了所有测试场景中的改进结果。具体来说，我们的方法改进了在遮挡区域预测的流量，这本身就是一项关键任务，从而产生更清晰的运动边界。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10294105</guid>
      <pubDate>Tue, 24 Oct 2023 13:17:55 GMT</pubDate>
    </item>
    <item>
      <title>具有稀疏用户交互的深度图像抠图</title>
      <link>http://ieeexplore.ieee.org/document/10290984</link>
      <description><![CDATA[图像抠图是计算机视觉和图形学中的一个基本且具有挑战性的问题。大多数现有的抠图方法利用用户提供的三元贴图作为辅助输入来生成良好的 alpha 遮罩。然而，获得高质量的三维地图本身是很困难的。最近，出现了一些无提示的方法，但是，抠图质量仍然远远落后于基于 trimap 的方法。主要原因是，一些消除语义歧义和提高抠图质量的提示是必不可少的。显然，交互成本和抠图质量之间存在权衡。为了平衡性能和用户友好性，我们提出了一种改进的深度图像抠图框架，该框架是无三分图的，只需要稀疏的用户点击或涂鸦交互，以最大限度地减少所需的辅助约束，同时仍然允许交互性。此外，我们引入了不确定性估计，可以预测哪些零件需要抛光并进行不确定性引导的细化。为了权衡运行时间和细化质量，用户还可以选择不同的细化模式。实验结果表明，我们的方法比现有的无 trimap 方法表现更好，并且与最先进的基于 trimap 的方法相比，只需最少的用户工作量。最后，我们通过添加基于光流的稀疏提示传播和对单帧施加的时间一致性正则化，展示了我们的框架在没有任何结构修改的情况下对视频人体抠图的可扩展性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10290984</guid>
      <pubDate>Mon, 23 Oct 2023 13:20:50 GMT</pubDate>
    </item>
    <item>
      <title>细分非对抗性生成自动编码器的潜在空间</title>
      <link>http://ieeexplore.ieee.org/document/10288226</link>
      <description><![CDATA[非对抗性生成模型相对容易训练，并且比对抗性模型具有更少的模式崩溃。然而，它们在近似潜在空间中的目标分布方面并不是很准确，因为它们没有鉴别器。为此，我们开发了一种名为 Tessellated Wasserstein Auto-Encoders (TWAE) 的新型分而治之模型，该模型在逼近目标分布时具有较小的统计误差。 TWAE 使用质心 Voronoi 曲面细分 (CVT) 技术将目标分布的支持曲面细分为给定数量的区域，并根据曲面细分而不是随机改组来设计数据批次，以准确计算差异。理论上，我们证明，随着样本数量 $n$n 和镶嵌区域 $m$m 以 $\mathcal {O}(\frac{1}{\sqrt分别为 {n}})$O(1n) 和 $\mathcal {O}(\frac{1}{\sqrt{m}})$O(1m)。 TWAE 对于不同的非对抗性指标非常灵活，与现有指标相比，可以显着提高其在 Fréchet 起始距离（FID）方面的生成性能。此外，数值结果表明，TWAE 与对抗模型相比具有竞争力，并显示出强大的生成能力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10288226</guid>
      <pubDate>Thu, 19 Oct 2023 13:16:38 GMT</pubDate>
    </item>
    <item>
      <title>COLD Fusion：用于不确定性感知多模态情感识别的校准和有序潜在分布融合</title>
      <link>http://ieeexplore.ieee.org/document/10287630</link>
      <description><![CDATA[自动识别面部和声音中的明显情绪很困难，部分原因是各种不确定性来源，包括输入数据和机器学习框架中使用的标签。本文介绍了一种不确定性感知的多模态融合方法，该方法可以量化情绪预测的模态任意或数据不确定性。我们提出了一种新颖的融合框架，其中通过限制单峰时间上下文的潜在分布来学习它们的方差。这些方差约束、校准和序数排序的设计使得为模态估计的方差可以表示该模态的时间上下文的信息量。情感识别。经过良好校准后，模态不确定性分数表明其相应的预测可能与真实标签有多大差异。排名良好的不确定性分数允许对不同模式的不同框架进行顺序排名。为了共同施加这两个约束，我们提出了 softmax 分布匹配损失。我们对 AVEC 2019 CES、CMU-MOSEI 和 IEMOCAP 数据集的评估表明，所提出的多模态融合方法不仅提高了情感识别模型及其预测不确定性估计的泛化性能，而且使模型对测试中遇到的新噪声模式具有鲁棒性时间。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10287630</guid>
      <pubDate>Wed, 18 Oct 2023 13:16:57 GMT</pubDate>
    </item>
    <item>
      <title>用于零样本学习的解释性对象部分聚合</title>
      <link>http://ieeexplore.ieee.org/document/10287616</link>
      <description><![CDATA[零样本学习（ZSL）旨在仅基于已见类别中的标记图像来识别未见类别中的对象。大多数现有的 ZSL 方法都专注于优化特征空间或生成未见过的类的视觉特征，无论是在传统 ZSL 还是广义零样本学习 (GZSL) 中。然而，由于学习到的特征空间不是最优的，因此存在许多视觉特征和语义属性彼此不对应的虚拟连接。为了减少虚拟连接，在本文中，我们提出通过基于卷积特征图构建解释图来发现全面且细粒度的对象部分，然后聚合对象部分以训练部分网络以获得预测结果。由于聚合的对象部分包含用于激活语义属性的全面视觉特征，因此可以很大程度上减少虚拟连接。由于part-net旨在提取局部细粒度的视觉特征，因此忽略了与全局结构相关的一些属性。为了利用局部和全局视觉特征，我们设计了一个特征提取器，将局部特征提取到一个旨在提取全局特征的主网络中。 AWA2、CUB、FLO 和 SUN 数据集上的实验结果表明，我们提出的方法在传统 ZSL 和 GZSL 任务中明显优于现有技术。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10287616</guid>
      <pubDate>Wed, 18 Oct 2023 13:16:57 GMT</pubDate>
    </item>
    <item>
      <title>从 2D GAN 数据渐进学习 3D 重建网络</title>
      <link>http://ieeexplore.ieee.org/document/10286100</link>
      <description><![CDATA[本文提出了一种从单个图像重建高质量纹理 3D 模型的方法。当前的方法依赖于带有昂贵注释的数据集；多视图图像及其相机参数。我们的方法依赖于 GAN 生成的多视图图像数据集，其注释成本可以忽略不计。然而，它们并不是严格的多视图一致，有时 GAN 会输出扭曲的图像。这导致重建质量下降。在这项工作中，为了克服生成数据集的这些限制，我们有两个主要贡献，使我们在具有挑战性的对象上取得了最先进的结果：1）一个强大的多阶段学习方案，逐渐更多地依赖于模型计算损失时自己的预测；2）一种新颖的对抗性学习管道，具有在线伪地面实况生成，以实现精细细节。我们的工作提供了从 GAN 模型的 2D 监督到 3D 重建模型的桥梁，并消除了昂贵的注释工作。无论是在 GAN 生成的多视图图像上还是在具有昂贵注释的真实图像上进行训练，我们都比以前的方法有了显着的改进。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10286100</guid>
      <pubDate>Mon, 16 Oct 2023 13:17:29 GMT</pubDate>
    </item>
    <item>
      <title>用于混合事件帧相机的异步线性滤波器架构</title>
      <link>http://ieeexplore.ieee.org/document/10238826</link>
      <description><![CDATA[事件摄像机非常适合捕捉高动态范围 (HDR) 视觉信息而不模糊，但对于静态或缓慢变化的场景的成像能力较差。相反，传统图像传感器可以有效测量缓慢变化场景的绝对强度，但在 HDR 或快速变化场景上表现不佳。在本文中，我们提出了一种异步线性滤波器架构，融合事件和帧相机数据，用于 HDR 视频重建和空间卷积，利用两种传感器模式的优势。关键思想是引入一种状态，该状态直接对集成或卷积图像信息进行编码，并且随着每个事件或每个帧从相机到达而异步更新。可以根据需要随时读取状态，并将其输入到实时机器人系统的后续视觉模块中。我们的实验结果是在具有挑战性的光照条件和快速运动的公开数据集以及我们提供的带有 HDR 参考的新数据集上进行评估的。所提出的 AKF 管道在绝对强度误差（减少 69.4%）和图像相似性指数（平均提高 35.5%）方面均优于其他最先进的方法。我们还演示了图像卷积与线性空间核高斯、索贝尔和拉普拉斯的集成，作为我们架构的应用。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10238826</guid>
      <pubDate>Mon, 04 Sep 2023 14:03:21 GMT</pubDate>
    </item>
    <item>
      <title>OPAL：用于无监督光场视差估计的遮挡模式感知损失</title>
      <link>http://ieeexplore.ieee.org/document/10185573</link>
      <description><![CDATA[光场视差估计是计算机视觉中的一项重要任务。目前，基于监督学习的方法比无监督和基于优化的方法取得了更好的性能。然而，在没有真实数据可用于训练的情况下，监督方法对现实世界数据的泛化能力仍然有限。在本文中，我们认为无监督方法不仅可以在现实世界数据上实现更强的泛化能力，而且可以在合成数据集上获得更准确的视差估计结果。为了实现这一目标，我们提出了遮挡模式感知损失（Occlusion Pattern Aware Loss），名为 OPAL，它成功地提取和编码光场中固有的一般遮挡模式，以计算视差损失。 OPAL 能够：i) 通过教导网络如何有效处理遮挡来实现准确且稳健的视差估计，以及 ii) 显着减少准确且高效估计所需的网络参数。我们进一步提出了 EPI 转换器和基于梯度的细化模块，以实现更准确和像素对齐的视差估计结果。大量实验表明，与SOTA无监督方法相比，我们的方法不仅显着提高了准确性，而且与SOTA监督方法相比，对现实数据具有更强的泛化能力。最后但并非最不重要的一点是，网络训练和推理效率远高于现有的基于学习的方法。我们的代码将公开。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10185573</guid>
      <pubDate>Tue, 18 Jul 2023 14:02:08 GMT</pubDate>
    </item>
    <item>
      <title>残差神经网络中的扩散机制：理论与应用</title>
      <link>http://ieeexplore.ieee.org/document/10114599</link>
      <description><![CDATA[扩散是许多物理过程中出现的一种基本内部机制，描述了不同物体之间的相互作用。在许多训练样本有限的学习任务中，扩散连接了标记和未标记的数据点，是实现高分类精度的关键组成部分。许多现有的深度学习方法在训练神经网络时直接施加融合损失。在这项工作中，受对流扩散常微分方程（ODE）的启发，我们提出了一种新颖的扩散残差网络（Diff-ResNet），在神经网络架构中内部引入扩散。在结构化数据假设下，证明所提出的扩散块可以增加距离直径比，从而提高类间点的可分离性并减少局部类内点之间的距离。此外，残差网络可以很容易地利用这一特性来构造可分离的超平面。在各种数据集中进行的综合二元分类、半监督图节点分类和少样本图像分类的大量实验验证了该方法的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10114599</guid>
      <pubDate>Tue, 02 May 2023 14:08:15 GMT</pubDate>
    </item>
    </channel>
</rss>