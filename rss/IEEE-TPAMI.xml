<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 模式分析与机器智能学报 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物 # 34 的目录提醒</description>
    <lastBuildDate>Wed, 04 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用于图像和点云非配对恢复的无监督退化表征学习</title>
      <link>http://ieeexplore.ieee.org/document/10738507</link>
      <description><![CDATA[低级视觉中的恢复任务旨在从低质量 (LQ) 观测中恢复高质量 (HQ) 数据。为了规避在实际场景中获取配对数据的困难，旨在仅在非配对数据上恢复 HQ 数据的非配对方法引起了越来越多的关注。由于恢复任务与退化模型紧密耦合，实际场景中未知且高度多样化的退化使得从非配对数据中学习相当具有挑战性。在本文中，我们提出了一种退化表示学习方案来应对这一挑战。通过学习区分表示空间中的各种退化，我们的退化表示可以以无监督的方式提取隐式退化信息。此外，为了处理不同的退化，我们开发了退化感知 (DA) 卷积，可以灵活地适应各种退化，以充分利用学习到的表示中的退化信息。基于我们的退化表示和 DA 卷积，我们为非配对恢复任务引入了一个通用框架。基于我们的框架，我们分别针对非配对图像和点云恢复任务提出了 UnIRnet 和 UnPRnet。结果表明，我们的退化表示学习方案可以提取判别性表示以获得准确的退化信息。在非配对图像和点云恢复任务上的实验表明，我们的 UnIRnet 和 UnPRnet 实现了最佳性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10738507</guid>
      <pubDate>Wed, 30 Oct 2024 13:17:21 GMT</pubDate>
    </item>
    <item>
      <title>EventHDR：从事件到高速 HDR 视频及其他</title>
      <link>http://ieeexplore.ieee.org/document/10713104</link>
      <description><![CDATA[事件相机是一种创新的神经形态传感器，可以异步捕捉场景动态。由于事件触发机制，与传统相机相比，此类相机记录事件流的响应延迟更短，强度灵敏度更高。基于这些特点，以前的研究尝试从事件中重建高动态范围 (HDR) 视频，但要么出现不切实际的伪影，要么无法提供足够高的帧速率。在本文中，我们提出了一种循环卷积神经网络，可以从事件序列中重建高速 HDR 视频，并使用关键帧引导来防止稀疏事件数据导致的潜在错误积累。此外，为了解决真实数据集严重有限的问题，我们开发了一种新的光学系统来收集具有成对高速 HDR 视频和事件流的真实数据集，以促进该领域的未来研究。我们的数据集为事件到 HDR 重建提供了第一个真实的成对数据集，避免了模拟策略可能带来的不准确性。实验结果表明，我们的方法可以生成高质量、高速的 HDR 视频。我们进一步探索我们的工作在跨摄像头重建和下游计算机视觉任务中的潜力，包括对象检测、全景分割、光流估计和 HDR 场景下的单目深度估计。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10713104</guid>
      <pubDate>Wed, 09 Oct 2024 13:17:29 GMT</pubDate>
    </item>
    <item>
      <title>在部分客户端参与的情况下稳定和加速异构数据的联邦学习</title>
      <link>http://ieeexplore.ieee.org/document/10696955</link>
      <description><![CDATA[联邦学习 (FL) 通常鼓励客户端在全局聚合之前执行多次局部更新，从而避免频繁的模型交换并缓解服务器和客户端之间的通信瓶颈。虽然经验上有效，但多次局部更新对 FL 稳定性的负面影响尚未得到彻底研究，这可能导致全局不稳定和收敛缓慢。基于敏感性分析，我们在本文中定义了一般 FL 的局部更新稳定性指数，以多次局部更新后客户端间模型差异的最大值来衡量，这主要源于数据异质性。它可以确定具有多次局部更新的客户端模型的变化对全局模型的影响程度，也可以与收敛和泛化联系起来。我们从理论上推导出当前最先进的 FL 方法的局部更新稳定性，为从稳定性的新角度理解它们的动机和局限性提供了可能的见解。例如，在客户端本地天真地执行并行加速会损害局部更新稳定性。受此启发，我们基于服务器和客户端级 Nesterov 加速梯度 (NAG) 提出了一种新型加速但稳定的 FL 算法 (称为 FedANAG)。在 FedANAG 中，全局和局部动量经过精心设计并交替更新，而局部更新的稳定性借助全局动量得到增强。我们证明了 FedANAG 在强凸、一般凸和非凸设置下的收敛性。然后，我们对合成数据集和真实世界数据集进行评估，首先验证我们提出的局部更新稳定性。结果进一步表明，在不同的数据异构性和客户端参与率下，FedANAG 不仅通过将所需的通信轮数减少到目标精度来加速全局收敛，而且最终收敛到更高的精度。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10696955</guid>
      <pubDate>Thu, 26 Sep 2024 13:16:18 GMT</pubDate>
    </item>
    <item>
      <title>PSVMA+：探索广义零样本学习的多粒度语义视觉自适应</title>
      <link>http://ieeexplore.ieee.org/document/10693541</link>
      <description><![CDATA[广义零样本学习 (GZSL) 致力于利用来自可见领域的知识来识别看不见的类别，这需要视觉特征和属性语义特征之间的内在交互。然而，由于属性多样性和实例多样性，GZSL 的视觉语义对应性不足。属性多样性是指属性描述中不同的语义粒度，从低级（特定、直接可观察）到高级（抽象、高度通用）特征。这种多样性对在单粒度下收集足够的属性视觉线索提出了挑战。此外，对应于相同共享属性的不同视觉实例会引入语义歧义，导致模糊的视觉模式。为了解决这些问题，我们提出了一种多粒度渐进式语义视觉相互自适应 (PSVMA+) 网络，其中可以收集跨粒度级别的足够视觉元素来弥补粒度不一致的问题。 PSVMA+ 探索不同粒度级别的语义-视觉交互，从而能够感知视觉和语义元素中的多粒度。在每个粒度级别，双语义-视觉转换器模块 (DSVTM) 将共享属性重铸为以实例为中心的属性，并聚合与语义相关的视觉区域，从而学习明确的视觉特征以适应各种实例。鉴于不同粒度的不同贡献，PSVMA+ 采用选择性跨粒度学习来利用可靠粒度的知识，并自适应地融合多粒度特征以实现全面的表示。实验结果表明，PSVMA+ 始终优于最先进的方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10693541</guid>
      <pubDate>Wed, 25 Sep 2024 13:16:50 GMT</pubDate>
    </item>
    <item>
      <title>通过时空视图一致性进行弱监督单目 3D 物体检测</title>
      <link>http://ieeexplore.ieee.org/document/10689672</link>
      <description><![CDATA[单目 3D 物体检测在自动驾驶汽车领域发挥着至关重要的作用，它仅根据输入图像来估计物体的大小和位置。然而，3D 物体检测器的训练和推理之间存在显著差异。这种差异的出现是因为在推理过程中，单目 3D 检测器仅依赖于摄像机捕获的图像；而在训练过程中，这些方法需要标记在点云数据上的 3D 地面实况，而点云数据是使用 LiDAR 等专用设备获得的。这种差异导致数据循环中断，无法利用量产车的反馈数据来增强检测器的稳健性。为了解决这个问题并在数据循环中建立连接，我们提出了一种弱监督解决方案，仅使用 2D 标签训练单目 3D 物体检测器，从而无需 3D 地面实况。我们的方法考虑了两种视图一致性：空间和时间视图一致性，它们在调节 3D 边界框的预测方面起着至关重要的作用。空间视图一致性是通过使用投影和多视图一致性技术来指导目标位置和大小的优化来实现的。我们利用时间视点一致性来提供时间多视图图像对，并进一步引入时间运动一致性来应对动态场景的挑战。仅使用 2D 基本事实，我们的方法就实现了与全监督方法相当的性能。此外，我们的方法可以用作预训练方法，并且在使用一小部分全监督标签进行微调时实现了显着的改进。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10689672</guid>
      <pubDate>Tue, 24 Sep 2024 13:16:31 GMT</pubDate>
    </item>
    <item>
      <title>RoBoSS：用于监督学习的稳健、有界、稀疏且平滑的损失函数</title>
      <link>http://ieeexplore.ieee.org/document/10685140</link>
      <description><![CDATA[在机器学习领域，损失函数的重要性至关重要，尤其是在监督学习任务中。它是深刻影响监督学习算法行为和功效的基本支柱。传统的损失函数虽然被广泛使用，但通常难以处理容易出现异常值和高维数据，导致训练过程中的结果不理想且收敛速度缓慢。在本文中，我们通过为监督学习提出一种新的稳健、有界、稀疏和平滑 (RoBoSS) 损失函数来解决上述限制。此外，我们将 RoBoSS 损失纳入支持向量机 (SVM) 框架，并引入一种名为 $\mathcal {L}_{RoBoSS}$LRoBoSS-SVM 的新稳健算法。对于理论分析，还介绍了分类校准属性和泛化能力。这些研究对于更深入地了解 RoBoSS 损失函数在分类问题中的稳健性及其对未知数据的良好泛化潜力至关重要。为了验证所提出的 $\mathcal {L}_{RoBoSS}$LRoBoSS-SVM 的效力，我们在 KEEL 和 UCI 存储库中的 88 个基准数据集上对其进行了评估。此外，为了严格评估其在具有挑战性的场景中的表现，我们使用有意注入异常值和标签噪声的数据集进行了评估。此外，为了证明 $\mathcal {L}_{RoBoSS}$LRoBoSS-SVM 在生物医学领域的有效性，我们在两个医学数据集上对其进行了评估：脑电图 (EEG) 信号数据集和乳腺癌 (BreaKHis) 数据集。数值结果证实了所提出的 $\mathcal {L}_{RoBoSS}$LRoBoSS-SVM 模型的优越性，无论是在其卓越的泛化性能方面，还是在训练时间效率方面。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10685140</guid>
      <pubDate>Fri, 20 Sep 2024 13:15:59 GMT</pubDate>
    </item>
    <item>
      <title>事件增强快照马赛克高光谱帧去模糊</title>
      <link>http://ieeexplore.ieee.org/document/10684998</link>
      <description><![CDATA[快照马赛克高光谱相机 (SMHC) 是一种流行的高光谱成像设备，用于获取场景的颜色和运动细节。然而，SMHC 中的窄带光谱滤波器可能会对其运动感知能力产生负面影响，导致 SMHC 帧模糊。在本文中，我们提出了一种硬件-软件协作方法来解决 SMHC 的模糊问题。我们的方法涉及将 SMHC 与神经形态事件相机集成，以实现高效的事件增强型 SMHC 帧去模糊。为了实现由事件信号引导的光谱信息恢复，我们制定了一个光谱感知的基于事件的双重积分 (sEDI) 模型，该模型从光谱角度链接 SMHC 帧和事件，提供原则性的模型设计见解。然后，我们开发了一个扩散引导的噪声感知 (DNA) 训练框架，该框架利用扩散模型来学习噪声感知特征并提高模型对相机噪声的鲁棒性。此外，我们基于 sEDI 设计了一个事件增强型高光谱帧去模糊网络 (EvHDNet)，该网络使用 DNA 进行训练，具有改进的空间光谱学习和模态交互功能，可实现可靠的 SMHC 帧去模糊。对合成数据和真实数据的实验表明，所提出的 DNA + EvHDNet 在空间和光谱保真度方面均优于最先进的方法。代码和数据集将公开发布。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10684998</guid>
      <pubDate>Fri, 20 Sep 2024 13:15:59 GMT</pubDate>
    </item>
    <item>
      <title>T2TD：基于先验知识指导的文本-3D生成模型</title>
      <link>http://ieeexplore.ieee.org/document/10684147</link>
      <description><![CDATA[近年来，3D模型被广泛应用于自动驾驶、3D重建、VR、AR等诸多领域，然而3D模型数据的稀缺性无法满足实际需求，因此，从文本描述中高效地生成高质量的3D模型是一种很有前途但又充满挑战性的解决方式。本文受到人类想象力的创造机制的启发，提出了一种新颖的文本-3D生成模型（T2TD），该模型具体地从建立在人类经验知识基础上的模糊描述中补充目标模型。T2TD旨在借助经验知识基于文本描述生成目标模型。其目标创建过程模拟了人类的想象机制。在此过程中，我们首先引入文本-3D知识图谱来保留3D模型与文本语义信息之间的关系，从而提供类似人类经验信息的相关形状。其次，我们提出了一个有效的因果推理模型，从这些相关形状中选择有用的特征信息，该模型可以删除不相关的结构信息，仅保留与文本描述强相关的特征信息。第三，我们采用一种新颖的多层 Transformer 结构来逐步融合这种强相关的结构信息和文本信息，弥补结构信息的不足，并提高 3D 生成模型的最终性能。最终的实验结果表明，我们的方法显著提高了 3D 模型生成质量，并且在 text2shape 数据集上的表现优于 SOTA 方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10684147</guid>
      <pubDate>Wed, 18 Sep 2024 13:17:36 GMT</pubDate>
    </item>
    <item>
      <title>深度时空网络中静态与动态信息的量化与学习</title>
      <link>http://ieeexplore.ieee.org/document/10682100</link>
      <description><![CDATA[人们对深度时空模型在其中间表示中捕获的信息的理解有限。例如，虽然有证据表明动作识别算法受到单帧视觉外观的严重影响，但没有定量方法来评估潜在表示中的这种静态偏差与动态偏差的比较。我们通过提出一种量化任何时空模型的静态和动态偏差的方法来应对这一挑战，并将我们的方法应用于三个任务，即动作识别、自动视频对象分割 (AVOS) 和视频实例分割 (VIS)。我们的主要发现是：(i) 大多数检查的模型都偏向静态信息。(ii) 一些被认为偏向动态的数据集实际上偏向静态信息。(iii) 架构中的各个通道可以偏向静态、动态或联合编码静态和动态信息的组合。(iv) 大多数模型在训练的前半部分收敛到它们的最终偏差。然后，我们探讨这些偏差如何影响动态偏差数据集上的性能。对于动作识别，我们提出了 StaticDropout，这是一种语义引导的 dropout，可使模型从静态信息向动态信息偏移。对于 AVOS，与以前的架构相比，我们设计了更好的融合层和交叉连接层组合。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10682100</guid>
      <pubDate>Tue, 17 Sep 2024 13:16:57 GMT</pubDate>
    </item>
    <item>
      <title>提示和传输：针对小样本分割的动态类别感知增强</title>
      <link>http://ieeexplore.ieee.org/document/10681253</link>
      <description><![CDATA[为了更有效地推广到看不见的领域（类别），大多数小样本分割 (FSS) 会直接利用预训练的编码器并仅微调解码器，尤其是在当前大型模型时代。然而，这种固定特征编码器往往与类别无关，不可避免地会激活与目标类别无关的对象。相比之下，人类可以毫不费力地将注意力集中在视线内的特定物体上。本文模仿人类的视觉感知模式，提出了一种新颖而强大的提示驱动方案，称为“提示和迁移”（PAT），它构建了一个动态的类别感知提示范式来调整编码器以专注于当前任务中感兴趣的对象（目标类别）。阐述了三个关键点以增强提示：1）引入跨模态语言信息来初始化每个任务的提示。2）语义提示迁移 (SPT)，将图像中的类别特定语义精确地迁移到提示中。 3) 部分掩码生成器 (PMG) 与 SPT 配合使用，针对不同的个体自适应地生成不同但互补的部分提示。令人惊讶的是，PAT 在 4 个不同的任务上取得了有竞争力的表现，包括标准 FSS、跨域 FSS（例如，CV、医疗和遥感领域）、弱标签 FSS 和零样本分割，在 11 个基准上创下了新的最佳水平。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10681253</guid>
      <pubDate>Tue, 17 Sep 2024 13:16:56 GMT</pubDate>
    </item>
    <item>
      <title>用于判别性人物搜索的原型引导注意力蒸馏</title>
      <link>http://ieeexplore.ieee.org/document/10681282</link>
      <description><![CDATA[人物搜索旨在从多个不重叠的摄像头拍摄的大型图库中定位感兴趣的人物。流行的统一方法存在以下问题：(1) 噪声提案导致误检和遮挡，以及 (2) 类内外观差异大，这会降低基于原型的度量学习效果。为了解决这些问题，我们引入了原型引导注意力蒸馏，简称 PAD，它利用原型（身份的典型表示）作为注意力模块的指导，以在不同姿势中一致地突出显示身份固有区域。为了利用原型中编码的知识来匹配未见过的 ID，PAD 通过深度模仿原型查询中的注意力图来进行注意力蒸馏，以指导学生的 Re-ID 查询。此外，为了解决由姿势或摄像头视图引起的类内差异大的问题，我们扩展了 PAD，使用多个部分原型来表示不同实例中一致的局部区域。此外，我们利用自适应动量策略在 PAD 中进行稳健的注意力蒸馏，以更新更多不同的原型。在 CUHK-SYSU 和 PRW 上进行的大量实验证明了 PAD 的有效性，展现了最先进的性能。此外，我们的提炼注意力机制出人意料地突出了人物搜索中的多个显著区域。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10681282</guid>
      <pubDate>Mon, 16 Sep 2024 13:17:33 GMT</pubDate>
    </item>
    <item>
      <title>集成传输和基于查询的攻击框架中的潜在变量优化</title>
      <link>http://ieeexplore.ieee.org/document/10681296</link>
      <description><![CDATA[黑盒对抗攻击可以分为基于转移的攻击和基于查询的攻击。前者由于模型架构不匹配通常具有较差的转移性能，而基于查询的攻击需要大量查询和高维的优化变量。为了解决上述问题，我们提出了一种新型的攻击框架，融合了基于转移和基于查询的攻击的优点，该框架分为两个阶段：训练对抗生成器和执行黑盒攻击。在第一阶段，通过对抗损失函数训练生成器，使其能够输出对抗扰动，其中隐变量被设计为生成器的输入以降低优化变量的维度。在第二阶段，基于训练好的生成器，我们进一步采用粒子群优化算法来优化隐变量，使得生成器能够输出能够实现成功攻击的扰动。在 ImageNet 数据集上进行了大量的实验，结果表明，与许多最先进的黑盒对抗攻击方法相比，所提出的框架可以获得更好的攻击性能。此外，我们通过扩展少像素攻击实验展示了所提出的框架的灵活性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10681296</guid>
      <pubDate>Mon, 16 Sep 2024 13:17:33 GMT</pubDate>
    </item>
    <item>
      <title>通过残差移位进行图像恢复的有效扩散模型</title>
      <link>http://ieeexplore.ieee.org/document/10681246</link>
      <description><![CDATA[虽然基于扩散的图像恢复 (IR) 方法取得了显著的成功，但它们仍然受到推理速度慢的限制，这是由于需要执行数百甚至数千个采样步骤。现有的加速采样技术虽然试图加快这一过程，但不可避免地在一定程度上牺牲性能，导致恢复结果过于模糊。为了解决这个问题，本研究提出了一种新颖而有效的 IR 扩散模型，可显著减少所需的扩散步骤数。我们的方法避免了推理过程中对后加速的需要，从而避免了相关的性能下降。具体而言，我们提出的方法建立了一个马尔可夫链，通过移动它们的残差来促进高质量和低质量图像之间的转换，大大提高了转换效率。设计了一个精心制定的噪声计划，以灵活控制扩散过程中的移动速度和噪声强度。大量的实验评估表明，即使只有四个采样步骤，所提出的方法在四个经典的 IR 任务（即图像超分辨率、图像修复、盲脸修复和图像去模糊）上也实现了优于或与当前最先进的方法相当的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10681246</guid>
      <pubDate>Mon, 16 Sep 2024 13:17:27 GMT</pubDate>
    </item>
    <item>
      <title>用于视频异常检测和预测的潜在空间场景相关预测</title>
      <link>http://ieeexplore.ieee.org/document/10681297</link>
      <description><![CDATA[视频异常检测 (VAD) 在智能监控中起着至关重要的作用。然而，一种名为场景相关异常的重要异常类型却被忽视了。此外，视频异常预测 (VAA) 的任务也值得关注。为了填补这些空白，我们建立了一个名为 NWPU Campus 的综合数据集，它是最大的半监督 VAD 数据集，也是第一个场景相关 VAD 和 VAA 的数据集。同时，我们为场景相关 VAD 和 VAA 引入了一种新颖的前向-后向框架，其中前向网络单独解决 VAD，并与后向网络联合解决 VAA。具体来说，我们为前向和后向网络提出了一个潜在空间中的场景相关生成模型。首先，我们提出了一个分层变分自动编码器来提取场景通用特征。接下来，我们在潜在空间中设计一个基于分数的扩散模型，以将这些特征细化得更紧凑，以完成任务，并使用场景信息自动编码器生成场景相关特征，对视频事件和场景之间的关系进行建模。最后，我们开发了关键帧的时间损失来约束视频片段的运动一致性。大量实验表明，我们的方法可以很好地处理场景相关的异常检测和预测，在上海科技大学、香港中文大学大道和拟议的西北工业大学校园数据集上实现了最先进的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10681297</guid>
      <pubDate>Mon, 16 Sep 2024 13:17:27 GMT</pubDate>
    </item>
    <item>
      <title>用于超图归纳学习的自适应神经信息传递</title>
      <link>http://ieeexplore.ieee.org/document/10612216</link>
      <description><![CDATA[图是用于表示关系数据集并在其中执行推理的最普遍的数据结构。然而，它们仅对节点之间的成对关系进行建模，并非为编码高阶关系而设计。超图可以缓解这一缺点，其中一条边可以连接任意数量的节点。大多数超图学习方法将超图结构转换为图的结构，然后部署现有的几何深度学习方法。这种转换会导致信息丢失，并且无法充分利用超图的表达能力。我们提出了 HyperMSG，这是一种新颖的超图学习框架，它使用模块化两级神经消息传递策略准确高效地在每个超边内和跨超边传播信息。HyperMSG 通过学习与每个节点的度中心性相关的注意力权重来适应数据和任务。这种机制量化了节点的局部和全局重要性，捕捉了超图的结构属性。HyperMSG 是归纳性的，允许对以前看不见的节点进行推理。此外，它非常稳健，在各种任务和数据集上的表现都优于最先进的超图学习方法。最后，我们通过对具有挑战性的多媒体数据集进行详细实验，证明了 HyperMSG 在学习多模态关系方面的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10612216</guid>
      <pubDate>Fri, 26 Jul 2024 13:17:22 GMT</pubDate>
    </item>
    </channel>
</rss>