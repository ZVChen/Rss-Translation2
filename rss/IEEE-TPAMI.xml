<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 模式分析与机器智能学报 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>TOC警报出版＃34</description>
    <lastBuildDate>Wed, 05 Feb 2025 05:00:00 GMT</lastBuildDate>
    <item>
      <title>用于学习迭代模型的深度损失凸化</title>
      <link>http://ieeexplore.ieee.org/document/10777605</link>
      <description><![CDATA[由于非convex优化的性质，迭代方法（例如，迭代的最接近点（ICP））通常会遭受不良的局部最优性（例如，马鞍点）。为了应对这一基本挑战，在本文中，我们建议学习形成深层迭代方法W.R.T.的损失格局。得益于神经网络中的过度参数化，在鉴于数据的每个地面真理（即深度损耗凸）（即DLC）周围，测试时间的预测围绕每个地面真相的局部形状进行预测。为此，我们通过操纵基本真理预测而不是输入数据来基于对抗性培训来制定学习目标。特别是，我们建议使用星形识别性，这是一个结构化的非凸函数的家族，这些函数在通过全球最小化的所有线上都不是模态，因为我们对重塑损失景观的几何限制，导致（1）（1）附加到附加到额外的新型铰链损失到附加到附件原始损失和（2）几乎最佳的预测。我们使用DLC与现有网络体系结构进行了最新性能，用于培训复发性神经网络（RNN），3D点云注册和多模型图像对齐任务。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10777605</guid>
      <pubDate>Wed, 04 Dec 2024 13:17:52 GMT</pubDate>
    </item>
    <item>
      <title>DiffAct++：扩散动作分割</title>
      <link>http://ieeexplore.ieee.org/document/10772006</link>
      <description><![CDATA[了解长形视频需要精确的时间动作细分。尽管现有的研究通常采用遵循迭代改进过程的多阶段模型，但我们提出了一个基于降级扩散模型的新框架，该模型保留了该核心迭代原理。在此框架内，模型迭代产生动作预测，从随机噪声开始，以输入视频的特征为条件。为了有效捕获人类行为的三个关键特征，即先前的立场，边界歧义和关系依赖性，我们提出了针对调节特征的凝聚力掩盖策略。此外，提出了一致性梯度引导技术，该技术可最大程度地提高带有或不带掩盖的输出之间的相似性，从而在推理过程中丰富条件信息。大量实验在四个数据集上进行，即GTEA，50SALADS，早餐和汇编101。结果表明，我们提出的方法优于现有的最新技术，强调了生成方法的动作分割方法的潜力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10772006</guid>
      <pubDate>Fri, 29 Nov 2024 13:16:48 GMT</pubDate>
    </item>
    <item>
      <title>IBCS：学习信息瓶颈约束去噪因果子图进行图分类</title>
      <link>http://ieeexplore.ieee.org/document/10771715</link>
      <description><![CDATA[图形学习的重大成功激发了一项有意义但具有挑战性的任务，即提取可以解释和改善预测的确切因果子图。不幸的是，目前的作品仅集中在部分消除虚假或嘈杂的部分，同时忽略了一个事实，即在更实际和一般的情况下，无论是虚假和嘈杂的子图与因果关系。这带来了巨大的挑战，并使以前的方法无法提取真正的因果子结构。与现有的研究不同，在本文中，我们提出了一个更合理的问题制定，假设该图是因果，虚假和嘈杂的子图的混合物。在这方面，开发了信息瓶颈限制的因果关系子图（IBCS）学习模型，该模型能够同时排除虚假和嘈杂的部分。具体而言，对于虚假的相关性，我们设计了一个新颖的因果学习目标，其中除了最大程度地减少因果和虚假子图分类的经验风险之外，该干预措施进一步进行了伪造特征，以切断其与因果关系的相关性。在此基础上，我们进一步施加了信息瓶颈约束，以滤除标签 -  iRrex-relevant噪声信息。从理论上讲，我们证明由IBC提取的因果子图可以近似地面真相。从经验上讲，对九个基准数据集进行广泛的评估证明了我们优于最先进的基准。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10771715</guid>
      <pubDate>Thu, 28 Nov 2024 13:18:14 GMT</pubDate>
    </item>
    <item>
      <title>Anchor3Dlane ++：通过样品自适应稀疏3D锚回归的3D车道检测</title>
      <link>http://ieeexplore.ieee.org/document/10771714</link>
      <description><![CDATA[在本文中，我们专注于单眼3D车道检测的具有挑战性的任务。以前的方法通常采用反视角映射（IPM）将前视图（FV）图像或特征转换为鸟眼观察（BEV）空间以进行泳道检测。但是，IPM对BEV表示中的平坦地面假设和上下文信息丢失的依赖导致3D信息估计不准确。尽管已经努力绕过BEV并直接从FV表示中预测3D车道，但由于缺乏3D车道的结构化建模，它们的性能仍然落后于基于BEV的方法。在本文中，我们提出了一种名为Anchor3dlane ++的新型无BEV方法，该方法将3D车道锚定为结构表示，并直接从FV特征进行预测。我们还设计了一个基于原型的自适应锚定（PAAG）模块，以动态生成样品自适应稀疏3D锚。另外，开发出相等的宽度（EW）损失，以利用泳道的平行特性进行正规化。此外，还基于Anchor3Dlane ++探索了相机范围的融合，以利用互补信息。在三个流行的3D车道检测基准上进行的广泛实验表明，我们的Anchor3dlane ++的表现优于先前的最新方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10771714</guid>
      <pubDate>Thu, 28 Nov 2024 13:18:14 GMT</pubDate>
    </item>
    <item>
      <title>实用紧凑深度压缩感知</title>
      <link>http://ieeexplore.ieee.org/document/10763443</link>
      <description><![CDATA[近年来，深度网络在压缩感知 (CS) 领域取得了成功，它显著降低了采样成本，自诞生以来就受到越来越多的关注。在本文中，我们提出了一种新的实用紧凑网络，称为 PCNet，用于一般图像 CS。具体而言，在 PCNet 中，设计了一种新颖的协同采样算子，它由深度条件过滤步骤和双分支快速采样步骤组成。前者将线性变换矩阵的隐式表示学习为几个卷积，并首先对输入图像执行自适应局部滤波，而后者则使用离散余弦变换和加扰块对角高斯矩阵来生成欠采样测量值。我们的 PCNet 配备了增强型近端梯度下降算法展开网络用于重建。一旦经过训练，它就能为任意采样率提供灵活性、可解释性和强大的恢复性能。此外，我们还为单像素 CS 成像系统提供了一种面向部署的提取方案，允许将任何线性采样算子方便地转换为其矩阵形式，以便加载到数字微镜设备等硬件上。对自然图像 CS、量化 CS 和自监督 CS 进行的大量实验表明，与现有的最先进方法相比，PCNet 具有更优异的重建精度和泛化能力，尤其是对于高分辨率图像。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10763443</guid>
      <pubDate>Fri, 22 Nov 2024 13:16:35 GMT</pubDate>
    </item>
    <item>
      <title>以任务为导向的渠道注意细粒度分类</title>
      <link>http://ieeexplore.ieee.org/document/10763467</link>
      <description><![CDATA[细颗粒图像分类的困难主要来自跨班级的共同整体外观。因此，认识到歧视性细节，例如鸟类的眼睛和喙，是任务的关键。但是，当培训数据受到限制时，这尤其具有挑战性。为了解决这个问题，我们提出了任务差异最大化（TDM），这是一种面向任务的通道注意方法，该方法针对精细颗粒的几弹性分类量使用，其中有两个新型模块支持注意力模块（SAM）和查询注意模块（QAM）。 SAM突出显示了编码类别歧视性特征的通道，而QAM将更高的权重分配给查询的对象相关通道。基于这些子模型，TDM通过专注于编码类别歧视性细节的通道来产生任务自适应的功能，并同时使用查询，以提供支持和查询实例之间的准确类别敏感的相似度度量。尽管TDM通过任务自适应校准通道的重要性影响高级特征图，但我们进一步介绍了在特征提取器的中间层中运行的实例注意模块（IAM），以实例化突出显示对象与对象相关的通道，并扩展QAM。 TDM和IAM的优点及其互补益处在精细粒度的少量分类任务中得到了实验验证。此外，IAM在粗粒和跨域几乎没有分类中也有效。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10763467</guid>
      <pubDate>Thu, 21 Nov 2024 13:20:31 GMT</pubDate>
    </item>
    <item>
      <title>图像检索的相关性验证及其内存占用优化</title>
      <link>http://ieeexplore.ieee.org/document/10759842</link>
      <description><![CDATA[在本文中，我们提出了一个名为“相关验证网络”（CVNET）的新型图像检索网络，以用4D卷积神经网络替换传统的几何重新排列，该网络学习多样化的几何匹配可能性。为了启用有效的跨尺度匹配，我们构建特征金字塔并在单个推理中建立跨尺度特征相关性，从而替换了昂贵的多尺度推断。此外，我们采用捉迷藏策略的课程学习来处理具有挑战性的样本。我们提出的CVNET证明了在几个图像检索基准测试中的最新性能。但是，从实现角度来看，CVNET有一个缺点：它需要高内存使用情况，因为它需要存储所有数据库图像的密集特征。在实际应用中，这种高内存需求可能是一个重要的限制。为了解决此问题，我们引入了CVNET的扩展名，称为密集到SPARSE CVNET（CVNET $^{DS} $ DS），该扩展可以通过占用数据库图像的功能来大大减少内存使用情况。 CVNET $^{DS} $ DS中的稀疏模块学会使用Gumbel估算器端到端选择图像功能的相关部分。由于泄漏是离线执行的，因此CVNET $^{DS} $ DS不会增加在线提取和匹配时间。 cvnet $^{ds} $ ds会大大降低内存足迹，同时保持性能水平几乎相同。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10759842</guid>
      <pubDate>Thu, 21 Nov 2024 13:20:31 GMT</pubDate>
    </item>
    <item>
      <title>细粒度的视觉文本提示</title>
      <link>http://ieeexplore.ieee.org/document/10763465</link>
      <description><![CDATA[视觉语言模型 (VLM)，例如 CLIP，在零样本图像级视觉理解方面表现出色，但在需要精确定位和识别的基于对象的任务中却举步维艰。建议使用彩色框或圆圈等视觉提示来增强局部感知。然而，这些方法通常包含不相关和嘈杂的像素，导致性能不佳。更好的视觉提示的设计及其与文本提示的协作仍未得到充分探索。本文介绍了细粒度视觉文本提示 (FGVTP)，这是一种使用精确语义掩码和强化图像文本对齐的基于对象任务的新零样本框架。FGVTP 包括细粒度视觉提示 (FGVP) 和一致性增强文本提示 (CETP)。具体来说，我们通过探索更多形状和形式各异的视觉标记来仔细研究视觉提示设计。FGVP 使用来自分割器（如 Segment Anything Model (SAM)）的语义掩码，并采用背景模糊（模糊反向掩码）来突出显示目标，同时保持空间连贯性。此外，CETP 通过基于 FGVP 处理的图像提示字幕来增强图像文本对齐。因此，FGVTP 在 RefCOCO/+/g 基准上实现了卓越的零样本指代表达理解，平均比以前的 SOTA 方法高出 5.8%。在 PACO 数据集上进行的部分检测实验进一步验证了 FGVTP 相对于现有作品的优势。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10763465</guid>
      <pubDate>Thu, 21 Nov 2024 13:20:31 GMT</pubDate>
    </item>
    <item>
      <title>用于在线高性能成像和视觉的流式量子传感器</title>
      <link>http://ieeexplore.ieee.org/document/10758928</link>
      <description><![CDATA[最近，量子图像传感器 (QIS) - 超快、零读取噪声二进制图像传感器 - 在许多具有挑战性的场景中展示了卓越的成像能力。尽管它们具有潜力，但这些传感器的采用受到 (a) 高数据速率和 (b) 需要新的计算管道来处理非常规原始数据的严重阻碍。我们引入了一种简单的低带宽计算管道来应对这些挑战。我们的方法基于一种新颖的流式表示，具有较小的内存占用，可有效捕获多个时间尺度的强度信息。更新表示只需要 24 个浮点运算/像素，可以以二进制帧的原始帧速率在线高效计算。我们使用基于此表示的神经网络来实时重建视频（10-30 fps）。我们说明了为什么这种表示非常适合这些新兴传感器，以及它如何提供低延迟和高帧速率，同时为下游计算机视觉保留灵活性。我们的方法可显著减少数据带宽（约 100\times$∼100 倍），并且与现有的最先进方法（Ma et al. 2020）相比，实时图像重建和计算机视觉计算量可减少 $-10^{4}\text{-}10^{5} \times$-104-105 倍，同时保持同等质量。据我们所知，我们的方法是第一个在 QIS 上实现在线实时图像重建的方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10758928</guid>
      <pubDate>Wed, 20 Nov 2024 13:16:48 GMT</pubDate>
    </item>
    <item>
      <title>部分场景文本检索</title>
      <link>http://ieeexplore.ieee.org/document/10758313</link>
      <description><![CDATA[部分场景文本检索的任务涉及本地位置和搜索与图像库中给定查询文本相同或相似的文本实例。但是，现有方法只能处理文本行实例，而由于培训数据中缺乏补丁注释，因此在这些文本行实例中搜索部分补丁的问题。为了解决这个问题，我们提出了一个可以同时检索文本线实例及其部分补丁的网络。我们的方法将两种类型的数据（查询文本和场景文本实例）嵌入共享特征空间，并测量其跨模式相似性。为了处理部分补丁，我们提出的方法采用多个实例学习（MIL）方法来学习与查询文本的相似之处，而无需额外的注释。但是，构造袋子是常规MIL方法的标准步骤，可以引入许多嘈杂的样本进行训练，并降低推理速度。为了解决这个问题，我们提出了一种排名MIL（RANKMIL）的方法来适应过滤这些嘈杂的样本。此外，我们提出了一种动态的部分匹配算法（DPMA），该算法可以在推理阶段直接从文本行实例中直接搜索目标部分贴片，而无需袋子。这大大提高了搜索效率和检索部分补丁的性能。我们在两个任务中评估了英语和中文数据集的提议方法：检索文本线实例和部分补丁。对于英语文本检索，我们的方法在这两个任务的三个数据集中，我们的方法的平均地图分别超过8.04％的地图和平均12.71％的地图。对于中文文本检索，我们的方法超过了最新的方法24.45％地图和三个任务数据集中的平均地图分别超过了38.06％的地图。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10758313</guid>
      <pubDate>Tue, 19 Nov 2024 13:16:30 GMT</pubDate>
    </item>
    <item>
      <title>Bokehme ++：多功能散景的古典和神经渲染的和谐融合</title>
      <link>http://ieeexplore.ieee.org/document/10756626</link>
      <description><![CDATA[尽管在从全焦图像模拟数码单反相机 (DSLR) 的散景效果方面取得了重大进展，但在处理亮点、保留对焦物体的边界细节以及有效处理高分辨率图像方面仍然存在挑战。为了解决这些问题，我们首先开发了一个基于光线追踪的散景模拟器。引入了一种具有权重重新分配的创新管道来处理高光渲染。通过考虑镜筒的前长，我们可以模拟逼真的猫眼效果。这个散景模拟器是我们创建训练数据集的基础。在此数据集的基础上，我们引入了一个混合框架 BokehMe++，结合了经典渲染器和神经渲染器。经典渲染器是通过基于分层散射的方法实现的，该方法存在边界不准确的问题。这些错误区域将由错误图生成器识别，并由两阶段神经渲染器进行校正。神经渲染器中引入了自适应调整大小和迭代上采样，以有效处理任意模糊大小。大量实验表明，BokehMe++ 的表现优于现有方法，并提供高度可定制的渲染功能，例如可调节的模糊量、焦平面、高光模式和猫眼效果。此外，BokehMe++ 可以通过辅助 alpha 贴图输入保持肖像中头发细节的清晰度。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10756626</guid>
      <pubDate>Mon, 18 Nov 2024 13:16:41 GMT</pubDate>
    </item>
    <item>
      <title>超越持续学习的深度学习遗忘综合调查</title>
      <link>http://ieeexplore.ieee.org/document/10752992</link>
      <description><![CDATA[遗忘是指先前获得的知识的丢失或退化。虽然现有的关于遗忘的研究主要集中在持续学习上，但遗忘是深度学习中其他各种研究领域中观察到的一种普遍现象。遗忘表现在诸如由于生成器移位而导致的生成模型和由于客户端之间异构数据分布而导致的联邦学习等研究领域。解决遗忘问题涉及几个挑战，包括平衡旧任务知识的保留与新任务的快速学习、管理与冲突目标的任务干扰以及防止隐私泄露等。此外，大多数现有的关于持续学习的调查都隐含地假设遗忘总是有害的。相比之下，我们的调查认为遗忘是一把双刃剑，在某些情况下可能是有益的和可取的，例如隐私保护场景。通过在更广泛的背景下探索遗忘，我们对这一现象提出了更细致入微的理解，并强调了它的潜在优势。通过这项全面的调查，我们希望通过借鉴处理遗忘的各个领域的想法和方法来发现潜在的解决方案。通过超越传统界限来研究遗忘，我们希望鼓励开发新的策略来在实际应用中减轻、控制甚至接受遗忘。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10752992</guid>
      <pubDate>Thu, 14 Nov 2024 13:16:50 GMT</pubDate>
    </item>
    <item>
      <title>Patnas：基于小路的无训练神经建筑搜索</title>
      <link>http://ieeexplore.ieee.org/document/10753099</link>
      <description><![CDATA[神经体系结构搜索（NAS）的开发受到与评估网络体系结构相关的高成本的阻碍。最近，已经提出了一些零成本代理，作为降低NAS网络体系结构评估成本的有前途的方法。他们可以在初始阶段的几秒钟内快速估算网络的最终性能。但是，现有的零成本代理要么忽略网络结构对性能的影响，要么仅限于特定任务。为了解决这些问题，我们提出了一个新颖的零成本代理，称为骨架路径内核跟踪（SPKT），该代理利用整个网络体系结构的骨骼路径结构信息。然后，我们将其集成到称为PATNAS的NAS框架的有效贝叶斯优化中，并在不同数据集上演示其功效。结果表明，我们提出的SPKT零成本代理可以在多个任务中与网络的最终性能达到高度相关性。此外，它可以显着加速寻找表现最佳的网络体系结构的搜索过程。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10753099</guid>
      <pubDate>Thu, 14 Nov 2024 13:16:50 GMT</pubDate>
    </item>
    <item>
      <title>DIFFI2I：图像到图像翻译的有效扩散模型</title>
      <link>http://ieeexplore.ieee.org/document/10752976</link>
      <description><![CDATA[扩散模型 (DM) 已成为图像合成的 SOTA 方法。然而，现有的 DM 在某些图像到图像转换 (I2I) 任务上表现不佳。与图像合成不同，某些 I2I 任务（例如超分辨率）需要根据 GT 图像生成结果。用于图像合成的传统 DM 需要大量迭代和大型去噪模型来估计整个图像，这赋予了它们强大的生成能力，但也导致了 I2I 的伪影和效率低下。为了应对这一挑战，我们为 I2I 提出了一个简单、高效且强大的 DM 框架，称为 DiffI2I。具体而言，DiffI2I 包含三个关键组件：紧凑的 I2I 先验提取网络 (CPEN)、动态 I2I 变换器 (DI2Iformer) 和去噪网络。我们分两个阶段训练 DiffI2I：预训练和 DM 训练。对于预训练，GT 和输入图像被输入到 CPEN$_{S1}$S1 中，以捕获引导 DI2Iformer 的紧凑 I2I 先验表示 (IPR)。在第二阶段，DM 被训练为仅使用输入图像来估计与 CPEN$_{S1}$S1 相同的 IRP。与传统 DM 相比，紧凑的 IPR 使 DiffI2I 能够获得更准确的结果，并使用更轻的去噪网络和更少的迭代。通过对各种 I2I 任务的大量实验，我们证明 DiffI2I 实现了 SOTA 性能，同时显著降低了计算负担。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10752976</guid>
      <pubDate>Thu, 14 Nov 2024 13:16:50 GMT</pubDate>
    </item>
    <item>
      <title>Hi-SAM：结合任意分割模型实现分层文本分割</title>
      <link>http://ieeexplore.ieee.org/document/10750316</link>
      <description><![CDATA[该细分市场模型（SAM）是在大规模数据集上预测的深刻视觉基础模型，它破坏了一般细分的界限，并引发了各种下游应用程序。本文介绍了HI-SAM，这是一个统一的模型，利用SAM进行分层文本分割。 HI-SAM在分段方面划分了四个层次结构，包括像素级文本，单词，文本行和段落，同时也实现了布局分析。具体而言，我们首先通过参数有效的微调方法将SAM变成高质量像素级文本分割（TS）模型。我们使用此TS模型以半自动方式迭代生成像素级文本标签，并在HierText DataSet中的四个文本层次结构上统一标签。随后，使用这些完整的标签，我们使用定制的层次掩码解码器启动了基于TS体系结构的端到端训练HI-SAM。在推断期间，HI-SAM既提供自动掩码生成（AMG）模式，又提供迅速分割（PS）模式。在AMG模式下，HI-SAM片段像素级文本最初是前景掩码，然后为层次文本掩码生成的前景点进行样品，并通过传递进行布局分析。至于PS模式，HI-SAM单击单点，提供单词，文本行和段落掩码。实验结果表明，我们的TS模型的最新性能：用于像素级文本分割的TextSeg上的总文本率为84.86％，FGIOU为88.96％。此外，与先前用于HierText的联合分层检测和布局分析的专家相比，HI-SAM取得了重大改进：文本线级别的4.73％PQ和5.39％F1，5.49％PQ和7.39％F1在段级别的布局上分析，需要$ 20 \ Times $ 20×较少的培训时期。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10750316</guid>
      <pubDate>Mon, 11 Nov 2024 13:16:35 GMT</pubDate>
    </item>
    </channel>
</rss>