<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 模式分析和机器智能汇刊 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物 TOC 提醒# 34</description>
    <lastBuildDate>Tue, 06 Feb 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>社论：在计算机视觉中使用更少的标签进行学习</title>
      <link>http://ieeexplore.ieee.org/document/10423573</link>
      <description><![CDATA[毫无疑问，从 AlexNet 到 ResNet 再到 Transformer，深度神经网络 (DNN) 引发了各种计算机视觉任务的革命性进步。由于计算资源的快速发展，DNN 的规模呈指数级增长。尽管取得了巨大的成功，DNN 通常依赖于大量的训练数据（尤其是最近的各种基础模型）来实现高性能，并且很脆弱，因为操作环境的微小变化，它们的性能可能会严重下降。一般来说，收集大规模的训练数据集成本高昂，甚至不可行，对于某些领域，只能收集到非常有限的样本，甚至根本无法收集到样本。然而，收集、标记和审查大量的实际训练数据无疑是困难且昂贵的，因为它需要经验丰富的人类注释者或专家的艰苦努力，而且在许多情况下，由于某些原因（例如隐私），成本过高或不可能、安全或道德问题。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10423573</guid>
      <pubDate>Tue, 06 Feb 2024 13:19:25 GMT</pubDate>
    </item>
    <item>
      <title>学习用于小样本学习的任务自适应超参数</title>
      <link>http://ieeexplore.ieee.org/document/10080995</link>
      <description><![CDATA[少样本学习的目标是设计一个系统，该系统可以仅用很少的示例来适应给定的任务，同时实现泛化。与模型无关的元学习（MAML）最近因其简单性和灵活性而受到欢迎，它学习良好的初始化以快速适应少数据条件下的任务。然而，它的性能相对有限，特别是当新任务与之前在训练期间看到的任务不同时。在这项工作中，我们不是寻找更好的初始化，而是专注于设计更好的快速适应过程。因此，我们提出了一种新的任务自适应权重更新规则，大大增强了快速适应过程。具体来说，我们引入了一个小型元网络，它可以为每个给定任务生成每步超参数：学习率和权重衰减系数。实验结果验证了学习良好的权重更新规则以实现快速适应是同样重要的组成部分，但在最近的少样本学习方法中相对较少受到关注。令人惊讶的是，使用 ALFA 进行随机初始化的快速适应已经优于 MAML。此外，所提出的权重更新规则被证明可以持续提高 MAML 跨不同问题域的任务适应能力：少镜头分类、跨域少镜头分类、回归、视觉跟踪和视频帧插值。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10080995</guid>
      <pubDate>Fri, 24 Mar 2023 14:01:30 GMT</pubDate>
    </item>
    </channel>
</rss>