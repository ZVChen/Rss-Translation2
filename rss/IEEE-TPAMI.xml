<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 模式分析与机器智能学报 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物 TOC 提醒# 34</description>
    <lastBuildDate>Tue, 07 May 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>MotionDiffuse：使用扩散模型生成文本驱动的人体运动</title>
      <link>http://ieeexplore.ieee.org/document/10416192</link>
      <description><![CDATA[人体运动建模对于许多现代图形应用程序非常重要，这通常需要专业技能。为了消除外行人的技能障碍，最近的动作生成方法可以直接生成以自然语言为条件的人类动作。然而，利用各种文本输入实现多样化和细粒度的运动生成仍然具有挑战性。为了解决这个问题，我们提出了 MotionDiffuse，它是第一个基于扩散模型的文本驱动运动生成框架之一，它展示了现有方法的几个所需属性。 1）概率映射。 MotionDiffuse 不是确定性的语言运动映射，而是通过一系列注入变化的去噪步骤生成运动。 2）现实综合。 MotionDiffuse 擅长对复杂的数据分布进行建模并生成生动的运动序列。 3）多级操纵。 MotionDiffuse 响应身体部位的细粒度指令，以及随时间变化的文本提示的任意长度的运动合成。我们的实验表明，MotionDiffuse 在文本驱动的运动生成和动作条件运动生成方面具有令人信服的优势，优于现有的 SoTA 方法。定性分析进一步证明了 MotionDiffuse 对综合运动生成的可控性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10416192</guid>
      <pubDate>Mon, 29 Jan 2024 13:16:54 GMT</pubDate>
    </item>
    <item>
      <title>通过节点到邻域对齐的自监督节点表示学习</title>
      <link>http://ieeexplore.ieee.org/document/10414173</link>
      <description><![CDATA[自监督节点表示学习的目的是从未标记的图中学习与监督对应的节点表示相媲美的节点表示。学习信息丰富的节点表示的关键在于如何有效地从图结构中获取上下文信息。在这项工作中，我们通过对齐节点及其邻域的隐藏表示来提出简单而有效的自监督节点表示学习。我们的第一个想法通过直接最大化它们表示之间的互信息来实现这种节点到邻域的对齐，我们从理论上证明，这起到了图平滑的作用。我们的框架通过替代对比损失进行了优化，并提出了拓扑感知正采样（TAPS）策略，通过考虑节点之间的结构依赖性来对正样本进行采样，从而实现离线正选择。考虑到对比学习的过多内存开销，我们进一步提出了一种无负解决方案，其中主要贡献是图信号解相关（GSD）约束，以避免表示崩溃和过度平滑。 GSD 约束统一了一些现有的约束，可用于派生新的实现来对抗表示崩溃。通过在简单的基于 MLP 的节点表示编码器上应用我们的方法，我们学习了节点表示，这些节点表示在一组从小规模到大规模的图结构数据集上实现了有前途的节点分类性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10414173</guid>
      <pubDate>Thu, 25 Jan 2024 13:16:29 GMT</pubDate>
    </item>
    <item>
      <title>Dropout 的隐式正则化</title>
      <link>http://ieeexplore.ieee.org/document/10412142</link>
      <description><![CDATA[了解 dropout（一种流行的正则化方法）如何帮助在神经网络训练期间实现良好的泛化解决方案非常重要。在这项工作中，我们提出了 dropout 的隐式正则化的理论推导，并通过一系列实验进行了验证。此外，我们在数值上研究了隐式正则化的两个含义，直观地解释了为什么 dropout 有助于泛化。首先，我们发现隐藏神经元的输入权重倾向于压缩在用 dropout 训练的孤立方向上。压缩是非线性学习过程中的一个特征，它使网络变得不那么复杂。其次，我们发现与标准梯度下降训练相比，dropout 训练导致神经网络具有更平坦的最小值，而隐式正则化是找到平坦解决方案的关键。虽然我们的理论主要关注最后隐藏层中使用的 dropout，但我们的实验适用于训练神经网络中的一般 dropout。这项工作指出了 dropout 与随机梯度下降相比的显着特征，并作为充分理解 dropout 的重要基础。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10412142</guid>
      <pubDate>Tue, 23 Jan 2024 13:17:59 GMT</pubDate>
    </item>
    <item>
      <title>检验两组线性可分性的新充分必要条件</title>
      <link>http://ieeexplore.ieee.org/document/10411108</link>
      <description><![CDATA[作为机器学习领域的基础数学问题，线性可分性检验仍然缺乏理论上完整且计算高效的方法。本文提出并证明了基于球体模型的线性可分性检验的充分必要条件。该测试方法的优点有两个：（1）它不仅提供了线性可分性的定性测试，而且还提供了线性可分实例的可分性的定量分析； (2)时间成本低，比现有测试方法更加高效。通过在基准数据集和人工数据集上的大量实验验证了所提出的方法，证明了其正确性和效率。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10411108</guid>
      <pubDate>Mon, 22 Jan 2024 13:21:30 GMT</pubDate>
    </item>
    <item>
      <title>I2C：用于高保真可变速率图像压缩的可逆连续编解码器</title>
      <link>http://ieeexplore.ieee.org/document/10411123</link>
      <description><![CDATA[有损图像压缩是媒体传输和存储的一项基础技术。可变速率方法最近引起了广泛关注，以避免使用一组不同模型以不同速率压缩图像。在媒体共享过程中，不可避免地会执行不同速率的多次重编码。然而，现有的基于变分自动编码器（VAE）的方法在这种情况下很容易被破坏，导致出现强烈的伪影并破坏图像保真度。基于通过可逆变换保持图像保真度的理论发现，我们旨在解决高保真精细可变速率图像压缩问题，从而提出可逆连续编解码器（I2C）。我们使用核心可逆激活转换 (IAT) 模块以数学可逆方式实现 I2C。 I2C 基于单速率可逆神经网络 (INN) 模型构建，质量水平 (QLevel) 将被输入 IAT 以生成缩放和偏差张量。大量实验表明，所提出的 I2C 方法大幅优于最先进的可变速率图像压缩方法，特别是在以不同速率进行多次连续重新编码之后，同时能够获得非常精细的可变速率控制而不影响任何性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10411123</guid>
      <pubDate>Mon, 22 Jan 2024 13:21:30 GMT</pubDate>
    </item>
    <item>
      <title>NaturalSpeech：具有人类水平质量的端到端文本到语音合成</title>
      <link>http://ieeexplore.ieee.org/document/10409539</link>
      <description><![CDATA[近年来，文本转语音（TTS）在学术界和工业界都取得了快速进展。自然会出现一些问题：TTS 系统是否可以达到人类水平的质量、如何定义/判断该质量以及如何实现它。在本文中，我们首先根据主观测量的统计显着性定义人类水平的质量，并引入适当的准则来判断它，然后开发一个名为 NaturalSpeech 的 TTS 系统，在基准数据集上实现人类水平的质量，从而回答这些问题。具体来说，我们利用变分自动编码器（VAE）进行端到端文本到波形生成，并通过几个关键模块来增强文本先验的能力并降低语音后验的复杂性，包括音素VAE 中的预训练、可微持续时间建模、双向先验/后验建模和记忆机制。对流行的 LJSpeech 数据集的实验评估表明，我们提出的 NaturalSpeech 在句子级别与人类录音相比实现了 $-0.01$-0.01 CMOS（比较平均意见得分），并在 p 级别进行了 Wilcoxon 符号秩检验 $p \gg 0.05$p ≫0.05，首次证明与人类记录没有统计学上的显着差异。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10409539</guid>
      <pubDate>Fri, 19 Jan 2024 13:16:52 GMT</pubDate>
    </item>
    <item>
      <title>面向查询的微视频摘要</title>
      <link>http://ieeexplore.ieee.org/document/10403941</link>
      <description><![CDATA[面向查询的微视频摘要任务旨在生成具有两个属性的简洁句子：（a）总结微视频的主要语义；（b）以搜索查询的形式表达以方便检索。尽管它在检索领域具有巨大的应用价值，但这个方向几乎没有被探索过。以往的摘要研究主要集中在传统长视频的内容摘要上。由于微视频和查询的独特特征：短时间内实体多样、场景复杂、模态之间的语义差距以及不同表达方式下的各种查询，直接应用这些研究很容易获得不令人满意的结果。为了专门适应这些特征，我们提出了一种面向查询的微视频摘要模型，称为 QMS。它采用基于编码器-解码器的变压器架构作为骨架。多模态（视觉和文本）信号通过两个特定于模态的编码器来获取其表示，然后通过实体感知表示学习模块来识别和突出显示关键实体信息。在优化方面，考虑到模态之间存在较大的语义差距，我们根据优化过程中的语义相关性分配不同的置信度分数。此外，我们开发了一种新颖的策略，可以在具有各种表达式的多样化查询集中采样有效的目标查询。大量的实验证明了 QMS 方案在摘要和检索任务上优于几种最先进的方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10403941</guid>
      <pubDate>Thu, 18 Jan 2024 13:16:19 GMT</pubDate>
    </item>
    <item>
      <title>用于从视频创建逼真头像的可动画化隐式神经表示</title>
      <link>http://ieeexplore.ieee.org/document/10401886</link>
      <description><![CDATA[本文解决了从多视图视频重建可动画人体模型的挑战。最近的一些工作提出将非刚性变形场景分解为规范神经辐射场和一组将观察空间点映射到规范空间的变形场，从而使它们能够从图像中学习动态场景。然而，它们将变形场表示为平移矢量场或 SE(3) 场，这使得优化高度受限。此外，这些表示不能由输入动作明确控制。相反，我们引入混合权重场来产生变形场。基于骨架驱动的变形，混合权重场与 3D 人体骨架一起使用，以生成观察到规范和规范到观察的对应关系。由于 3D 人体骨骼更容易观察，因此它们可以规范变形场的学习。此外，混合权重场可以与输入骨骼运动相结合，生成新的变形场来为人体模型制作动画。为了提高人体建模的质量，我们进一步将人体几何表示为规范空间中的带符号距离场。此外，引入神经点位移场来增强混合权重场对详细人体运动进行建模的能力。实验表明，我们的方法明显优于最近的人体建模方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10401886</guid>
      <pubDate>Wed, 17 Jan 2024 13:16:23 GMT</pubDate>
    </item>
    <item>
      <title>联合高斯过程：收敛、自动个性化和多保真度建模</title>
      <link>http://ieeexplore.ieee.org/document/10402074</link>
      <description><![CDATA[在本文中，我们提出了 FGPR：一种联邦高斯过程 ($\mathcal {GP}$GP) 回归框架，它使用模型聚合的平均策略和本地计算的随机梯度下降。值得注意的是，由于 FGPR 共同学习所有设备上共享的先验，由此产生的全局模型在个性化方面表现出色。然后通过利用这个共享先验和对本地数据进行调节来获得预测后验，该数据对来自特定数据集的个性化特征进行编码。理论上，我们表明 FGPR 收敛到完整对数边际似然函数的临界点，但会受到统计误差的影响。这一结果提供了独立的价值，因为它将联邦学习理论结果引入了相关范式。通过对多个回归任务的广泛案例研究，我们表明 FGPR 在广泛的应用中表现出色，并且是隐私保护多保真数据建模的一种有前途的方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10402074</guid>
      <pubDate>Wed, 17 Jan 2024 13:16:23 GMT</pubDate>
    </item>
    <item>
      <title>学习人类教育智慧：以学生为中心的知识提炼方法</title>
      <link>http://ieeexplore.ieee.org/document/10400954</link>
      <description><![CDATA[现有的知识提炼研究多以教师为中心的方法，即教师网络按照自身的标准进行训练，再将学到的知识传递给学生网络。然而，由于教师和学生的网络结构不同，前者学到的知识可能并不是后者所需要的。受人类教育智慧的启发，本文提出了一种以学生为中心的知识提炼（SCD）方法，使教师网络能够根据学生网络的需求调整其知识传递方式。我们基于各种人类教育智慧实现了SCD，例如，教师网络在验证集上识别并学习学生网络所需的知识，然后通过训练集将其传递给学生。为了解决学生网络在学习过程中面临的当前知识缺失、样本学习困难和知识遗忘的问题，我们引入并改进了自动化领域的比例-积分-微分（PID）算法，使其能够有效识别学生网络当前所需的知识。此外，我们提出了一种基于课程学习的模糊策略，并将其应用于所提出的 PID 控制算法，使得 SCD 中的学生网络在掌握一定知识后可以主动关注具有挑战性的样本的学习。通过将 SCD 与最先进的方法进行比较，验证了 SCD 在多个任务中的整体性能。实验结果表明，我们以学生为中心的蒸馏方法优于现有的以教师为中心的蒸馏方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10400954</guid>
      <pubDate>Tue, 16 Jan 2024 13:16:03 GMT</pubDate>
    </item>
    <item>
      <title>通过系统评估更好地理解归因方法的差异</title>
      <link>http://ieeexplore.ieee.org/document/10398493</link>
      <description><![CDATA[深度神经网络在许多视觉任务上都非常成功，但由于其黑盒性质而难以解释。为了克服这个问题，人们提出了各种事后归因方法来识别对模型决策最有影响的图像区域。评估此类方法具有挑战性，因为不存在基本事实归因。因此，我们提出了三种新颖的评估方案，以更可靠地衡量这些方法的可信度，使它们之间的比较更加公平，并使目视检查更加系统化。为了解决忠实度问题，我们提出了一种新颖的评估设置（DiFull），在该设置中，我们仔细控制输入的哪些部分可以影响输出，以便区分可能的归因和不可能的归因。为了解决公平性，我们注意到不同的方法应用于不同的层，这会扭曲任何比较，因此评估同一层（ML-Att）上的所有方法，并讨论这如何影响它们在定量指标上的性能。为了更系统的可视化，我们提出了一种方案（AggAtt）来定性评估完整数据集上的方法。我们使用这些评估方案来研究一些广泛使用的归因方法在各种模型上的优点和缺点。最后，我们提出了一种后处理平滑步骤，可以显着提高某些归因方法的性能，并讨论其适用性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10398493</guid>
      <pubDate>Fri, 12 Jan 2024 13:16:26 GMT</pubDate>
    </item>
    <item>
      <title>ASP：学习通用神经求解器！</title>
      <link>http://ieeexplore.ieee.org/document/10387785</link>
      <description><![CDATA[将机器学习应用于组合优化问题有可能提高效率和准确性。然而，现有的基于学习的求解器在面对问题分布和规模的变化时常常难以泛化。在本文中，我们提出了一种称为 ASP：自适应阶梯策略空间响应 Oracle 的新方法来解决这些泛化问题并学习通用神经求解器。 ASP 由两个组件组成：分布探索（它增强求解器使用策略空间响应预言机处理未知分布的能力）和持久规模适应（通过课程学习提高可扩展性）。我们在几个具有挑战性的 COP 上测试了 ASP，包括旅行商问题、车辆路线问题和奖品收集 TSP，以及来自 TSPLib 和 CVRPLib 的真实实例。我们的结果表明，即使模型大小相同且训练信号较弱，ASP 也可以帮助神经求解器探索和适应看不见的分布和变化的尺度，从而实现卓越的性能。特别是，与标准训练管道下的相同神经求解器相比，ASP 在 TSP 的生成实例和真实实例上的最优性差距显着降低，分别为 90.9% 和 47.43%，并且降低了 19% 和CVRP 为 45.57%。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10387785</guid>
      <pubDate>Wed, 10 Jan 2024 13:17:17 GMT</pubDate>
    </item>
    <item>
      <title>不完全伽马核：推广局部最优投影算子</title>
      <link>http://ieeexplore.ieee.org/document/10380761</link>
      <description><![CDATA[我们提出了不完整的伽玛核，这是局部最优投影（LOP）算子的推广。特别是，我们通过新颖的内核揭示了用于点云去噪的 LOP 算子中的经典局部 $ L_{1}$L1 估计器与常见的 Mean Shift 框架的关系。此外，我们将此结果推广到基于不完整 gamma 函数构建的整个内核系列，每个内核代表一个局部 $ L_{p}$Lp 估计器。通过推导核族有关分布、Mean Shift 诱导以及其他方面（例如严格正定性）的各种属性，我们可以更深入地了解算子的投影行为。从这些理论见解中，我们阐述了几种应用，从改进的加权 LOP (WLOP) 密度加权方案和更准确的连续 LOP (CLOP) 核近似到一组新颖的鲁棒损失函数的定义。这些不完全伽马损失包括高斯损失和 LOP 损失作为特殊情况，可以应用于包括正常滤波在内的各种任务。此外，我们表明新的内核可以作为先验包含到神经网络中。我们在一系列定量和定性实验中展示了每种应用的效果，突出了我们的修改带来的好处。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10380761</guid>
      <pubDate>Thu, 04 Jan 2024 13:17:16 GMT</pubDate>
    </item>
    <item>
      <title>MixFormer：具有迭代混合注意力的端到端跟踪</title>
      <link>http://ieeexplore.ieee.org/document/10380715</link>
      <description><![CDATA[视觉对象跟踪通常采用特征提取、目标信息集成和边界框估计的多级流程。为了简化这个流程并统一特征提取和目标信息集成的过程，在本文中，我们提出了一个基于 Transformer 的紧凑跟踪框架，称为 MixFormer。我们的核心设计是利用注意力操作的灵活性，我们提出了混合注意力模块（MAM），用于同时进行特征提取和目标信息集成。这种同步建模方案使我们能够提取特定于目标的判别特征，并在目标和搜索区域之间进行广泛的通信。基于 MAM，我们只需堆叠多个 MAM 并在顶部放置一个定位头即可构建 MixFormer 跟踪器。具体来说，我们实例化两种类型的 MixFormer 跟踪器：分层跟踪器 MixCvT 和非分层简单跟踪器 MixViT。对于这两个跟踪器，我们研究了一系列预训练方法，并揭示了 MixFormer 跟踪器中监督预训练和自监督预训练之间的不同行为。我们还将屏蔽自动编码器预训练扩展到 MixFormer 跟踪器，并设计了新的竞争性 TrackMAE 预训练技术。最后，为了在在线跟踪过程中处理多个目标模板，我们在 MAM 中设计了一种非对称注意力方案来降低计算成本，并提出了一种有效的分数预测模块来选择高质量模板。我们的 MixFormer 跟踪器在 LaSOT、TrackingNet、VOT2020、GOT-10 k、OTB100、TOTB 和 UAV123 等七个跟踪基准上创下了新的最先进性能。特别是，我们的 MixViT-L 在 LaSOT 上的 AUC 分数为 73.3%，在 TrackingNet 上的 AUC 分数为 86.1%，在 TOTB 上的 AUC 分数为 82.8%。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10380715</guid>
      <pubDate>Thu, 04 Jan 2024 13:17:16 GMT</pubDate>
    </item>
    <item>
      <title>DeepSFM：针对运动结构的稳健深度迭代细化</title>
      <link>http://ieeexplore.ieee.org/document/10241282</link>
      <description><![CDATA[运动结构（SfM）是一个基本的计算机视觉问题，深度学习尚未很好地解决该问题。有前景的解决方案之一是将显式结构约束（例如 3D 成本量）应用到神经网络中。仅从图像中获取准确的相机姿势可能具有挑战性，特别是在复杂的环境因素下。现有方法通常通过 GT 或其他方法假设准确的相机姿态，这在实践中是不现实的，并且需要额外的传感器。在这项工作中，我们设计了一种物理驱动架构，即 DeepSFM，其灵感来自于传统的 Bundle adjustment，它由两个基于成本量的架构组成，用于迭代地细化深度和姿态。对深度和姿势的明确约束与学习组件相结合，为传统 BA 和新兴深度学习技术带来了优点。为了加快学习和推理效率，我们在迭代细化中应用了基于门控循环单元（GRU）的深度和姿态更新模块，并具有从粗到细的成本量。此外，通过扩展的残差深度预测模块，我们的模型可以有效地适应动态场景。对各种数据集的大量实验表明，我们的模型实现了最先进的性能，并且针对具有挑战性的输入具有卓越的鲁棒性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10241282</guid>
      <pubDate>Tue, 05 Sep 2023 14:02:30 GMT</pubDate>
    </item>
    </channel>
</rss>