<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE神经网络和学习系统的交易 - 新的TOC</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>TOC警报出版＃5962385</description>
    <lastBuildDate>Fri, 04 Apr 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>目录</title>
      <link>http://ieeexplore.ieee.org/document/10949154</link>
      <description><![CDATA[无效的]]></description>
      <guid>http://ieeexplore.ieee.org/document/10949154</guid>
      <pubDate>Fri, 04 Apr 2025 13:18:20 GMT</pubDate>
    </item>
    <item>
      <title>IEEE关于神经网络和学习系统出版信息的交易</title>
      <link>http://ieeexplore.ieee.org/document/10949585</link>
      <description><![CDATA[无效的]]></description>
      <guid>http://ieeexplore.ieee.org/document/10949585</guid>
      <pubDate>Fri, 04 Apr 2025 13:18:20 GMT</pubDate>
    </item>
    <item>
      <title>有关因果增强学习的调查</title>
      <link>http://ieeexplore.ieee.org/document/10771589</link>
      <description><![CDATA[尽管加强学习（RL）在许多领域的序性决策问题中取得了巨大的成功，但它仍然面临着数据效率低下和缺乏可解释性的关键挑战。有趣的是，许多研究人员最近利用了因果关系文献的见解，提出了蓬勃发展的作品来统一因果关系的优点，并解决了RL的挑战。因此，整理这些因果RL（CRL）作品，对CRL方法进行综述并研究因果关系到RL的潜在功能是很大的必要和意义。特别是，我们根据是否提前给出基于因果关系的信息将现有的CRL方法分为两类。我们进一步分析了每个类别的不同模型的形式化，范围从马尔可夫决策过程（MDP），部分观察到的MDP（POMDP）（POMDP），多型匪徒（MABS），模仿学习（IL）和动态治疗方案（DTR）。它们每个都代表着一种不同的因果图形插图。此外，我们总结了评估矩阵和开源来源，同时讨论新兴应用程序，以及CRL未来发展的前景。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10771589</guid>
      <pubDate>Thu, 28 Nov 2024 13:18:20 GMT</pubDate>
    </item>
    <item>
      <title>EVID-GAN：用无限的歧视者以微不足道的成本改善GAN</title>
      <link>http://ieeexplore.ieee.org/document/10639254</link>
      <description><![CDATA[集合学习提高了基于卷积神经网络（CNN）的歧视者的能力，其性能对于生成对抗性网络（GAN）中产生的样品的质量至关重要。但是，这种学习策略导致参数数量以及计算开销的大幅增加。同时，仍在研究增强GAN性能所需的合适数量的歧视者。为了减轻这些问题，我们提出了gan（evid-gan）的证据歧视器 - 可在https://github.com/tohokantche/evid-gan上获得COD，以学习模型（认知）和数据（认识）（认识）（lealeatoric）的不确定性。具体而言，通过分析三个GAN模型，已经发现了歧视器输出的分布与发电机性能之间的关系，从而产生了GAN框架的一般公式。通过上述分析，证据歧视者通过对歧视者的输出中表达的可能性施加较高的分布限制来了解差异和认知不确定性的程度。该约束可以学习与无限集合歧视者相对应的似然函数的集合。因此，EVID-GAN通过歧视器的集合学习来汇总知识，该学习使发电机以可忽略的计算成本从信息梯度流中受益。此外，我们受到最大平均差异（MMD） - 抑制性GAN的启发，我们为EVID-GAN设计了不对称的正则化方案。与在分布水平上执行的MMD抑制性GAN不同，我们的正则化方案基于成对损耗函数，在样本级别执行，并在发电机和鉴别器的训练过程中以不对称行为为特征。实验结果表明，所提出的证据歧视者具有成本效益，从Frechet Inception距离（FID）和INCEPTION评分（IS）方面始终改善GAN，并且比使用多个歧视者的其他竞争模型更好。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10639254</guid>
      <pubDate>Mon, 19 Aug 2024 13:16:54 GMT</pubDate>
    </item>
    <item>
      <title>图像字幕通过动态路径自定义</title>
      <link>http://ieeexplore.ieee.org/document/10616183</link>
      <description><![CDATA[本文探讨了视觉和语言（V＆amp; l）任务的新型动态网络，其中推断结构是为不同输入而自定义的。大多数以前的最先进的方法（SOTA）方法是静态和手工制作的网络，它们不仅在很大程度上依赖专家知识，而且忽略了输入样本的语义多样性，因此导致了次优性能。为了解决这些问题，我们为图像字幕提出了一个新型的动态变压器网络（DTNET），该网络将自定义路径分配给不同的样本，从而导致歧视性但准确的标题。具体而言，为了构建丰富的路由空间并提高路由效率，我们根据其操作域，即空间和通道，将五种类型的基本单元引入两个单独的路由空间。然后，我们设计了一个空间通道关节路由器（SCJR），该路由器（SCJR）赋予模型基于输入样本的空间和通道信息的路径自定义能力。为了验证我们提出的DTNET的有效性，我们在MS-Coco数据集上进行了广泛的实验，并在KarPathy Split和在线测试服务器上实现了新的SOTA性能。源代码可在https://github.com/xmu-xiaoma666/dtnet上公开获得。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10616183</guid>
      <pubDate>Wed, 31 Jul 2024 13:17:38 GMT</pubDate>
    </item>
    <item>
      <title>改善双重相关性减少网络，亲和力恢复</title>
      <link>http://ieeexplore.ieee.org/document/10605097</link>
      <description><![CDATA[深度图聚类旨在揭示基础图结构并将节点分为没有人类注释的不同群集，这是一项基本而又具有挑战性的任务。但是，我们观察到现有方法遭受了表示崩溃问题的影响，并且倾向于将具有不同类别的样品编码为同一潜在嵌入。因此，节点的判别能力受到限制，导致次优聚类性能。为了解决这个问题，我们提出了一种新颖的深图聚类算法，该算法称为改善双重相关性还原网络（IDCRN），通过提高样品的判别能力。具体而言，通过将跨视图特征相关矩阵与身份矩阵近似，我们减少了特征的不同维度之间的冗余，从而明确提高了潜在空间的判别能力。同时，跨视图样品相关矩阵被迫近似设计的聚类精制的邻接矩阵，以指导学习的潜在表示即使在视图上恢复了亲和力矩阵，从而增强了特征的歧视能力。此外，我们避免了通过引入的繁殖正规化项中的图形卷积网络（GCN）中的过度厚度问题造成的崩溃表示，使IDCRN能够使用浅网络结构捕获远程信息。与现有的最新深图聚类算法相比，六个基准的广泛实验结果证明了IDCRN的有效性和效率。 IDCRN的代码在IDCRN发布。此外，我们共享一系列深图聚类的集合，包括ADGC上的论文，代码和数据集。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10605097</guid>
      <pubDate>Fri, 19 Jul 2024 13:15:54 GMT</pubDate>
    </item>
    <item>
      <title>深度聚类：一项全面的调查</title>
      <link>http://ieeexplore.ieee.org/document/10585323</link>
      <description><![CDATA[聚类分析在机器学习和数据挖掘中起着必不可少的作用。学习良好的数据表示对于聚类算法至关重要。最近，深层聚类（DC）可以使用深神经网络（DNNS）学习聚类友好的表示，已广泛应用于各种聚类任务。 DC的现有调查主要集中在单视场和网络体系结构上，忽略了聚类的复杂应用程序方案。为了解决此问题，在本文中，我们在数据源的观点中为DC提供了全面的调查。使用不同的数据源，我们从方法论，先验知识和架构方面系统地区分聚类方法。具体而言，DC方法是根据四个类别（即传统的单视DC，半监督DC，Deep Multiview Clustering（MVC）和深层传输聚类引入的。最后，我们讨论了DC不同领域的开放挑战和潜在的未来机会。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10585323</guid>
      <pubDate>Thu, 04 Jul 2024 13:16:00 GMT</pubDate>
    </item>
    <item>
      <title>通过渐进式任务上下文化的多种持续协调</title>
      <link>http://ieeexplore.ieee.org/document/10562331</link>
      <description><![CDATA[合作的多基础增强学习（MARL）引起了极大的关注，并具有许多现实应用的潜力。以前的艺术主要集中于在单任务或多任务方案中促进不同方面（例如非组织性和信用分配）的协调能力，而忽略了以连续方式出现的任务流。这种无知使持续的协调成为未开发的领域，既不在问题制定中，也不是设计有效的算法。为了解决上述问题，本文提出了一种通过渐进任务上下文化（MACPRO）的方法，多基因的持续协调。关键点在于使用共享的特征提取层获得分解策略，但分开独立任务头，每个任务头都专门研究特定的任务类别。可以根据学习的任务上下文化逐步扩展任务头。此外，为了迎合MARL中流行的分散执行（CTDE）范式的流行集中培训，每个代理商都学会以分散的方式根据本地信息来预测和采用最相关的政策主管。我们在多个多基准基准中显示现有的持续学习方法失败，而MacPro可以实现近距离的性能。更多结果还揭示了MacPro从多个方面（例如高概括能力）中揭示的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10562331</guid>
      <pubDate>Wed, 19 Jun 2024 13:16:32 GMT</pubDate>
    </item>
    <item>
      <title>从算法到硬件：有关深度神经网络有效且安全部署的调查</title>
      <link>http://ieeexplore.ieee.org/document/10557780</link>
      <description><![CDATA[深层神经网络（DNN）已被广泛用于许多人工智能（AI）任务。但是，由于记忆，能量和计算的巨大成本，部署它们带来了巨大的挑战。为了应对这些挑战，研究人员开发了各种模型压缩技术，例如模型量化和模型修剪。最近，在保留性能的同时，对压缩方法的研究激增。此外，越来越多的工作重点是自定义DNN硬件加速器，以更好地利用模型压缩技术。除了效率外，保持安全性和隐私对于部署DNN至关重要。但是，庞大而多样化的相关作品可能是压倒性的。这激发了我们对最新研究的全面调查，以实现高性能，成本效益和安全部署DNN的目标。我们的调查首先涵盖了主流模型压缩技术，例如模型量化，模型修剪，知识蒸馏和非线性操作的优化。然后，我们介绍了设计可以适应有效模型压缩方法的硬件加速器方面的最新进展。此外，我们讨论了如何集成同构加密以确保DNN部署的。最后，我们讨论了几个问题，例如各种压缩方法的硬件评估，概括和集成。总体而言，我们旨在提供从算法到硬件加速器和安全性观点的有效DNN的全局。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10557780</guid>
      <pubDate>Fri, 14 Jun 2024 13:16:24 GMT</pubDate>
    </item>
    <item>
      <title>基于样本的连续近似方法用于构建间隔神经网络</title>
      <link>http://ieeexplore.ieee.org/document/10557504</link>
      <description><![CDATA[在安全至关重要的工程应用中，例如针对对抗性噪声的可靠预测，有必要量化神经网络的不确定性。间隔神经网络（INNS）是用于不确定性定量的有效模型，给出了预测间隔，而不是相应输入的单个值。本文提出了培训旅馆作为偶然受限的优化问题的问题。配制的机会受限优化的最佳解决方案自然形成了一个旅馆，该旅馆给出了最紧密的预测间隔，并具有所需的置信度。由于偶然约束的优化问题是棘手的，因此使用基于样本的连续近似方法来获得近似解决方案，以解决机会受限的优化问题。我们证明了近似值的均匀收敛性，表明它与原始的旅馆保持一致。此外，我们研究了使用有限样品的近似值的可靠性，从而给出了有限样本违规的概率。通过在风能数据中检测异常检测的数值示例和应用程序案例研究，我们评估了针对现有方法（包括贝叶斯神经网络）的拟议旅馆的有效性，从而强调了其能够显着提高Inns进行回归和无易于异常检测的能力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10557504</guid>
      <pubDate>Thu, 13 Jun 2024 13:16:44 GMT</pubDate>
    </item>
    <item>
      <title>基于数据的最佳切换和控制能力保证了Q学习</title>
      <link>http://ieeexplore.ieee.org/document/10549827</link>
      <description><![CDATA[本文通过两阶段的近似动态编程（ADP）算法解决了基于数据的最佳开关和控制代码。通过离线策略改进和政策评估，所提出的算法迭代地确定了使用系统输入/输出数据的最佳混合控制策略。此外，为两阶段ADP算法提供了严格的收敛证明。可采性，必须确保用于实际应用的混合控制政策的重要特性。为此，分析了混合控制策略的特性，并获得了可接纳性标准。为了实现所提出的Q学习算法，采用了多个NNS来近似不同子系统的Q-功能和控制策略，采用了参与者批生神经网络（NN）结构。通过应用拟议的可接受性标准，可以保证获得的混合控制政策是可以接受的。最后，两个数值模拟验证了所提出的算法的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10549827</guid>
      <pubDate>Wed, 05 Jun 2024 13:17:47 GMT</pubDate>
    </item>
    <item>
      <title>元调节：一个跨任务适应的一般学习框架</title>
      <link>http://ieeexplore.ieee.org/document/10549846</link>
      <description><![CDATA[建立具有适应性灵活性不同任务的学习系统至关重要且具有挑战性。在本文中，我们提出了一个名为Meta调制（备忘录）的新颖而通用的元学习框架，以促进基础学习者在不同任务上的适应能力，在不同的任务中，每个任务只有少数培训数据。对于一项独立的任务，备忘录像“反馈调节系统”一样进行，该系统可以对所谓的查询数据的确定确定嵌入进行自适应调制，以最大化相应的任务目标。具体而言，我们设计了一种有效的反馈信息，确定的嵌入反馈（DEF），以数学和量化少数培训数据与基础学习者之间的不合适性，以及有希望的调整方向，以减少这种不合适的能力。 DEF被编码为高级表示形式，并通过调制编码暂时存储为特定于任务的调制器模板。对于即将到来的查询数据，我们开发了一种对这些调制器模板作用的注意机制，并将任务/数据级调制组合起来以生成最终数据特定的元调节器。然后，该元调节器用于调节查询的嵌入以正确决策。我们的框架可扩展到多层学习者模型，例如多层感知器（MLP），长期短期记忆（LSTM），卷积神经网络（CNN）和变压器，以及适用于不同学习问题，例如语言建模和图像识别。在语言和视觉域中的2-D点合成数据集和各种基准测试的实验结果证明了我们框架的有效性和竞争力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10549846</guid>
      <pubDate>Wed, 05 Jun 2024 13:17:47 GMT</pubDate>
    </item>
    <item>
      <title>通过成倍成长的训练集进行舞台训练</title>
      <link>http://ieeexplore.ieee.org/document/10542969</link>
      <description><![CDATA[在大数据的世界中，培训大规模的机器学习问题引起了人们的关注。近年来，已经提出了许多创新的优化策略，以加速大规模培训过程。但是，进一步加速各种优化算法的训练过程的可能性仍然是尚未解决的主题。为了开始解决这个困难的问题，我们利用了研究的发现，即当培训数据是独立的并且分布相同的情况下，较小数据集上的学习问题与原始数据没有显着差异。因此，我们提出了一种舞台训练技术，该技术在求解非平滑子问题的同时，将训练集的大小成倍增长。我们证明，通过指数增长的训练集（Stegss）的阶段训练与大量近端梯度下降和梯度硬阈值（GHT）技术兼容。有趣的是，我们证明Steg可以大大降低整体复杂性，同时保持统计准确性，甚至超过GHT方法引入的内在错误。此外，我们分析了培训数据增长率对整体复杂性的影响。应用$ l_ {2,1} $和$ l_ {0} $ -NORMS的实际结果不仅证实了我们的理论，而且还证明了我们Stegs框架的好处。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10542969</guid>
      <pubDate>Fri, 31 May 2024 13:16:30 GMT</pubDate>
    </item>
    <item>
      <title>图内神经网络</title>
      <link>http://ieeexplore.ieee.org/document/10542111</link>
      <description><![CDATA[许多现代神经体系结构核心的卷积操作员可以有效地看作是在输入矩阵和过滤器之间执行点产物。尽管这很容易适用于诸如图像之类的数据，这些数据可以表示为欧几里得空间中的常规网格，但由于其不规则的结构，将卷积操作员扩展到图表上的工作证明更具挑战性。在本文中，我们建议使用图形内核，即计算内部产品的内核函数，以将标准卷积运算符扩展到图形域。这使我们能够定义一个完全不需要计算输入图的嵌入的结构模型。我们的体系结构允许插入任何类型的图内内核，并带来了在训练过程中学到的结构口罩提供一些解释性的额外好处，类似于传统卷积神经网络（CNN）中卷积掩模的情况。我们进行了一项广泛的消融研究，以研究模型超参数的影响，并表明我们的模型在标准图分类和回归数据集上实现了竞争性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10542111</guid>
      <pubDate>Thu, 30 May 2024 13:16:20 GMT</pubDate>
    </item>
    <item>
      <title>双重信息增强的多视属性图形群集</title>
      <link>http://ieeexplore.ieee.org/document/10542165</link>
      <description><![CDATA[多视属性图形群集是基于属性特征和来自不同视图的相邻矩阵分区数据数据的重要方法。在使用图形神经网络（GNN）方面已经尝试了一些尝试，这些神经网络已实现了有希望的聚类性能。尽管如此，很少有人会注意嵌入多个视图中的固有特定信息。同时，他们无法从低水平的高级高级表示中恢复潜在的高级表示，从而极大地限制了下游聚类性能。为了填补这些空白，本文提出了一种新颖的双重信息增强的多视归因图聚类（DIAGC）方法。具体而言，所提出的方法介绍了特定信息重建（SIR）模块，以将共识和特定信息的探索与多个视图相关，这使图形卷积网络（GCN）可以捕获更重要的低级表示。此外，对比度学习（CL）模块最大程度地提高了潜在的高级表示与低级表述之间的一致性，并允许高级表示以满足所需的聚类结构，并借助于自我监视的聚类（SC）模块。对几个现实基准测试的广泛实验证明了与最先进的基线相比，提出的DIAGC方法的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10542165</guid>
      <pubDate>Thu, 30 May 2024 13:16:20 GMT</pubDate>
    </item>
    </channel>
</rss>