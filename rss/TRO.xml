<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE关于机器人技术的交易 - 新TOC</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>TOC警报出版＃8860</description>
    <lastBuildDate>Fri, 13 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>客座编辑式系列触觉机器人技术</title>
      <link>http://ieeexplore.ieee.org/document/10900528</link>
      <description><![CDATA[无效的]]></description>
      <guid>http://ieeexplore.ieee.org/document/10900528</guid>
      <pubDate>Mon, 24 Feb 2025 13:16:24 GMT</pubDate>
    </item>
    <item>
      <title>在备忘录中：乔治·贝基（George Bekey）1928  -  2024</title>
      <link>http://ieeexplore.ieee.org/document/10896982</link>
      <description><![CDATA[无效的]]></description>
      <guid>http://ieeexplore.ieee.org/document/10896982</guid>
      <pubDate>Thu, 20 Feb 2025 13:18:17 GMT</pubDate>
    </item>
    <item>
      <title>在未知环境中的自主尾式航班</title>
      <link>http://ieeexplore.ieee.org/document/10829730</link>
      <description><![CDATA[由于高度非线性的空气动力学，无人驾驶飞机（UAV）完全自动飞行的轨迹产生造成了重大挑战。在本文中，我们介绍了作者的最佳知识，这是世界上第一个完全自主的尾随者无用的无用，能够在未知的，杂乱无章的环境中进行高速导航。 UAV自主权是通过包括基于激光雷达的传感，基于差异的轨迹计划和控制纯粹的板载计算的最先进技术来实现的。特别是，我们提出了一个基于优化的尾部轨迹轨迹计划框架，该框架生成高速，无碰撞和动态的轨迹。为了有效，可靠地解决这个非线性，有限的问题，我们开发了有效的可行性求解器，有效的可行性优化求解器（EFOPT），该求解器（EFOPT）是为尾随无用的在线规划而定制的。我们进行了广泛的模拟研究，以基于EFOPT在计划任务上对传统的非线性编程求解器的优势。我们还展示了在各种现实环境中，包括室内实验室，地下停车场和室外公园在内的各种现实环境中，具有高达15 m/s的积极自主航班的详尽实验。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10829730</guid>
      <pubDate>Mon, 06 Jan 2025 13:17:34 GMT</pubDate>
    </item>
    <item>
      <title>Riemannian优化机器人团队主动映射</title>
      <link>http://ieeexplore.ieee.org/document/10829726</link>
      <description><![CDATA[使用一组移动机器人对未知环境的自主探索需要分布的感知和计划策略，以实现高效且可扩展的性能。理想情况下，每个机器人都应更新其地图并计划其运动不仅依赖于自己的观察结果，还要考虑其同龄人的观察结果。多机器人协调的集中解决方案容易受到中央节点故障的影响，并且需要一个复杂的通信基础架构才能可靠。当前的分散活跃映射方法考虑使用线性高斯观测和欧几里得机器人状态的简单机器人模型。在这项工作中，我们提出了一种分布式的多机器人映射和计划方法，称为主动映射（ROAM）的Riemannian优化。我们通过图表进行优化问题，该图形具有属于Riemannian歧管的节点变量，并共识约束，需要可行的解决方案以同意节点变量。我们开发了一种分布式的Riemannian优化算法，该算法仅依赖于单跳通信来通过共识和最佳保证来解决问题。我们表明，可以通过我们的分布式Riemannian优化的两个应用程序来实现多机器人主动映射，这可以在不同的歧管上进行优化：对$ \ text {se}（3）$轨迹的3-D语义图和分布式计划的分布式估计，以最大程度地减少地图不确定。我们使用带有RGB-D摄像机的机器人团队在模拟和现实世界实验中漫游的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10829726</guid>
      <pubDate>Mon, 06 Jan 2025 13:17:17 GMT</pubDate>
    </item>
    <item>
      <title>使用高斯工艺运动提前连续时间持续惯性和激光惯性进程</title>
      <link>http://ieeexplore.ieee.org/document/10816238</link>
      <description><![CDATA[在这项工作中，我们使用高斯工艺运动表明了连续的时间持续惯性和激光惯性探射仪。使用稀疏的先验，我们证明了在预融合和插值过程中的计算复杂性提高。我们先前使用白色噪声运动，并将陀螺仪视为对状态的直接测量，同时预先整合加速度计测量以形成相对速度因子。我们的探针法是使用滑动窗口批处理轨迹估计实现的。据我们所知，我们的工作是第一个使用陀螺仪和加速度计测量值旋转机械雷达来证明持续惯性射测的方法。通过合并惯性测量单元，我们将雷达音量计的性能提高了43％。我们的方法是有效的，我们展示了实时性能。可以在以下网址找到本文的代码：https：//github.com/utiasasrl/steam_icp。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10816238</guid>
      <pubDate>Wed, 25 Dec 2024 13:17:25 GMT</pubDate>
    </item>
    <item>
      <title>通过仿生光学触觉传感器整合类似人类的阻抗调节和基于模型的方法来歧视合规性歧视</title>
      <link>http://ieeexplore.ieee.org/document/10816065</link>
      <description><![CDATA[基于仿生的授予机器人具有先进的触觉能力，涉及设计类似人类的触觉传感器，计算模型和运动控制策略以增强接触信息的检索。在这里，我们考虑使用柔软的仿生触觉光学传感器（TACTIP）的合规性歧视。在先前的工作中，我们提出了一种基于视觉的方法，该方法是从人类触觉感知的计算模型中得出的，以基于接触区域扩散计算在缩进力量上扩展计算，以区分对象符合tactip。在这项工作中，我们首先通过对初始接触区域条件进行更精确的估计，提高了基于视觉方法的鲁棒性，当探测方向与试样表面的正常状态相比时，这也可以正确遵守估计。然后，我们将人类在对象合规性探测过程中采用的内部肌肉调节（共同收缩）的机制集成到了验证中，以最大程度地提高信息的吸收。为此，我们使用了在物体柔软探测过程中提取的人类共同收缩模式来控制可变的刚度执行器（模拟人类肌肉的激动性 - 抗抗酸行为），该模式用于驱动与对象合规性探索的策略有关的凹痕系统。我们发现，我们基于模型的合规性歧视方法，以更精确的估计初始条件喂养，就刚性执行器的使用而言，随着人类启发的阻抗调节有了显着改善。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10816065</guid>
      <pubDate>Wed, 25 Dec 2024 13:17:23 GMT</pubDate>
    </item>
    <item>
      <title>SE（3）上连续多机器人系统的状态估计</title>
      <link>http://ieeexplore.ieee.org/document/10816239</link>
      <description><![CDATA[与常规机器人相反，由于部分未知的材料特性，寄生效应或作用于连续体内的不明力量，对连续机器人的运动学和静电量进行了准确的建模。因此，利用其他传感器信息来预测连续机器人形状的状态估计方法引起了重大兴趣。本文提出了一种对具有多个耦合连续机器人的系统的状态估计的新方法，该系统允许在任意耦合拓扑中估算多个连续机器人的形状和应变变量。模拟和实验证明了该方法的能力和多功能性，同时对此类系统状态进行了准确，连续的估计，从而导致平均最终效果误差为3.3 mm和5.02 $^\ circ $，具体取决于传感器的设置。进一步表明，该方法提供了低于10毫秒的快速计算时间，从而在准静态实时场景中使用了其利用率，平均更新速率为100-200 Hz。拟议的状态估计方法的开源C ++实施可公开提供给社区。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10816239</guid>
      <pubDate>Wed, 25 Dec 2024 13:17:23 GMT</pubDate>
    </item>
    <item>
      <title>FAPP：在动态杂乱的环境中，无人机的快速和自适应感知和计划</title>
      <link>http://ieeexplore.ieee.org/document/10816005</link>
      <description><![CDATA[在混乱的环境中避免未扎的飞机（UAV）的障碍物非常具有挑战性。现有的无人机避免障碍物要么专注于完全静态环境，要么只有几个动态对象。在本文中，我们主动考虑在动态混乱的环境中避免无人机的障碍，在这种环境中，动态对象是主要对象。这种环境对感知和计划都构成了重大挑战。多个动态对象具有各种动作，因此很难使用一个运动模型来估计和预测其动作。计划必须高效，以避免混乱的动态对象。本文提出了在复杂的动态混乱环境中飞行的无人机，并计划快速，适应性的感知和计划。提出了一种新颖有效的云分割策略，以区分静态和动态对象。为了解决不同动作的多个动态对象，提出了一种具有协方差自适应的自适应估计方法，以快速而准确地预测其动作。我们提出的轨迹优化算法高效，使其能够避免快速对象。此外，提出了一种自适应重新植物方法来解决轨迹优化找不到可行解决方案的情况，这对于动态混乱环境而言是常见的。模拟和现实世界实验的广泛验证证明了我们提出的系统对高度动态和混乱的环境的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10816005</guid>
      <pubDate>Wed, 25 Dec 2024 13:16:54 GMT</pubDate>
    </item>
    <item>
      <title>在具有超声波式换能器阵列和显微镜的复杂环境中，选择性，健壮和精确操纵颗粒</title>
      <link>http://ieeexplore.ieee.org/document/10816248</link>
      <description><![CDATA[颗粒，生物样本，液滴和气泡的非连接声操作在生物学，化学，药物等领域已成为一种有前途的技术。非接触性质在生物相容性，污染的自由和材料多功能性方面具有显着优势。但是，当前的非接触声音操纵技术仍然缺乏足够的选择性，鲁棒性和在复杂环境中的精确可控性。为此，在本文中，我们提出了一个自动化的非接触操作系统，该系统利用高密度的超声波循环传感器阵列与显微镜结合使用，以进一步优化和增强非连接粒子操纵的可控性和灵活性。这项工作提出了几项显着的贡献。首先，我们成功地实现了选择性粒子的操纵，从而允许与用户进行瞬时交互，以执行用户指定和目标的操纵任务。其次，我们将一个闭环控制策略集成到系统中，该策略有效地减轻了由声学陷阱的陷阱刚度异质性引起的未对准误差，并实现了复杂环境中颗粒的自动精确位置控制（在30 mm宽的工作区中，位置精度为波长的1/40）。第三，我们提出了一种可重构的声学陷阱设计方法，该方法名为Pseudovortex陷阱，具有比波长大的实时计算和捕获粒子。本文详细介绍了系统设置，校准细节，声学陷阱设计方法和相应的视觉伺服控制方案（就选择性陷阱，精度定位和动态轨迹计划而言）。同时，在这项工作中还分析了捕获刚度和操纵稳定性。实验结果很好地证明了拟议系统的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10816248</guid>
      <pubDate>Wed, 25 Dec 2024 13:16:54 GMT</pubDate>
    </item>
    <item>
      <title>Swarm-Lio2：空中群体系统的分散式激光辐射式辐射仪</title>
      <link>http://ieeexplore.ieee.org/document/10816004</link>
      <description><![CDATA[空中群体在各个方面具有巨大的潜力，例如合作探索，目标跟踪以及搜索和救援。有效准确的自我和相互状态估计是完成这些群体任务的关键前提，这些任务仍然具有挑战性。本文提出了Swarm-Lio2，这是一种完全分散的，插件，计算效率和带宽有效的光检测和范围（LIDAR） - 用于空中群体系统的孔态。 Swarm-Lio2使用分散的插件网络作为通信基础架构。仅交换带宽效率和低维信息，包括身份，自我状态，相互观察测量和全球外部转换。为了支持新队友参与者的插头，Swarm-Lio2检测了潜在的队友自动飞机（AAV），并将时间偏移和全球外部转换均自动初始化。为了提高初始化效率，提出了基于反射率的AAV检测，轨迹匹配和因子图优化方法。为了进行状态估计，在有效的误差状态迭代迭代的卡尔曼滤波器（ESIKF）框架内，群体LIO2融合了激光雷达，惯性测量单元和相互观察测量值，并仔细补偿了时间延迟和测量值的建模以提高准确性和一致性。此外，提议的ESIKF框架在激光雷达变性的情况下利用了自我状态估计的全球外部外部框架，或者否则会完善全球外部外部外部估计以及EGO状态估计。为了增强可扩展性，Swarm-Lio2在ESIKF中引入了一种新型边缘化方法，从而防止了计算时间的生长，其大小。广泛的仿真和现实世界实验表明，对大规模空中群体系统和复杂情况的广泛适应性，包括摄像机或激光镜头的被GPS贬低的场景和退化场景。实验结果展示了厘米级的定位精度，该精度优于单个AAV系统的其他最先进的激光惯性射测。此外，不同的应用表明了群体LIO2作为各种空中群任务的可靠基础设施的潜力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10816004</guid>
      <pubDate>Wed, 25 Dec 2024 13:16:54 GMT</pubDate>
    </item>
    <item>
      <title>任务驱动的分配转移检测具有机器人学习的统计保证</title>
      <link>http://ieeexplore.ieee.org/document/10815081</link>
      <description><![CDATA[我们的目标是执行分布外（OOD）检测，即检测机器人何时在与训练机器人的不同分布中绘制的环境中进行操作。我们利用大约正确的巴约斯理论来培训一项保证的培训绩效的政策。我们对OOD检测的想法取决于以下直觉：违反在测试环境上绑定的绩效提供了证据，证明机器人正在操作OOD。我们通过基于$ p $值和集中不平等的统计技术对此进行正式化。该方法为OOD检测提供了保证的置信界限，包括探测器的假阳性和错误阴性率的界限，并且是任务驱动的，并且仅对影响机器人性能的变化敏感。我们在模拟和硬件方面展示了使用陌生形状或姿势的对象以及无人机在具有风干扰和各种障碍物密度的环境中避免基于视觉的障碍物的对象。我们的示例表明，我们可以在少数几次试验中执行任务驱动的OOD检测。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10815081</guid>
      <pubDate>Tue, 24 Dec 2024 13:16:51 GMT</pubDate>
    </item>
    <item>
      <title>具有透明视觉传感器的多模式和力匹配的模仿学习</title>
      <link>http://ieeexplore.ieee.org/document/10814647</link>
      <description><![CDATA[与机器人操纵的接触量富裕的任务继续构成许多挑战。在这项工作中，我们利用模仿学习框架内的多模式视觉传感器（IL）来执行涉及终端效果和操纵对象之间相对运动（例如滑动和滑动）的接触率丰富的任务。我们介绍了两种算法贡献，触觉力匹配和学习模式切换，作为改善IL的免费方法。触觉力匹配可以通过在演示过程中阅读近似力来增强动力学教学，并产生一个适应性的机器人轨迹，从而重新创建记录的力量。学习的模式切换使用IL将视觉和触觉传感器模式与学习的运动策略相结合，从而简化了从达到接触到接触的过渡。我们对四个开门任务进行了机器人操纵实验，并具有各种观察和算法配置，以研究多模式视觉效果感应的实用性以及我们提出的改进。我们的结果表明，将力匹配的包括将平均策略成功率提高了62.5％，视觉actactile模式的切换增加了30.3％，并且Visuotactile数据作为策略输入42.5％，强调了IL的透明触觉感知的价值，既可以允许数据收集的功能匹配，又可以执行准确的任务返还。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10814647</guid>
      <pubDate>Tue, 24 Dec 2024 13:16:51 GMT</pubDate>
    </item>
    <item>
      <title>生成图形逆运动学</title>
      <link>http://ieeexplore.ieee.org/document/10814707</link>
      <description><![CDATA[对于许多机器人操纵器来说，快速，可靠地找到准确的逆运动学（IK）解决方案仍然是一个具有挑战性的问题。现有的数值求解器广泛适用，但通常仅产生单个解决方案，并依靠本地搜索技术来最大程度地减少非convex目标函数。近似于整个可行解决方案集的最新基于学习的方法在生成多个快速准确的IK并并联时表现出了希望。但是，现有的基于学习的技术具有重要的缺点：每个感兴趣的机器人都需要一个专门的模型，必须从头开始训练。为了解决这一关键缺点，我们提出了一种新颖的距离几何机器人表示形式，并结合了图形结构，使我们能够利用图神经网络（GNNS）的概括性。我们称之为生成图形IK（GGIK）的方法是第一个学到的IK求解器，能够并行能够有效地产生大量不同的解决方案，同时也显示出概括的能力 - 单个学习的模型可用于为各种不同机器人生产IK解决方案。与其他几种学到的IK方法相比，GGIK提供了具有相同数量的培训数据的更准确的解决方案。 GGIK在培训期间也可以很好地概括为机器人操纵器。此外，GGIK能够学习一个约束的分布，该分布编码关节限制，并与机器人接头和采样溶液的数量很好地缩放。最后，GGIK可用于通过为本地优化过程提供可靠的初始化来补充本地IK求解器。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10814707</guid>
      <pubDate>Tue, 24 Dec 2024 13:16:51 GMT</pubDate>
    </item>
    <item>
      <title>通过基于自适应阶段的入学控制的路径约束触觉运动指导</title>
      <link>http://ieeexplore.ieee.org/document/10814694</link>
      <description><![CDATA[机器人在力量和准确性方面超越了人类，但人类在面对不可预测的干扰时保留了无与伦比的决策能力。本文旨在将两个实体的优势结合在一个奇异的任务中：在严格的几何约束下，人类运动指导，尤其是遵守预定的路径。为了应对这一挑战，提出了一个模块化的触觉指导法，该法律将人为扳手作为输入。使用称为相位的辅助变量，可以保证生成的所需运动始终遵循约束路径。它证明了如何将指导策略推广到物理上可解释的术语中，可以在启动任务之前进行调整，或在进行任务时动态。此外，还展示了一个说明性的指导适应政策，以考虑到人类的操纵性。利用被动性分析，潜在的不稳定性来源是精确的，随后，通过合并增强的虚拟能源罐来确保整体系统稳定性。最后，包括20个参与者的用户研究在内的一组全面的实验探讨了实践中该方法的各个方面，涵盖了技术和可用性考虑因素。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10814694</guid>
      <pubDate>Tue, 24 Dec 2024 13:16:51 GMT</pubDate>
    </item>
    <item>
      <title>通过选举和真空致动，增强层流堵塞可变刚度</title>
      <link>http://ieeexplore.ieee.org/document/10804650</link>
      <description><![CDATA[已经开发出各种可变的刚度机制，可以通过改变机器人的机械行为来赋予机器人界的新功能。但是，可变刚度在致动，响应速度，刚度比以及最重要的是建模方面有限。本文提出了混合动态层层层压，以优于个体驱动的可变刚度机制。首先构建了用于准确表征机械行为的多层层流的分析模型。基于此模型的综合参数分析是层状干扰性能改进的设计指南。前馈控制进一步证明了所提出的模型的有效性，并具有良好的可控性，显示响应速度的速度最快为5 ms。当选和真空致动之间的协同作用显着提高了整体性能，从而产生的影响远大于个人贡献。例如，所提出的设备产生的高刚度几乎无法实现单个真空度或选举。此外，真空增加了击穿电压的23％，从而导致较大的选举力量，从而增加较高的刚度。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10804650</guid>
      <pubDate>Tue, 17 Dec 2024 13:18:23 GMT</pubDate>
    </item>
    </channel>
</rss>