<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 机器人与自动化快报 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物目录提醒# 7083369</description>
    <lastBuildDate>Thu, 19 Dec 2024 05:00:00 GMT</lastBuildDate>
    <item>
      <title>在不同身体耦合任务中单独和协作三手操作多肢的比较</title>
      <link>http://ieeexplore.ieee.org/document/10792937</link>
      <description><![CDATA[通过使用机器人的额外肢体，有人提出，单个用户可以执行目前需要团队合作才能完成的手术或工业装配等任务。尽管通常在虚拟现实中进行的验证研究已经表明，个人可以学会控制额外肢体，但比较结果通常表明，团队最初的表现优于操作额外肢体的个人。在这项研究中，我们研究了 (i) 使用市售的物理机器人设置而不是虚拟现实系统的影响，以及 (ii) 肢体耦合对用户在一系列三手操作过程中的表现的影响。与先前的研究结果相反，我们的结果表明，在作为三手用户工作时，在拾取和放置三个物体时，与作为团队工作时相比，用户的表现没有明显差异。此外，对于这项任务，我们观察到，虽然用户在控制大多数肢体时更喜欢与伙伴合作，但我们发现，他们在单独三手操作和与伙伴合作并控制第三肢体时的偏好没有明显差异。这些发现表明，视觉遮挡和触觉反馈等虚拟现实中通常不存在的因素对于多余肢体的有效操作可能是至关重要的，并为多余肢体在一系列身体任务中的可行性提供初步证据。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10792937</guid>
      <pubDate>Wed, 11 Dec 2024 13:19:15 GMT</pubDate>
    </item>
    <item>
      <title>双臂机器人协同运动控制的自适应噪声抑制策略</title>
      <link>http://ieeexplore.ieee.org/document/10783029</link>
      <description><![CDATA[双臂机器人具有良好的协作能力与多功能性，在各个领域展现出广阔的应用前景。作为双臂机器人的一个重要研究领域，对协调运动控制的要求也逐渐提高。在实际应用中，机器人不可避免地会受到噪声干扰，导致协调运动控制性能达不到最优。本文研究了谐波噪声下的双臂机器人协同运动控制。在相对雅可比方法的基础上，提出了一种自适应噪声抑制策略，用于受谐波噪声干扰的双臂机器人协同运动控制。该策略加入了补偿器，可以模拟和抑制谐波噪声的干扰。理论分析表明，所提策略产生的笛卡尔误差表现出收敛性。在两个Panda机器人机械手组成的双臂系统下的仿真和实验结果进一步验证了所提策略在谐波噪声存在下的抗噪性和适用性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10783029</guid>
      <pubDate>Mon, 09 Dec 2024 13:21:16 GMT</pubDate>
    </item>
    <item>
      <title>使用带圆圈放置的约束优化进行摄像头-LiDAR 外部校准</title>
      <link>http://ieeexplore.ieee.org/document/10778314</link>
      <description><![CDATA[单目相机-激光雷达数据融合在各个领域都表现出了卓越的环境感知能力。数据融合的成功依赖于图像和点云中对应特征的准确匹配。在本文中，我们提出了一种基于目标的相机-激光雷达外部校准方法，通过匹配两种数据中的对应关系。具体来说，为了从点云中提取准确的特征，我们提出了一种新方法，通过优化初始位置的概率分布来估计圆心。该优化涉及从圆边缘点生成圆心的概率分布，并使用拉格朗日乘数法估计圆心的最佳位置。我们进行了两种类型的实验：定量结果的模拟和定性评估的真实系统评估。与现有方法相比，我们的方法在 20 个目标姿势的模拟校准性能上表现出了 $\mathbf{\text{0.03}\,m}$ 的提升，并且在将点云重新投影到真实场景中的图像上时也表现出较高的视觉质量。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10778314</guid>
      <pubDate>Thu, 05 Dec 2024 13:19:17 GMT</pubDate>
    </item>
    <item>
      <title>CusADi：用于符号表达式和最优控制的 GPU 并行化框架</title>
      <link>http://ieeexplore.ieee.org/document/10778410</link>
      <description><![CDATA[GPU 提供的并行性在通过强化学习 (RL) 训练控制器方面具有显著优势。然而，将基于模型的优化集成到这一过程中仍然具有挑战性，因为在数千个实例中制定和解决优化问题的复杂性。在这项工作中，我们提出了 CusADi，这是 casadi 符号框架的扩展，用于支持使用 CUDA 在 GPU 上并行化任意闭式表达式。我们还制定了一个闭式近似来解决一般最优控制问题，从而实现 MPC 控制器的大规模并行化和评估。我们的结果显示，与 CPU 上的类似 MPC 实现相比，速度提高了十倍，并且我们展示了 CusADi 在各种应用中的使用，包括并行模拟、参数扫描和策略训练。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10778410</guid>
      <pubDate>Thu, 05 Dec 2024 13:18:54 GMT</pubDate>
    </item>
    <item>
      <title>CMIF-VIO：一种用于视觉惯性里程计的新型跨模态交互框架</title>
      <link>http://ieeexplore.ieee.org/document/10777572</link>
      <description><![CDATA[视觉惯性里程计 (VIO) 通过自身运动估计预测轨迹。随着人工智能的普及，基于深度学习的 VIO 方法表现出比传统基于几何的 VIO 方法更好的性能。然而，在深度学习方法中，如何更好地实现来自摄像机的视觉图像与来自 IMU 传感器的惯性测量单元 (IMU) 测量之间的融合和互补以输出准确的姿态仍然是一个挑战。在本文中，我们提出了一种新颖的 VIO 跨模态交互框架，称为 CMIF-VIO，它提高了 VIO 的准确性并具有良好的实时性。具体而言，我们首先使用现有的主干网络并构建一个简单的主干网络分别从摄像机和 IMU 中提取特征，确保低复杂度。然后，我们探索了一种自适应地集成来自不同模态特征的信息的跨模态交互模块，实现视觉和 IMU 模态特征之间的深度交互，同时保持每个模态分支中的特征主导地位。最后，引入长短期记忆（LSTM）网络来建模时间运动相关性并输出高精度六自由度（6-DOF）位姿。实验结果表明，我们的方法与最先进的VIO方法相比表现出更好的性能，其实时性可以满足实际应用场景的需求。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10777572</guid>
      <pubDate>Wed, 04 Dec 2024 13:19:19 GMT</pubDate>
    </item>
    <item>
      <title>使用基于视觉的管道实现人机软切换</title>
      <link>http://ieeexplore.ieee.org/document/10777566</link>
      <description><![CDATA[交接物体是人机协作场景中的一项重要任务。先前的研究主要使用刚性夹持器进行交接，重点是避免与人身体接触的抓握。在本文中，我们提出了一种基于视觉的张开手掌交接解决方案，其中软机械手利用与人手的接触来提高抓握成功率和稳健性。人机物理交互使机械手可以滑过人手手掌并牢固地抓住物体。通过利用单个 RGB-D 摄像头的多功能感知管道，可以识别人手平面和物体姿势。通过实验，我们表明该系统可以成功抓取具有不同几何形状和纹理的多个物体。比较分析评估了所提出的软交接方法与基线方法的稳健性。一项有 30 名参与者的研究评估了用户在交接过程中对人机交互的感知，突出了所提出的管道的有效性和偏好。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10777566</guid>
      <pubDate>Wed, 04 Dec 2024 13:19:19 GMT</pubDate>
    </item>
    <item>
      <title>ChatEMG：用于控制中风机械手矫形器的合成数据生成</title>
      <link>http://ieeexplore.ieee.org/document/10777608</link>
      <description><![CDATA[由于数据收集困难，对中风患者的手部矫形器进行意图推断具有挑战性。此外，EMG 信号在不同条件、会话和主题之间表现出显著差异，这使得分类器难以概括。传统方法需要来自新条件、会话或主题的大量标记数据集来训练意图分类器；然而，这个数据收集过程既繁琐又耗时。在这封信中，我们提出了 ChatEMG，这是一种自回归生成模型，可以生成以提示（即给定的 EMG 信号序列）为条件的合成 EMG 信号。ChatEMG 使我们能够从新条件、会话或主题中仅收集一小部分数据集，并使用以来自这一新上下文的提示为条件的合成样本对其进行扩展。ChatEMG 通过生成训练利用了大量以前的数据，同时仍然通过提示保持上下文特定性。我们的实验表明，这些合成样本与分类器无关，可以提高不同类型分类器的意图推断准确性。我们证明，我们的完整方法可以集成到单个患者会话中，包括使用分类器执行功能性矫形器辅助任务。据我们所知，这是第一次部署部分基于合成数据训练的意图分类器，供中风幸存者对矫形器进行功能控制。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10777608</guid>
      <pubDate>Wed, 04 Dec 2024 13:19:19 GMT</pubDate>
    </item>
    </channel>
</rss>