<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 机器人与自动化快报 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物目录提醒# 7083369</description>
    <lastBuildDate>Wed, 17 Jul 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于注意力机制的分布式强化学习，实现安全高效的自动驾驶</title>
      <link>http://ieeexplore.ieee.org/document/10604470</link>
      <description><![CDATA[自动驾驶汽车在智能交通系统中发挥着重要作用，并引起了广泛关注。目前，自动驾驶系统中流行的方法是为每个独立模块设计单独的最优目标。因此，人们主要担心的是，这些不同的最优目标可能会对最终的驾驶策略产生影响。然而，强化学习通过联合训练和探索能力提供了一种有前途的解决方案来应对这一挑战。这封信旨在开发一种安全、高效、具有先进功能的强化学习方法，用于城市交通场景中的自主导航。首先，我们开发了一种新颖的分布式强化学习方法，将隐式分布模型集成到演员-评论家框架中。随后，我们引入了一个空间注意模块来捕捉自我车辆与其他交通车辆之间的交互特征，并设计了一个时间注意模块来提取长期顺序特征。最后，我们利用鸟瞰图作为交通场景的上下文感知表示，并融合上述时空特征。为了验证我们的方法，我们在 NoCrash 和 CoRL 基准上进行了实验，特别是在我们的闭环 openDD 场景上。实验结果表明，与基线相比，我们的方法在收敛性和稳定性方面具有令人印象深刻的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10604470</guid>
      <pubDate>Thu, 18 Jul 2024 13:17:19 GMT</pubDate>
    </item>
    <item>
      <title>TSCL：针对动作分割的时间戳监督对比学习</title>
      <link>http://ieeexplore.ieee.org/document/10598312</link>
      <description><![CDATA[时间动作分割是理解复杂人类活动序列和识别人类动作之间长期依赖关系的重要任务。这对于有效的非语言人机协作和机器人辅助理解人类的潜在意图至关重要。为了最大限度地减少标记工作量，我们专注于时间戳监督设置，其中每个动作片段在随机选择的时间点仅提供一个标签。这大大减少了标记工作量，从而提高了对更大的现实世界数据集的可扩展性。我们提出了一种基于对比学习的方法，该方法加强了相同动作的视频片段特征的相似性，并对比了不同动作的特征。我们的边界估计算法用于确定相对于地面真实时间戳标签的负集和正集。此外，我们提出的损失函数进一步惩罚不属于封闭时间戳的任何动作标签的预测。在四个公共数据集上对我们方法的评估表明，与不同环境中的最新技术相比，我们的方法有显着的改进，并且与以完全监督的方式训练的模型相比，产生了具有竞争力的结果。我们的方法进一步适用于半自动注释。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10598312</guid>
      <pubDate>Mon, 15 Jul 2024 13:17:21 GMT</pubDate>
    </item>
    <item>
      <title>具有解耦运动模式的混合驱动连续机器人，可实现灵巧操作</title>
      <link>http://ieeexplore.ieee.org/document/10598325</link>
      <description><![CDATA[连续机器人在探索非结构化环境时始终表现出很强的适应性，在实现人机交互时也具有很高的安全性。为了进一步提高它们的灵活性，这些机器人必须集成弯曲和伸长运动模式。然而，采用统一的驱动策略将不可避免地导致这些模式之间的运动耦合，这对预测和调节变形轮廓提出了重大挑战。在本文中，我们受到大象鼻子肌肉纤维中观察到的运动调节的启发，提出了一种混合驱动的模块化连续机器人。这种机器人配置能够通过各种方法调节运动模式，从而实现对弯曲和伸长运动的独立控制。在这里，模块的每个主干不仅产生 62.76 ± 0.01% 的伸长率，而且还变形为角度为 35.53 ± 1.18° 的弯曲轮廓。然后，通过对由三个模块组成的单节连续体机器人进行理论和实验研究，我们证明了将弯曲和伸长运动模式的驱动方法分开可以有效缓解运动耦合，从而提高连续体机器人的运动精度。此外，我们还展示了两节连续体机器人的多功能性，通过组合不同的运动模式，它可以变形成各种不同的形态，用于抓取、移动和释放物品。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10598325</guid>
      <pubDate>Mon, 15 Jul 2024 13:17:18 GMT</pubDate>
    </item>
    <item>
      <title>TNDF-Fusion：用于大型城市环境中 LiDAR 密集测绘和定位的隐式截断神经距离场</title>
      <link>http://ieeexplore.ieee.org/document/10598317</link>
      <description><![CDATA[大规模 3D 地图绘制是机器人和自动驾驶的重要任务。然而，硬件资源有限的移动机器人和自动驾驶汽车可能会面临内存消耗大的问题。在地图绘制质量和内存消耗之间取得平衡是一项挑战。为了解决这个问题，我们提出了一种新的紧凑隐式神经图表示 - 三金字塔，它可以在给定任意 3D 位置的情况下推断截断神经距离场 (TNDF)。此外，我们引入了一种 TNDF 标签校正方法，该方法同时考虑地面法线和最近表面点的方向，以提高监督信号的精度，并使用一组有效的损失函数进行训练。在公共数据集上的实验表明，与以前的 LiDAR 地图绘制方法相比，我们的方法在密集地图绘制方面达到了相当或更优异的性能，同时显着降低了内存消耗。此外，我们的研究证实了我们的方法从房间规模到城市规模场景的可扩展性和适应性。此外，我们通过解决优化问题探索了直接利用隐式神经图表示进行定位任务的潜力。实验展示了我们的方法在各种场景中的精确定位能力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10598317</guid>
      <pubDate>Mon, 15 Jul 2024 13:17:18 GMT</pubDate>
    </item>
    <item>
      <title>一种用于增强水下图像和识别水下多场景海参的多尺度卷积混合注意残差网络</title>
      <link>http://ieeexplore.ieee.org/document/10595499</link>
      <description><![CDATA[目前利用水下机器人替代水下人工作业是未来的发展方向，复杂多变的水下环境给机器人作业带来很大困难。为了改善海参图像色彩失真与退化问题，增加海参检测的准确率与稳定性，本文提出了一种数据驱动的多尺度卷积混合注意残差增强网络（MCRNet）。首先，采用考虑各颜色通道差异的增益因子中和水下图像的色彩偏差。其次，提出一种多尺度卷积融合模块，提取不同尺度下的浅层特征信息。构建多个残差块与混合注意模块，专注于提取图像中的深层特征，网络整体的残差连通性有助于保留浅层信息。实验结果表明,与未处理的四类海参图像相比,本文方法在图像质量评价指标UCIQE和UIQM上分别提高了63.96%和44.50%,海参平均检测准确率提高了4.7%。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10595499</guid>
      <pubDate>Thu, 11 Jul 2024 13:17:11 GMT</pubDate>
    </item>
    <item>
      <title>SemanticFormer：使用知识图谱进行轨迹预测的整体和语义交通场景表示</title>
      <link>http://ieeexplore.ieee.org/document/10592819</link>
      <description><![CDATA[自动驾驶中的轨迹预测依赖于对驾驶场景所有相关背景的准确表示，包括交通参与者、道路拓扑、交通标志以及它们之间的语义关系。尽管人们越来越关注这个问题，但大多数轨迹预测方法并没有充分考虑所有这些因素。我们提出了 SemanticFormer，这是一种通过使用混合方法对语义交通场景图进行推理来预测多模态轨迹的方法。它利用元路径形式的高级信息，即知识图中允许代理驾驶的轨迹，然后由基于多种注意机制的新型管道对其进行处理，以预测准确的轨迹。SemanticFormer 包含一个分层异构图编码器，用于捕获跨代理以及代理与道路元素之间的时空和关系信息。此外，它还包括一个预测器，用于融合不同的编码并使用概率解码轨迹。最后，细化模块评估轨迹和速度曲线的允许元路径，以获得最终的预测轨迹。nuScenes 基准的评估表明，与几种 SOTA 方法相比，其性能有所提高。此外，我们证明我们的知识图谱可以轻松添加到两种基于图的现有 SOTA 方法中，即 VectorNet 和 LaFormer，以取代它们原来的同构图。评估结果表明，通过添加我们的知识图谱，原始方法的性能分别提高了 5% 和 4%。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10592819</guid>
      <pubDate>Wed, 10 Jul 2024 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>DOZE：动态环境中开放词汇零样本对象导航的数据集</title>
      <link>http://ieeexplore.ieee.org/document/10592634</link>
      <description><![CDATA[零样本物体导航 (ZSON) 要求智能体在陌生环境中自主定位和接近未见过的物体，这已成为具身人工智能领域中一项特别具有挑战性的任务。现有的用于开发 ZSON 算法的数据集缺乏对动态障碍物、物体属性多样性和场景文本的考虑，因此与现实世界的情况存在明显差异。为了解决这些问题，我们提出了一个动态环境中开放词汇零样本物体导航数据集 (DOZE)，它包含十个高保真 3D 场景，包含超过 18,000 个任务，旨在模拟复杂、动态的现实世界场景。具体来说，DOZE 场景具有多个移动的人形障碍物、大量开放词汇物体、各种不同属性物体和有价值的文本提示。此外，与仅提供智能体与静态障碍物之间碰撞检查的现有数据集不同，我们通过集成检测智能体与移动障碍物之间碰撞的功能来增强 DOZE。这项新功能可以评估代理在动态环境中的避碰能力。我们在 DOZE 上测试了四种代表性的 ZSON 方法，发现现有方法在导航效率、安全性和物体识别准确性方面还有很大的改进空间。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10592634</guid>
      <pubDate>Wed, 10 Jul 2024 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>形状 BoW：用于水深测量 SLAM 中基于外观的回环检测的广义词袋</title>
      <link>http://ieeexplore.ieee.org/document/10592307</link>
      <description><![CDATA[现有的水深测量同步定位与测绘 (SLAM) 方法主要依靠里程计信息进行回环检测，在处理不可靠的里程计数据或执行大规模测绘任务时，该方法的性能会下降。本信介绍了一种新型广义词袋 (BoW)，称为 Shape BoW (S-BoW)，用于水深测量 SLAM 中基于外观的回环检测。S-BoW 是根据从现有水深测量数据集中提取的地形梯度特征集合进行训练的，可用于各种水深测量场景。我们将使用 S-BoW 的回环检测方法集成到一种基于特征的水深测量 SLAM 方法 TTT SLAM 中，并使用两个数据集评估了它与三种现有水深测量 SLAM 方法的性能。结果表明，S-BoW 不仅可用作广义 BoW，而且还可提高集成 SLAM 方法的效率，在大规模海试数据集中实现与原始 TTT SLAM 相当的精度，同时将速度提高了 37%。据我们所知，S-BoW 是第一个可用于在水深 SLAM 中实现基于外观的有效回环检测的广义 BoW。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10592307</guid>
      <pubDate>Wed, 10 Jul 2024 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>通过距离感应学习局部城市风流场</title>
      <link>http://ieeexplore.ieee.org/document/10592305</link>
      <description><![CDATA[在城市环境中准确及时地预测风向是一项艰巨的任务，但对未来城市空域中自主飞行器的安全性和效率具有广泛的影响。先前的工作严重依赖于有关环境的全局信息，例如城市的精确地图和各个位置的现场风测量，以运行昂贵的计算流体动力学求解器来预测整个风流场。相比之下，这封信介绍了一种新方法，可以实时估计机器人周围区域的风流场，利用机载范围测量来感知附近的建筑物，并利用稀疏风测量来推断风速和风向。我们认为这些信息足以描述局部感兴趣区域的风流场结构。为此，我们引入了一种基于深度学习的方法来根据范围测量预测局部流场。我们的结果表明，通过小型随机地图对大量模拟风进行训练的神经网络能够重建局部风流，同时推广到拥有 200 多座建筑物的更大环境。这一贡献使计算受限的空中机器人能够推理局部风流场的结构，从而无需事先了解地图，就能在多风的城市环境中制定新的规划、控制和估计策略。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10592305</guid>
      <pubDate>Wed, 10 Jul 2024 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>TC$^{2}$LI-SLAM：紧耦合的摄像头-LiDAR-惯性 SLAM 系统</title>
      <link>http://ieeexplore.ieee.org/document/10592768</link>
      <description><![CDATA[在本信中，我们提出了 TC$^{2}$LI-SLAM，这是一种新型的紧耦合相机-LiDAR-惯性 SLAM 系统，具有分离的前端和统一的后端。得益于我们新颖的面向关键帧的数据同步方法，前端接受非相同频率输入并执行实时姿势估计，同时将不同的输入合并到后端的关键帧中。为了提高后端优化的准确性，我们创新地利用了基于关键帧的局部束调整问题中的多传感器连续共视约束。为了弥合优化问题中来自不同传感器的不同残差项之间的差距，我们提出了一种易于应用的跨模态残差标准化方法。此外，所提出的系统可以退化为 TC$^{2}$L-SLAM，这是一种没有 IMU 的紧耦合相机-LiDAR SLAM 系统，以应对惯性测量不可用或不可靠的情况。最后，在公开数据集和自录数据集上对 TC$^{2}$LI-SLAM 和 TC$^{2}$L-SLAM 进行了测试。结果表明，与最先进的 SLAM 系统相比，它们的准确度表现更佳，在 KITTI 数据集上，准确度最多比 ORB-SLAM3 提高 33%。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10592768</guid>
      <pubDate>Wed, 10 Jul 2024 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>通过高效的跨模态扩散模型实现密集而准确的雷达感知</title>
      <link>http://ieeexplore.ieee.org/document/10592769</link>
      <description><![CDATA[毫米波 (mmWave) 雷达因其能够在极端天气条件下工作的能力而引起了学术界和工业界的极大关注。然而，它们面临着稀疏性和噪声干扰方面的挑战，这阻碍了它们在微型飞行器 (MAV) 自主导航领域的应用。为此，本信提出了一种通过跨模态学习构建密集而准确的毫米波雷达点云的新方法。具体而言，我们引入了在生成建模中具有最先进性能的扩散模型，以从成对的原始雷达数据中预测类似 LiDAR 的点云。我们还结合了最新的扩散模型推理加速技术，以确保所提出的方法可以在 MAV 上实施。我们通过广泛的基准比较和实际实验验证了所提出的方法，证明了其卓越的性能和泛化能力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10592769</guid>
      <pubDate>Wed, 10 Jul 2024 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>基于扰动观测器的具有预定性能的电磁驱动微定位器的终端滑模控制</title>
      <link>http://ieeexplore.ieee.org/document/10592832</link>
      <description><![CDATA[由于电磁驱动微定位器的非线性电磁动力学特性以及其独特的结构和应用场景，对其进行精确平稳的控制是一项具有挑战性的任务。主要挑战包括高阶非线性、建模不确定性、输入抖振、滞后和易受干扰。为了解决这些综合因素，本文提出了一种复合控制方案。首先，引入一种新的自适应滑模扰动观测器，主要基于位置反馈，以消除外部扰动和不确定性的影响。实施反步策略，显著提高了扰动观测器在微定位系统中的实用性。然后提出了一种终端滑模控制器，以获得高鲁棒性和快速收敛性，同时采用规定的性能技术来保证瞬态和稳态响应特性。为了获得更高的精度，在该控制器中使用变换误差来构造积分型递归滑动流形。通过仿真和实验结果证明了所提方法的优越性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10592832</guid>
      <pubDate>Wed, 10 Jul 2024 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>用于反应任务和运动规划的多模态 MPPI 和主动推理</title>
      <link>http://ieeexplore.ieee.org/document/10592649</link>
      <description><![CDATA[任务和运动规划 (TAMP) 在复杂的操作任务中取得了长足进步，但规划解决方案的执行稳健性仍然被忽视。在这项工作中，我们提出了一种反应性 TAMP 方法来应对运行时的不确定性和干扰。我们结合了主动推理规划器 (AIP) 来进行自适应高级动作选择，以及新颖的多模态模型预测路径积分控制器 (M3P2I) 来进行低级控制。这导致了一种同时适应高级动作和低级运动的方案。AIP 生成备选符号计划，每个计划都与 M3P2I 的成本函数相关联。后者采用物理模拟器进行不同的轨迹部署，通过根据成本对不同样本进行加权来获得最佳控制。这个想法能够融合不同的机器人技能以实现流畅和反应性的计划执行，适应高级和低级的计划调整，例如，应对使当前计划无效的动态障碍或干扰。我们已经在模拟和真实场景中测试了我们的方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10592649</guid>
      <pubDate>Wed, 10 Jul 2024 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>ViewInfer3D：基于具身视点推理的 3D 视觉基础</title>
      <link>http://ieeexplore.ieee.org/document/10592798</link>
      <description><![CDATA[3D 视觉接地 (3D VG) 是具身智能中的一项基本任务，它需要机器人解释自然语言描述以在 3D 环境中定位物体。由于机器人根据其观察视点对物体的空间关系有不同的感知，因此这项任务的复杂性也随之显现。在这项工作中，我们提出了 ViewInfer3D，这是一个利用大型语言模型 (LLM) 来推断具身视点的框架，从而避免错误的观察视点。为了提高从具身视点进行推理的可靠性和速度，我们设计了三个子策略：构建分层 3D 场景图、实现具身视点解析和应用场景图推理。通过大量实验，我们证明该框架可以通过具身视点推理提高 3D 视觉接地任务的性能。我们的框架在 ScanRefer 和 Nr3D/Sr3D 数据集上实现了所有零样本方法中的最佳性能，并且不会显著增加推理时间。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10592798</guid>
      <pubDate>Wed, 10 Jul 2024 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>通过密集场景匹配进行深度单应性估计</title>
      <link>http://ieeexplore.ieee.org/document/10592770</link>
      <description><![CDATA[单应性估计是许多计算机视觉应用中的基本任务。最近，与传统方法相比，基于深度学习的方法已被证明有利于解决此问题。它们通常将单应性估计转换为回归 4 点偏移，可用于计算单应性矩阵。然而，这些方法通常使用隐式网络直接回归偏移并完全忽略匹配信息。隐式回归网络可能容易导致过度拟合，并且处理图像细节的表示能力有限。为了解决这些问题，我们提出了一种显式密集场景匹配策略，该策略引入匹配信息以在图像和偏移之间建立更合理的联系。在这种设计中，网络只需要学习简单的特征编码和信息交互任务，这大大降低了对网络表示能力的依赖。因此，所提出的显式策略可以在对齐图像细节方面带来更好的性能。基于密集场景匹配，我们提出了一个由三个子模型组成的由粗到细的网络来逐步对齐图像。实验结果表明，我们的方法优于最先进的单应性方法和多单应性方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10592770</guid>
      <pubDate>Wed, 10 Jul 2024 13:17:20 GMT</pubDate>
    </item>
    </channel>
</rss>