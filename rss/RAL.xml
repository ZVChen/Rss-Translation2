<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE机器人技术和自动化信 - 新的TOC</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>TOC警报出版＃7083369</description>
    <lastBuildDate>Wed, 26 Mar 2025 04:00:00 GMT</lastBuildDate>
    <item>
      <title>使用Koopman理论的球形机器人的在线系统识别算法</title>
      <link>http://ieeexplore.ieee.org/document/10933536</link>
      <description><![CDATA[这封信为球形机器人提出了一个新颖的线性在线标识框架，以解决非线性和随时间变化特征带来的建模困难。首先，将库普曼理论应用于球形机器人以构建线性模型以近似非线性。根据球形机器人的动力学选择一组可观测值之后，从数据中标识了模型。然后，提出了一种基于卡尔曼过滤器和噪声估计的新的在线系统标识算法，该算法实时更新模型以跟踪随时间变化的系统特性。实验表明，基于库普曼的线性模型符合非线性球形机器人长期预测的精确标准。通过Kalman Filter在线识别算法，模型参数可以实现稳定的收敛，准确跟踪由地形，负载和执行器等元素引起的系统更改。我们的算法的性能，鲁棒性和应用潜力大大超过了传统方法的性能。在为球形机器人的自适应控制提供基础之后，这项研究也是其他机器人和非线性系统”在线标识的有用参考。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10933536</guid>
      <pubDate>Thu, 20 Mar 2025 13:16:40 GMT</pubDate>
    </item>
    <item>
      <title>航空群遥控的第一人称视图接口</title>
      <link>http://ieeexplore.ieee.org/document/10933589</link>
      <description><![CDATA[空中群可以大大提高无人机在检查，监视和寻找救援等应用中的有效性。当这些群体是由几个单独的无人机制成的，这些无人机使用局部传感和协调规则来实现集体运动。尽管群体自治最近取得了进展，但人类控制和决策对于处于危险或人类认知技能的任务中仍然至关重要。但是，第一人称视图（FPV）的远程操作系统需要每个无人机的一个或多个人类操作员，从而将这些系统的可扩展性限制在群体上。这项工作调查了使用不同的FPV接口进行空中群的飞行员的性能，偏好和行为。实验研究了具有单一视角和多个视角的接口，人类通过障碍物驾驶模拟的空中群。发现参与者更喜欢和表现更好，可以从群体背面的视野中表现得更好，而前面的视图导致用户飞行更快，但导致了更多的崩溃。立即向用户提供多个视图导致完成时间较慢，并且发现用户专注于最大的视图，而不管其群中的观点如何。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10933589</guid>
      <pubDate>Wed, 19 Mar 2025 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>HER-DRL：单机器人和多机器人人群导航的异质关系深入学习</title>
      <link>http://ieeexplore.ieee.org/document/10933548</link>
      <description><![CDATA[近年来，人群导航引起了大量研究的关注，尤其是随着基于DRL的方法的出现。当前基于DRL的方法已广泛探索了单机器人方案中的交互关系。但是，通常会忽略多个相互作用关系的异质性。这种“互动盲点”阻碍了更复杂的场景，例如多机器人人群导航。在这封信中，我们提出了一种名为HER-DRL的异质关系深的增强学习方法，该方法利用定制的异质图神经网络（GNN）来提高人群导航中的整体性能。首先，我们设计了一种构建机器人弧异质关系图的方法，该图有效地模拟了异质的配对相互作用关系。基于此图，我们提出了一种新型的异质GNN来编码相互作用关系信息。最后，我们将编码的信息纳入深度强化学习中，以探索最佳政策。通过将单杆和多机器人圆形杂交场景中的最新算法进行比较，可以严格评估HER-DRL。实验结果表明，HER-DRL超过了整体表现的最新方法，在效率和舒适性方面尤其出色。这强调了人群导航中异质相互作用的重要性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10933548</guid>
      <pubDate>Wed, 19 Mar 2025 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>缪斯：四足机器人的实时多传感器状态估计器</title>
      <link>http://ieeexplore.ieee.org/document/10933515</link>
      <description><![CDATA[这封信介绍了创新的状态估计器MUSE（多传感器估算器），旨在提高国家估计的四倍机器人导航中的准确性和实时性能。拟议的状态估计量建立在我们以前在（Fink等，2020）中提出的工作。它集成了来自包括IMU，编码器，相机和LIDAR在内的一系列机载传感器的数据，以对机器人的姿势和运动进行全面可靠的估计，即使在湿滑的情况下也是如此。我们在一个单位Aliengo机器人上测试了Muse，在困难的情况下成功地关闭了机车控制环路，包括湿滑和不平坦的地形。针对Pronto（Camurri等，2020）和Vilens（Wisth等，2022）的基准分别显示了转化误差的67.6％和26.7％。此外，缪斯（Muse）的表现优于DLIO（Chen等，2023年），这是一种旋转错误和频率的激光持续操纵系统，而Muse（P-Muse）的本体感受版本优于TSIF [Bloesch等。 2018]，绝对轨迹误差降低了45.9％（ATE）。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10933515</guid>
      <pubDate>Wed, 19 Mar 2025 13:17:20 GMT</pubDate>
    </item>
    <item>
      <title>用手中的磁性传感的磁性螺旋机器人的姿势估计</title>
      <link>http://ieeexplore.ieee.org/document/10932690</link>
      <description><![CDATA[该字母提出了一种用于磁驱动螺旋机器人的基于磁性的姿势传感方法。与直接从磁场测量值中直接计算姿势的常规方法不同，所提出的方法通过从旋转磁场的空间特性与旋转磁场的空间特性与旋转磁场的空间特性与旋转磁场（PM）之间的分析关系（PM）之间的分析关系来解除由螺旋机器人的姿势引起的磁场成分。在准静态驱动条件下建立了双向旋转PM系统的磁场模型，通过考虑到驱动PM的效果来实现实时姿势估计。为了解决工作空间和信号质量限制，提出了一个手中配置的移动传感器阵列，以提高信噪比和高精度，实现了后续测量。该方法已在磁性驱动平台上进行了实验验证，结果表明，该方法可以使用有限数量的传感器进行大范围跟踪，并为在磁驱动的螺旋螺旋机器人中的连续实时姿势传感提供了强大的解决方案。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10932690</guid>
      <pubDate>Tue, 18 Mar 2025 13:19:55 GMT</pubDate>
    </item>
    <item>
      <title>双臂机器人计划生成的双臂相互作用的信息理论检测</title>
      <link>http://ieeexplore.ieee.org/document/10930577</link>
      <description><![CDATA[通过演示编程是一种通过人类示范来简化非专家的机器人编程过程的策略。但是，由于手工协调的复杂性，其对双人任务的采用是一个毫无疑问的问题，这也阻碍了数据记录。这封信提出了一种新颖的单发方法，用于处理一个双人任务演示的单个RGB视频，以生成双臂机器人系统的执行计划。为了检测手协调策略，我们应用香农的信息理论来分析场景元素和利用场景图属性之间的信息流。生成的计划是一个模块化行为树，它基于所需的武器协调假设不同的结构。我们通过多个主题视频演示验证了该框架的有效性，我们收集并制作了开放源代码，并从外部公开可用的数据集中利用数据。与现有方法的比较表明，在生成协调两臂系统的集中执行计划方面有了重大改进。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10930577</guid>
      <pubDate>Mon, 17 Mar 2025 13:19:42 GMT</pubDate>
    </item>
    <item>
      <title>不确定性感知的实时视觉异常检测与动态室内环境中的共形预测</title>
      <link>http://ieeexplore.ieee.org/document/10930535</link>
      <description><![CDATA[这封信提出了一个有效的视觉异常检测框架，旨在在动态室内环境（例如大学走廊）中安全自动导航。该方法在深度学习中采用了无监督的自动编码器方法，以对常规环境模式进行建模，并将异常视为嵌入空间中的偏差。为了提高可靠性和安全性，该系统整合了一个统计框架，共形预测，该预测提供了不确定性量化的概率保证。所提出的解决方案已在实时机器人平台上部署，证明了在资源约束条件下的有效性能。广泛的高参数优化确保模型保持动态性并适应变化，而严格的评估则证实了其在异常检测中的有效性。通过解决与实时处理和硬件限制相关的挑战，这项工作可以提高自主异常检测的最新技术。该框架提供的概率见解增强了操作安全，并为未来的发展铺平了道路，例如富裕的传感器融合和高级学习范式。这项研究突出了不确定性感知的深度学习的潜力，以增强安全监控框架，从而为现实世界应用提供了更可靠和智能的自主系统。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10930535</guid>
      <pubDate>Mon, 17 Mar 2025 13:19:41 GMT</pubDate>
    </item>
    <item>
      <title>可见性 - 可见性RRT*用于在未知环境中的感知限制机器人的安全至关重要的导航</title>
      <link>http://ieeexplore.ieee.org/document/10930526</link>
      <description><![CDATA[在未知环境中安全的自主导航仍然是具有有限感应能力的机器人的一个至关重要的挑战。尽管已经提出了诸如控制屏障功能（CBF）之类的安全控制技术来确保安全性，但其有效性依赖于机器人对周围环境完全了解的假设。实际上，机器人通常会以受限的视野和有限传感范围运行，如果计划者对这些限制不可知，这可能会导致遇到未知障碍的碰撞。为了解决此问题，我们介绍了可见性感知到的RRT*算法，该算法将基于抽样的计划与CBF结合在一起，以在部分未知的环境中生成安全有效的全球参考路径。该算法结合了避免碰撞的CBF和一种新颖的可见性CBF，该算法确保机器人保留在当地无碰撞的区域内，从而及时检测并避免了未知障碍物。我们进行了广泛的实验，将路径规划师与两个不同的安全关键控制器接口，其中我们的方法的表现优于安全性和效率方面的所有其他基准。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10930526</guid>
      <pubDate>Mon, 17 Mar 2025 13:19:41 GMT</pubDate>
    </item>
    <item>
      <title>一种新型的基于最终效应器的机器人康复平台的基于磁性的致动机制</title>
      <link>http://ieeexplore.ieee.org/document/10930540</link>
      <description><![CDATA[康复机器人技术继续面临重大挑战，尤其是在实现上肢运动训练的平稳，安全和直观的人类机器人相互作用方面。许多当前的系统取决于复杂的机械设计，直接的物理接触和多个传感器，这不仅提高了成本，还可以降低可访问性。此外，提供无缝的体重补偿和精确的运动跟踪仍然是一项高度复杂的工作。为了克服这些障碍，我们开发了一种新型的基于磁性的驱动机制，用于最终效果机器人康复。这种创新的方法可实现平滑，非接触力的传播，从而在上肢训练期间显着提高患者的安全性和舒适性。为了确保一致的性能，我们将扩展的Kalman滤波器（EKF）与控制器一起进行了实时位置跟踪，从而使系统可以保持高精度或即使在传感器故障或失败的情况下恢复。在与12名参与者的用户研究中，有75％的人对系统的平稳性高度评价，而66.7％的人赞扬其安全性和有效的体重补偿。 EKF证明了精确的跟踪性能，均方根误差（RMSE）值保持在可接受的限制（2 cm以下）之内。通过将磁性致动与先进的闭环控制算法相结合，该系统标志着上肢康复机器人技术领域的显着进步。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10930540</guid>
      <pubDate>Mon, 17 Mar 2025 13:19:41 GMT</pubDate>
    </item>
    <item>
      <title>立即将所有地方推动到任何地方：概率的预性推动</title>
      <link>http://ieeexplore.ieee.org/document/10930575</link>
      <description><![CDATA[我们解决了预先推动的问题，这是通过推动环境来操纵抓住物体的问题。我们的解决方案是一个有效的非线性轨迹优化问题，它是从精确的混合整数非线性轨迹优化公式中放松的。关键的见解是将外部推动器（环境）重铸为离散的概率分布，而不是二进制变量，并最大程度地减少分布的熵。概率重新制定允许同时使用所有推动器，但由于熵的最小化，概率质量浓缩到一个概率上。我们将方法与基于最新的采样基线进行比较，在预先推动任务上。结果表明，我们的方法发现轨迹的速度快8倍，成本比基线低20倍。最后，我们证明了一个模拟且真正的弗兰克熊猫机器人可以按照我们的方法提出的轨迹成功操纵不同的物体。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10930575</guid>
      <pubDate>Mon, 17 Mar 2025 13:19:41 GMT</pubDate>
    </item>
    <item>
      <title>立体声融合通过半全球匹配，与离散的差异匹配成本和半恢复</title>
      <link>http://ieeexplore.ieee.org/document/10930562</link>
      <description><![CDATA[我们提出了一种实时的，非学习的深度估计方法，该方法与立体摄像机输入融合了光检测和范围（LIDAR）数据。我们的方法包括三种关键技术：半全球匹配（SGM）立体声，具有离散的差异匹配成本（DDC），LIDAR差异的半敏化以及结合立体声图像和激光雷达数据的一致性检查。这些组件中的每一个都设计用于在GPU上并行化以实现实时性能。当在KITTI数据集上进行评估时，提出的方法达到了2.79％的错误率，表现优于先前最新的实时立体声融合方法，该方法的错误率为3.05％。此外，我们在各种情况下测试了所提出的方法，包括不同的LIDAR点密度，不同的天气状况和室内环境，以证明其高适应性。我们认为，我们方法的实时和非学习性质使其在机器人技术和自动化中的应用高度实用。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10930562</guid>
      <pubDate>Mon, 17 Mar 2025 13:19:41 GMT</pubDate>
    </item>
    <item>
      <title>自适应的自适应神经控制和适应性软爬行机器人的短期记忆</title>
      <link>http://ieeexplore.ieee.org/document/10925844</link>
      <description><![CDATA[柔软的爬行动物表现出由于形态计算（例如，柔性软体和各向异性皮肤）与神经计算（例如，具有可塑性和短期记忆（STM）神经控制）之间的协同作用而产生的有效和适应性行为。但是，将这些原则应用于软爬行机器人仍然具有挑战性。为了解决这个问题，我们的研究提出了一种自适应神经控制系统，该系统结合了在线学习和STM，以在软爬行机器人中产生适应性行为。该控制系统是在具有柔性软体，各向异性腹齿或皮肤的机器人中实现的，并具有体现的激光和Flex传感器。机器人展示了对各种扰动的多层次适应。扰动（例如粗糙的地形）可以通过被动（身体）的适应来管理牙齿的微观和人体的宏观变形。较大的扰动（包括被抬起或压制），通过狭窄的空间爬行以及遍历斜坡，通过主动（神经控制）适应来处理。机器人可以学习新的行为，例如在狭窄的空间中爬行，并存储感官信息，以保持稳健的行为，即使在暂时没有感觉反馈的情况下也是如此。此外，它可以通过感觉反馈预测，通过预测错误检测异常状态并适应其行为以解决这些错误来估计其状态。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10925844</guid>
      <pubDate>Fri, 14 Mar 2025 13:17:32 GMT</pubDate>
    </item>
    <item>
      <title>MAC-Planner：多机器人在线覆盖过程的新任务分配和路径计划框架</title>
      <link>http://ieeexplore.ieee.org/document/10924719</link>
      <description><![CDATA[本文提出了一个名为MAC-Planner的统一框架，该框架将多机器人任务分配与覆盖路径计划相结合，以更好地解决在线多机器人覆盖路径计划（MCPP）问题。通过根据系统的实时完成状态动态分配任务和计划覆盖路径，该计划者可以在其指定区域内有效地运行机器人。该框架不仅实现了出色的覆盖效率，而且还降低了机器人之间的冲突风险。我们提出了一种新颖的任务分配机制。这种机制通过构建目标覆盖地形的粗图，并利用$ k $  - 平均聚类以及成对优化方法来实现高效且公平的任务分配，将区域覆盖问题重新制定为点覆盖问题。我们还引入了有效的覆盖路径计划机制，以产生有效的覆盖路径并促进机器人合作。针对最新方法（SOTA）方法的广泛比较实验突出了Mac-Planner在降低冲突风险方面的显着覆盖效率和有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10924719</guid>
      <pubDate>Fri, 14 Mar 2025 13:17:32 GMT</pubDate>
    </item>
    <item>
      <title>唯一的方法是：主动膝盖外骨骼可在加权楼梯上升时减少股四头肌的肌肉努力</title>
      <link>http://ieeexplore.ieee.org/document/10925862</link>
      <description><![CDATA[消防员始终用齿轮的楼梯上升，其重量超过35公斤，这是他们最苛刻的活动。加权楼梯攀爬需要动态运动和大膝关节扭矩，这可能会在短期内引起疲惫，并长期过度使用伤害。主动的膝盖外骨骼可以通过在步态周期的关键阶段注入正能量，从而有可能减轻佩戴者的负担。在先前的研究中，类似的设备降低了各种运动活动的代谢成本。但是，在长时间加权楼梯期间，没有关于主动膝盖外骨骼对肌肉努力的影响的信息。在这里，我们表明我们的膝盖外骨骼在下肢上升时减少了下肢的净肌肉努力。在一项类似于美国消防员身体健身测试的任务中，八名参与者穿着9.1公斤的背心以不断的速度爬上楼梯三分钟。我们比较了下肢肌肉激活，以便在有或没有两个双侧磨损的犹他州膝盖外骨骼中执行任务。我们发现双边膝盖辅助降低了通过表面肌电图测量的平均峰值股四头肌激活32％，同时将股四头肌的总体肌肉活性降低了29％。这些结果表明，活跃的膝盖外骨骼可以降低加权时登上楼梯所需的整体肌肉努力。反过来，这可以通过保护消防员来扑灭大火和减少过度劳动伤害来帮助消防员。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10925862</guid>
      <pubDate>Fri, 14 Mar 2025 13:17:30 GMT</pubDate>
    </item>
    <item>
      <title>在复杂环境中具有全身安全的移动操纵器的局部反应性控制</title>
      <link>http://ieeexplore.ieee.org/document/10924710</link>
      <description><![CDATA[由于其高维状态空间和复杂的运动学，移动操纵器通常在导航狭窄，混乱的环境方面面临重大挑战。尽管反应性方法在动态设置中表现出色，但它们努力在整个状态空间中有效地纳入复杂的耦合约束。在这项工作中，我们提出了一个新型的局部反应控制器，该控制器将时间域的单步问题重新定义为空间域中多步优化问题，利用了串行运动链的传播。这种转换促进了定制的，脱钩的特定链接特定约束的制定，通过增强的Lagrangian差异动态编程（AL-DDP），可以有效地进一步解决。我们的方法自然会在向前传球中吸收空间运动学传播，并在向后通过时同时处理所有特定于链接的约束，从而提高了约束管理和计算效率。值得注意的是，在此框架中，我们使用带有提取的自由区域的准确几何模型为每个链接制定了碰撞避免限制，这可以在狭窄的，杂乱无章的空间中提高移动操纵器的可操作性。实验结果显示了安全，效率和任务完成率的显着提高。这些发现强调了所提出的方法的鲁棒性，尤其是在传统方法可能动摇的狭窄，混乱的环境中。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10924710</guid>
      <pubDate>Fri, 14 Mar 2025 13:17:30 GMT</pubDate>
    </item>
    </channel>
</rss>