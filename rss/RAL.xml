<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 机器人与自动化快报 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物目录提醒# 7083369</description>
    <lastBuildDate>Mon, 21 Oct 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>AIVIO：利用人工智能辅助视觉惯性里程计实现无人机闭环物体相关导航</title>
      <link>http://ieeexplore.ieee.org/document/10715655</link>
      <description><![CDATA[物体相关移动机器人导航对于各种任务（例如自主关键基础设施检查）至关重要，但需要能够从原始传感数据中提取有关感兴趣对象的语义信息。虽然基于深度学习 (DL) 的方法擅长从图像中推断语义对象信息，例如类别和相对 6$^{\circ }$ 自由度 (6-DoF) 姿势，但它们对计算要求很高，因此通常不适合有效载荷受限的移动机器人。在本信中，我们介绍了一种实时的无人机 (UAV) 系统，用于物体相关闭环导航，其最小传感器配置包括惯性测量单元 (IMU) 和 RGB 摄像头。利用基于 DL 的物体姿势估计器（仅对合成数据进行训练并针对配套板部署进行了优化），将物体相关姿势测量与 IMU 数据融合以执行物体相关定位。我们进行了多次真实世界实验，以验证我们的系统在电线杆检查这一具有挑战性的用例中的性能。补充视频中展示了闭环飞行的示例。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10715655</guid>
      <pubDate>Mon, 14 Oct 2024 13:16:52 GMT</pubDate>
    </item>
    <item>
      <title>用于结肠图重建的新型辅助成像设备</title>
      <link>http://ieeexplore.ieee.org/document/10715569</link>
      <description><![CDATA[结肠镜检查被公认为诊断和治疗结直肠癌的黄金标准，但它也存在一些局限性，可能会导致某些结肠区域被忽略。这可能会导致遗漏病变和间期癌症，从而导致治疗不完整。为了应对这一挑战，作者提出了一种新型结肠图重建辅助成像设备 (AID-CMR)，以帮助临床医生观察整个结肠粘膜并识别手术过程中可能遗漏的区域。该设备由一根远端装有成像模块的套管组成，该套管可围绕螺纹硅胶套移动。成像模块内装有可充气硅胶腔以扩张管腔、带 LED 的侧视微型全高清摄像头、磁性编码器和用于清洁摄像头的冲洗槽。在干预之前，该设备可以安装在标准结肠镜或其他系绳内窥镜上。在干预过程中，该设备可用于 (1) 重建器官的辅助地图、(2) 可视化完整解剖结构以及 (3) 提高疾病检测率。此外，这些地图可用于量化标准检查中遗漏的区域。本信介绍了一种概念验证设备，并讨论了在两种体外条件下进行的运动和重建测试。这些测试揭示了在运动、施加力和结肠地图重建方面的整体程序可行性，同时保留了息肉形态。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10715569</guid>
      <pubDate>Mon, 14 Oct 2024 13:16:52 GMT</pubDate>
    </item>
    <item>
      <title>KRRF：用于多目标运动规划的运动动力学快速探索随机森林算法</title>
      <link>http://ieeexplore.ieee.org/document/10714001</link>
      <description><![CDATA[运动动力学多目标运动规划问题就是在具有先验未知访问顺序的多个目标位置上找到一条轨迹。目标是在杂乱环境中，最小化具有运动动力学运动模型的机器人的轨迹规划成本。由于该问题结合了两个 NP 难题，即旅行商问题 (TSP) 和运动动力学运动规划问题，因此尚未得到有效解决。我们提出了一种称为运动动力学快速探索随机森林 (KRRF) 的新型近似方法，用于找到满足机器人运动约束的无碰撞多目标轨迹。KRRF 同时从所有目标向所有其他目标生长运动动力学树，同时使用其他树作为启发式方法来促进生长。一旦规划了目标到目标的轨迹，它们的成本就会用于解决 TSP 以找到目标序列。通过引导基于 RRT 的规划器沿着 TSP 序列中的目标到目标轨迹来规划满足运动动力学约束的最终多目标轨迹。与现有方法相比，KRRF 提供了更短的目标到目标轨迹和最终多目标轨迹，成本降低了 1.1-2 倍，同时在大多数测试案例中计算速度更快。该方法将作为开源库发布。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10714001</guid>
      <pubDate>Fri, 11 Oct 2024 13:17:34 GMT</pubDate>
    </item>
    <item>
      <title>通过多模态肌肉骨骼建模增强遮挡环境中的实时身体姿势估计</title>
      <link>http://ieeexplore.ieee.org/document/10714023</link>
      <description><![CDATA[近年来，人们对人机协作 (HRC) 的兴趣日益浓厚。开发有效的 HRC 工具的主要挑战之一是实时准确估计人体姿势，确保人身安全和高效协作。为了解决这个问题，我们提出了一种新颖的方法，即使在存在遮挡的情况下，也能实时准确、稳健地估计全身姿势。我们的系统结合了来自 RGB-D 相机和惯性测量单元的信息，利用它来通过多模态逆运动学优化来控制人体的肌肉骨骼模型。这种方法可确保提高跟踪运动的解剖真实感和准确性，同时允许灵活地适应各种传感器配置。考虑底层解剖结构也增强了在遮挡环境中估计身体姿势的能力。我们进行了几次 HRC 实验，其中操作员的视线受到各种类型的遮挡。结果表明，即使传感器数量有限且场景中存在遮挡，我们的方法也能显著提高姿势估计的准确性。我们的工作旨在促进需要精确理解人体运动的高级 HRC 应用。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10714023</guid>
      <pubDate>Fri, 11 Oct 2024 13:17:34 GMT</pubDate>
    </item>
    <item>
      <title>DexTouch：学习利用触觉灵活性寻找和操纵物体</title>
      <link>http://ieeexplore.ieee.org/document/10714461</link>
      <description><![CDATA[触觉是熟练执行各种任务的必备能力，它使机器人能够在不依赖视觉信息的情况下搜索和操纵物体。在本文中，我们介绍了一种多指机器人系统，该系统旨在使用触觉来操纵物体，而不依赖视觉。对于模拟日常生活的任务，机器人使用其触觉在黑暗中操纵随机放置的物体。这项研究的目的是让机器人在有先前信息的情况下，利用触觉来弥补因视觉缺失而造成的信息差距，从而实现无需视觉的操作。通过强化学习在模拟中训练策略，并将训练好的策略转移到现实环境中，我们证明了无需视觉输入的操作可以应用于无需视觉的机器人。此外，实验还展示了触觉在无需视觉执行的任务中的重要性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10714461</guid>
      <pubDate>Fri, 11 Oct 2024 13:17:34 GMT</pubDate>
    </item>
    <item>
      <title>从演示中学习运动原语的条件神经专家过程</title>
      <link>http://ieeexplore.ieee.org/document/10711283</link>
      <description><![CDATA[从演示中学习 (LfD) 是机器人技术中广泛使用的技能习得技术。然而，相同技能的演示可能会表现出显著的差异，或者学习系统可能会尝试同时获取相同技能的不同方法，这使得将这些动作编码为运动基元具有挑战性。为了应对这些挑战，我们提出了一个 LfD 框架，即条件神经专家过程 (CNEP)，该框架学习利用潜在空间内的固有信息将不同模式的演示分配给不同的专家网络，以将专家与编码表示相匹配。CNEP 不需要监督轨迹属于哪种模式。我们将 CNEP 的性能与广泛使用且功能强大的 LfD 方法（例如高斯混合模型、概率运动基元和稳定运动基元）进行了比较，并表明我们的方法在多模态轨迹数据集上优于这些基线。结果显示，运动基元的建模性能得到增强，从而可以合成更准确反映专家所展示轨迹的轨迹，尤其是当技能演示包括来自各种轨迹的交点时。我们在两个真实机器人任务（即避障任务和拾取和放置任务）上评估了 CNEP 模型，这两项任务要求机器人学习多模态运动轨迹并在给定目标环境条件下执行正确的基元。我们还表明，我们的系统能够通过在线调节机制即时适应环境变化。最后，我们认为，CNEP 通过自主查找离散行为基元并提供有关其专家选择决策的概率值，提供了更好的可解释性和可解释性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10711283</guid>
      <pubDate>Wed, 09 Oct 2024 13:18:28 GMT</pubDate>
    </item>
    <item>
      <title>字典标记 A*：带转弯半径约束的移动机器人最优路径和姿态规划</title>
      <link>http://ieeexplore.ieee.org/document/10711302</link>
      <description><![CDATA[在本文中，我们介绍了一种名为 Dictionary-Labeled A* (DL-A*) 的算法，该算法解决了具有转弯半径约束的移动机器人路径和姿势规划的关键问题。DL-A* 使用字典来存储和处理增强拓扑地图中的多元素信息。该算法将地图中的边缘分为前进和后退驾驶状态，并通过地图预处理构建符合路段约束的连续状态集。随后，采用 A* 算法找到一条到达终点的最佳路径，同时满足终点姿势约束，目标是最小化总行程成本。模拟结果表明，与其他流行算法相比，我们的算法能够调整机器人的前进和后退驾驶姿势以最小化总成本，并表现出卓越的搜索效率。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10711302</guid>
      <pubDate>Wed, 09 Oct 2024 13:18:28 GMT</pubDate>
    </item>
    <item>
      <title>用于视觉和语言导航的分层空间邻近推理</title>
      <link>http://ieeexplore.ieee.org/document/10710318</link>
      <description><![CDATA[大部分视觉语言导航 (VLN) 算法由于缺乏视觉常识和推理能力有限,容易做出不准确的决策。针对这一问题,我们提出了一种分层空间邻近推理 (HSPR) 方法。首先,我们引入场景理解辅助任务,帮助智能体构建分层空间邻近知识库。该任务利用全景图和物体特征识别节点类型,揭示节点间、物体间、节点与物体间的邻接关系。其次,我们提出一种基于分层空间邻近知识库的多步推理导航算法,不断规划可行路径,提升探索效率。第三,我们引入残差融合方法,提升导航决策准确率。最后,我们在 REVERIE、SOON、R2R、R4R 等公开数据集上进行实验,验证了我们的方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10710318</guid>
      <pubDate>Wed, 09 Oct 2024 13:18:26 GMT</pubDate>
    </item>
    <item>
      <title>CitDet：柑橘水果检测的基准数据集</title>
      <link>http://ieeexplore.ieee.org/document/10705083</link>
      <description><![CDATA[在本信中，我们提供了一个新的数据集，以推进最先进的柑橘类水果检测技术，并通过成像准确估算果园环境中受黄龙病 (HLB) 感染的树木的产量。尽管在解决水果检测问题方面取得了重大进展，但缺乏公开可用的数据集使得直接比较结果变得复杂。例如，柑橘检测长期以来一直是农业研究界关注的焦点，但缺乏相关工作，尤其是涉及受 HLB 影响的柑橘的公共数据集。为了解决这个问题，我们增强了最先进的物体检测方法，以用于典型的果园环境。具体来说，我们提供了位于已知受 HLB 影响严重的区域的柑橘树的高分辨率图像，以及柑橘类水果的高质量边界框注释。树上和地面上的果实都贴有标签，以便识别果实的位置，这有助于提高产量估计和通过果实掉落来衡量 HLB 影响的潜在程度。该数据集包含 579 张高分辨率图像中包含的 32,000 多个水果实例的边界框注释。总之，我们的贡献如下：(i) 我们引入了一个新数据集以及多种当代物体检测算法的基线性能基准，(ii) 我们展示了准确捕捉树上或地面上水果位置的能力，最后 (ii) 我们展示了我们的结果与产量估计的相关性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10705083</guid>
      <pubDate>Thu, 03 Oct 2024 13:16:52 GMT</pubDate>
    </item>
    </channel>
</rss>