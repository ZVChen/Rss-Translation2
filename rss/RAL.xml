<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 机器人与自动化快报 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物目录提醒# 7083369</description>
    <lastBuildDate>Mon, 30 Sep 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>针对退化场景使用基于块的梯度优化的点线 LIVO</title>
      <link>http://ieeexplore.ieee.org/document/10688407</link>
      <description><![CDATA[基于 3-D 光检测和测距 (LiDAR) 的同时定位和建图在无结构环境中往往会退化，导致定位精度和建图精度明显降低。本文提出了一种基于 FAST-LIVO 系统实现的点线 LiDAR-视觉惯性里程计 (PL-LIVO)，用于在 LiDAR 退化场景中实现稳健的定位。关键思想是将点和线集成到所提出的直接视觉里程计子系统 (PL-DVO) 中。通过最小化基于块的梯度残差进行状态优化，PL-DVO 提供了与 LiDAR 互补的额外约束。此外，提出了一种 LiDAR 地图辅助视觉特征深度提取 (LM-VDE) 方法，通过将视觉特征映射到 LiDAR 地图的 3-D 平面上来恢复视觉特征的 3-D 位置。该方法与单次扫描的密度无关，并且在各种 LiDAR 传感器上具有出色的泛化能力。在公共数据集和我们的数据集上进行的大量实验表明，PL-LIVO 可确保稳健的定位，并且在 LiDAR 退化场景中优于其他最先进的系统。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10688407</guid>
      <pubDate>Mon, 23 Sep 2024 13:17:08 GMT</pubDate>
    </item>
    <item>
      <title>SurgEM：基于视觉的手术环境建模框架，用于构建数字孪生以实现自主软组织操作</title>
      <link>http://ieeexplore.ieee.org/document/10685073</link>
      <description><![CDATA[机器人手术中的自主软组织操作仍然具有挑战性。对手术操作过程中的工具-组织相互作用进行建模、分析组织结构变形和监测生物力学状态可能有利于自主手术的发展；然而，目前研究不足。我们提出了一种基于视觉的手术环境建模框架，利用基于模型的姿势估计和基于场景流的网格优化，同时重建和跟踪钳子和组织。我们还提出了一种基于该框架的数字孪生，用于连续建模工具-组织相互作用并监测组织表面的变形和应变。进行了定量和定性的体外实验，从各个角度评估所提出的系统。结果表明，变形恢复精度为 $\bm {0.38\pm 0.30}$ 毫米，对遮挡具有鲁棒性；仪器姿势估计精度在旋转中为 $\bm {0.85\pm 0.57}$ 度，在平移中为 $\bm {2.09\pm 1.41}$ 毫米。在接触检测方面，可以正确建模组织和钳子之间的相对定位。该系统还正确地揭示了两种工具-组织相互作用（触诊和牵引）中应变分布的差异。利用所提出的系统，未来可以开发具有组织变形感知能力的手术机器人系统，以实现优化和自主手术。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10685073</guid>
      <pubDate>Fri, 20 Sep 2024 13:16:32 GMT</pubDate>
    </item>
    <item>
      <title>具有深度速度约束的稳健神经视觉惯性里程计</title>
      <link>http://ieeexplore.ieee.org/document/10685121</link>
      <description><![CDATA[视觉惯性里程计 (VIO) 是 GPS 受限环境中定位的常用解决方案。然而，由于视觉特征有限，当前 VIO 算法在视觉退化环境中的性能会下降。本文提出了一种具有学习速度约束的稳健 VIO 算法。具体而言，采用增强了注意机制的编码器-解码器神经网络基于 IMU 测量来估计瞬时速度及其不确定性。然后，学习到的速度作为伪测量，并在标准优化框架内与惯性和视觉测量融合，以获得准确而稳健的定位结果。这项工作的关键思想是，从惯性测量中学习到的速度约束可以有效地防止 VIO 在视觉退化环境中发散，而无需引入任何新的传感器，并且与以前基于位移矢量的神经 VIO 算法相比，可以更好地模拟运动的短期特征。在公共数据集上的实验表明，所提出的 VIO 算法在低能见度条件下运行稳健，并且与其他最先进的算法相比获得了更高的定位精度。我们将分享代码和模型。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10685121</guid>
      <pubDate>Fri, 20 Sep 2024 13:16:32 GMT</pubDate>
    </item>
    <item>
      <title>非结构化数据下基于基本技能先验的语言条件模仿学习</title>
      <link>http://ieeexplore.ieee.org/document/10685120</link>
      <description><![CDATA[人们对语言调节机器人操作的兴趣日益浓厚，旨在开发能够理解和执行复杂任务的机器人，目标是使机器人能够解释语言命令并相应地操纵物体。虽然语言调节方法在熟悉环境中表现出令人印象深刻的解决任务的能力，但它们在适应不熟悉的环境设置时会遇到限制。在这封信中，我们提出了一种通用的语言调节方法，该方法结合了非结构化数据下的基本技能先验和模仿学习，以增强算法在适应不熟悉环境方面的泛化能力。我们使用零样本设置评估了我们模型在模拟和现实环境中的性能。平均完成任务长度（表示代理可以连续完成的平均任务数）与基线方法 HULC 相比提高了 2.5 倍以上。在现实环境中对我们的策略进行零样本评估方面，我们设置了十个任务，与目前最先进的方法相比，我们的方法平均提高了 30%，在模拟环境和现实世界中都表现出很高的泛化能力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10685120</guid>
      <pubDate>Fri, 20 Sep 2024 13:16:32 GMT</pubDate>
    </item>
    <item>
      <title>非线性系统的在线时间知情动态运动规划</title>
      <link>http://ieeexplore.ieee.org/document/10682797</link>
      <description><![CDATA[基于采样的运动动力学运动规划器 (SKMP) 在为差分约束下的高维系统寻找无碰撞轨迹方面非常有效。时间知情集 (TIS) 可以提供启发式搜索域以加速它们收敛到时间最优解。然而，现有的 TIS 近似方法受到维数灾难、计算负担和系统适用范围有限的困扰，例如线性和多项式非线性系统。为了克服这些问题，我们提出了一种利用深度学习技术、库普曼算子理论和随机集理论的方法。具体来说，我们提出了一种带控制 U 模型的深度可逆库普曼算子 DIKU，通过使用可逆神经网络修改辅助网络来预测长范围内的正向和反向状态。开发了一种针对 DIKU 双向传播方法的对抗性采样 ASKU，该方法执行可达性分析，以在线近似非线性控制系统的 TIS。此外，我们设计了一种在线时间知情 SKMP，使用直接采样技术在 TIS 中抽取均匀随机样本。模拟实验结果表明，我们的方法优于其他现有方法，可以近乎实时地近似 TIS，并在几个时间最优的运动动力学运动规划问题中实现卓越的规划性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10682797</guid>
      <pubDate>Wed, 18 Sep 2024 13:21:30 GMT</pubDate>
    </item>
    <item>
      <title>使用分而治之的方法确保在固定相机增益下被动标记的高可见性</title>
      <link>http://ieeexplore.ieee.org/document/10684129</link>
      <description><![CDATA[这封信提出了一种新颖的解决方案，用于确定运动捕捉系统中相机的曝光和阈值，而无需与用户进行过多交互。该解决方案基于分而治之的方法，可确保快速有效地搜索值。结果表明，没有专业知识的用户也可以显著提高运动捕捉系统的跟踪能力，尤其是对于较小的被动标记。测试证明，对于直径为 7.9 毫米的球形标记，可以根据使用所提方法确定的设置确保全时跟踪能力，而使用默认设置则很难实现。此外，可以提高相机的利用率，这将对整体跟踪质量产生积极影响。这使得使用更小、更轻的标记成为可能，这对于有效载荷能力仅为几克的小型飞行装置来说是理想的。主要测试是在配备 12 个 OptiTrack Prime$^{\mathrm{x}}$ 13W 相机的实验室中进行的。使用了专用的编程接口（Motive API 和 Camera SDK）。验证测试包括一个附有四个标记的 DJI Tello EDU 单元。除了分析和考虑之外，该文档还包含伪代码，这些伪代码清楚地解释了算法背后的想法，并允许轻松实施解决方案。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10684129</guid>
      <pubDate>Wed, 18 Sep 2024 13:21:30 GMT</pubDate>
    </item>
    <item>
      <title>用于下消化道干预的带力度估计功能的混合操作器</title>
      <link>http://ieeexplore.ieee.org/document/10683884</link>
      <description><![CDATA[本信介绍了一种新型混合操纵器，由两个气动软段和一个肌腱驱动的连续段串联而成。软段增强了肌腱驱动操纵器的移动性，实现了三角测量等功能，同时保持了较低的工具刚度，使其适用于下消化道腔内手术。该设计的一个关键优势是实现了基于模型的控制器和基于观察器的接触力估计方法，该方法根据软段的配置和驱动来估计外力。通过实验将该方法与肌腱张力传感方法（称为内在力传感）进行了比较。实验包括典型的提升和推动任务，以及对离体猪肠组织的真实操作。结果证明了所提出的方法在外科应用中的可行性及其优于内在力传感的优势，在所有任务中实现了标准化 RMSE 平均降低 15.8%。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10683884</guid>
      <pubDate>Wed, 18 Sep 2024 13:21:29 GMT</pubDate>
    </item>
    <item>
      <title>针对性投掷的末端执行器的识别与基于学习的控制</title>
      <link>http://ieeexplore.ieee.org/document/10681644</link>
      <description><![CDATA[除了拾取和放置物体外，无人机和移动机械手还能投掷物体，在工业自动化、仓库环境、搜救行动和体育训练中非常有用。然而，主要的末端执行器主要满足抓取功能，而忽略了投掷方面。目前，投掷是通过快速的全臂运动实现的（Zeng 等人，2020 年），这种方法引发了人们对安全和能源效率的担忧。此外，由于模型参数的不确定性和未建模的动力学，有针对性的投掷带来了一些挑战。这封信介绍了一种新的末端执行器机制，它可以使用储存的弹性能量来抓取然后放置或投掷物体。这种储存能量的瞬间释放会推动被抓取的物体进行抛射运动，从而有助于将其放置在所需的目标位置，该位置可能超出机器人手臂可到达的工作空间。我们描述了末端执行器的机械设计、其仿真模型、用于拟合模型参数的系统识别方法以及数据驱动的残差学习框架。残差模型可预测由模型不确定性引起的控制输入残差，从而提高定向投掷的准确性，即使面对看不见的物体也是如此。使用安装在机械臂上的末端执行器进行的实验表明，我们的末端执行器机制和相关算法对于定向投掷非常有效。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10681644</guid>
      <pubDate>Tue, 17 Sep 2024 13:17:40 GMT</pubDate>
    </item>
    <item>
      <title>基于稀疏八叉树的 CNN 概率占用预测应用于下一个最佳视图规划</title>
      <link>http://ieeexplore.ieee.org/document/10679903</link>
      <description><![CDATA[本研究提出了 OcLe-CNN，一种基于稀疏八叉树的卷积神经网络 (CNN)，用于 3D 占用预测。占用预测涉及推断未观察空间的占用概率。OcLe-CNN 处理类似八叉树的数据结构，从而减少内存使用量，因为资源普遍分配在环境中细节最丰富的区域。此外，还引入了一种新颖的损失函数，与最先进的结构和任务损失相比，八叉树更小。所提出的 CNN 与概率机器人下一个最佳视图 (NBV) 规划器集成，其中类似八叉树的数据结构加快了光线投射阶段。集成导致总计算时间更短。该方法适用于四叉树和八叉树，并在 2D 和 3D 数据集以及真实的机器人操纵器设置上进行了验证。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10679903</guid>
      <pubDate>Fri, 13 Sep 2024 13:16:34 GMT</pubDate>
    </item>
    <item>
      <title>动作语境化：使用大型语言模型进行自适应任务规划和动作调整</title>
      <link>http://ieeexplore.ieee.org/document/10679904</link>
      <description><![CDATA[大型语言模型 (LLM) 利用广泛的人类知识，为机器人任务规划提供了一个有希望的前沿。然而，目前的文献往往忽视了机器人适应性和纠错的关键方面。这项工作旨在通过使机器人能够修改其动作并根据上下文选择最合适的任务计划来克服这一限制。我们引入了一个新颖的框架来实现动作情境化，旨在根据特定任务的上下文定制机器人动作，从而通过应用 LLM 得出的上下文洞察来增强适应性。我们的框架集成了评估机器人每个动作性能的运动指标，以解决规划中的冗余问题。此外，它支持机器人和 LLM 之间的在线反馈，从而可以立即修改任务计划并纠正错误。通过广泛的实验验证，总体成功率已达到 81.25%。最后，当与基于动态系统 (DS) 的机器人控制器集成时，机械臂系统展示了其在自主执行 LLM 生成的连续桌面清理任务运动计划、无需人工干预即可纠正错误以及展示对外部干扰的鲁棒性方面的熟练程度。我们的框架还具有与模块化控制方法集成的潜力，从而显著增强了机器人在现实世界中执行连续任务的适应性和自主性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10679904</guid>
      <pubDate>Fri, 13 Sep 2024 13:16:34 GMT</pubDate>
    </item>
    <item>
      <title>通信受限的未知环境下多机器人会合</title>
      <link>http://ieeexplore.ieee.org/document/10679913</link>
      <description><![CDATA[会合旨在将所有机器人聚集在特定位置，这是多机器人系统的重要协作行为。然而，在未知环境中，实现会合具有挑战性。以前的研究主要集中在不允许通信的特殊场景中，每个机器人执行随机搜索策略，这非常耗时，尤其是在大规模环境中。在本文中，我们专注于在可以通信的未知环境中的会合。我们将此任务分为两个步骤：基于会合的环境探索和相对姿势 (RP) 估计以及会合点选择。提出了一种称为分区和不完全会合探索 (PIER) 的新策略来有效地探索未知环境，其中构建轻量级拓扑地图并在机器人之间共享以进行 RP 估计，并且通信很少。然后，提出了一种基于合并拓扑图的会合点选择算法，以实现多机器人系统的高效会合。在模拟和真实世界实验中验证了所提出方法的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10679913</guid>
      <pubDate>Fri, 13 Sep 2024 13:16:34 GMT</pubDate>
    </item>
    <item>
      <title>MGS-SLAM：具有深度平滑正则化的单目稀疏跟踪和高斯映射</title>
      <link>http://ieeexplore.ieee.org/document/10679906</link>
      <description><![CDATA[本信介绍了一种基于高斯分层的密集视觉同步定位与地图构建 (VSLAM) 的新框架。最近，基于高斯分层的 SLAM 已显示出良好的效果。然而，在单目场景中，重建的高斯地图缺乏几何精度，并且表现出较弱的跟踪能力。为了解决这些限制，我们首次联合优化了稀疏视觉里程计跟踪和 3D 高斯分层场景表示。我们使用快速多视图立体 (MVS) 网络对高斯地图进行几何监督，在视觉里程计关键帧窗口上获得深度图。此外，我们提出了深度平滑损失和稀疏-密集调整环 (SDAR)，以减少估计深度图的负面影响并保持视觉里程计和高斯地图之间的尺度一致性。我们已经在各种合成和真实世界数据集上评估了我们的系统。我们的姿势估计的准确性超越了现有方法并达到了最先进的水平。此外，它在新颖的视图合成和几何重建保真度方面优于以前的单目方法。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10679906</guid>
      <pubDate>Fri, 13 Sep 2024 13:16:34 GMT</pubDate>
    </item>
    <item>
      <title>PAIR360：高分辨率 360$^{\circ }$ 全景图像与 LiDAR 扫描的配对数据集</title>
      <link>http://ieeexplore.ieee.org/document/10679919</link>
      <description><![CDATA[360$^{\circ }$ 相机是一种紧凑型全向感知系统，用于捕捉具有与 LiDAR 相同视野的全景图像。这提高了它在自动驾驶和机器人技术中的多功能性。然而，大多数现有的 360$^{\circ }$ 全景图像数据集主要关注室内或虚拟环境，或者仅提供低分辨率的室外图像和 LiDAR 配置。在这封信中，我们介绍了 PAIR360，这是一个多模态数据集，包含高分辨率 360$^{\circ }$ 相机图像和 3D LiDAR 扫描，旨在促进计算机视觉研究。为此，我们在庆熙大学全球校区收集了一个综合数据集，在晴天、多云和日出等不同大气条件下从 7 个不同区域捕捉了 52 个序列。该数据集具有 8K 分辨率全景图像、六个鱼眼图像、点云、GPS 和 IMU 数据，所有这些都使用 LiDAR 时间戳同步并跨视觉传感器进行校准。我们还提供额外的数据，例如深度图、分割和 3D 地图，以证明我们的数据集的可行性及其在各种计算机视觉任务中的应用。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10679919</guid>
      <pubDate>Fri, 13 Sep 2024 13:16:34 GMT</pubDate>
    </item>
    <item>
      <title>AmodalSynthDrive：用于自动驾驶的合成非模态感知数据集</title>
      <link>http://ieeexplore.ieee.org/document/10679899</link>
      <description><![CDATA[与人类不同，即使物体被部分遮挡，人类也能毫不费力地估计出整个物体，而现代计算机视觉算法在这方面仍然极具挑战性。由于缺乏合适的数据集，将这种非模态感知用于自动驾驶在很大程度上仍未得到利用。这些数据集的管理主要受到高昂的注释成本和减轻注释者在准确标记遮挡区域方面的主观性所阻碍。为了解决这些限制，我们推出了 AmodalSynthDrive，这是一个合成的多任务多模态非模态感知数据集。该数据集为 150 个驾驶序列提供了多视角摄像头图像、3D 边界框、激光雷达数据和里程表，并在不同的交通、天气和光照条件下提供了超过 100 万个物体注释。AmodalSynthDrive 支持多种非模态场景理解任务，包括引入的非模态深度估计，以增强空间理解。我们评估了每个任务的几个基线以说明挑战并设置了公共基准服务器。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10679899</guid>
      <pubDate>Fri, 13 Sep 2024 13:16:34 GMT</pubDate>
    </item>
    <item>
      <title>HGS-Mapping：在城市场景中使用混合高斯表示进行在线密集制图</title>
      <link>http://ieeexplore.ieee.org/document/10679910</link>
      <description><![CDATA[城市场景的在线密集制图是场景理解和自动驾驶汽车导航的基础基石。密集制图方法的最新进展主要基于 NeRF，但其渲染速度太慢，无法满足在线要求。3D 高斯分层 (3DGS) 的渲染速度比 NeRF 快数百倍，在在线密集制图方面具有更大的潜力。然而，将 3DGS 集成到街景密集制图框架中仍然面临两个挑战，包括由于缺乏 LiDAR 覆盖范围以外的几何信息而导致的不完整重建以及在大型城市场景中进行重建的大量计算。为此，我们提出了 HGS-Mapping，这是一种无界大规模场景中的在线密集制图框架。为了实现完整的构建，我们的框架引入了混合高斯表示，它使用具有不同属性的高斯对整个场景的不同部分进行建模。此外，我们采用混合高斯初始化机制和自适应更新方法来实现高保真和快速重建。据我们所知，我们是第一个将高斯表示集成到城市场景的在线密集制图中的人。我们的方法仅采用 66% 的高斯数量就实现了 SOTA 重建精度，从而使重建速度提高了 20%。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10679910</guid>
      <pubDate>Fri, 13 Sep 2024 13:16:33 GMT</pubDate>
    </item>
    </channel>
</rss>