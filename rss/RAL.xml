<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 机器人与自动化快报 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物 TOC 警报# 7083369</description>
    <lastBuildDate>Thu, 14 Mar 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>基于欧拉带理论的藤状动力软夹具</title>
      <link>http://ieeexplore.ieee.org/document/10433741</link>
      <description><![CDATA[软机器人在难以预测外部环境且需要操纵不规则形状重物的灾难现场具有使用潜力。然而，现有的软机器人负载能力较低。因此，我们提出了一种类似藤蔓的动力软抓手，通过包裹物体来抓取物体，并制作了一个原型。该夹具基于欧拉皮带理论，负载能力随着包角的增加而增加，并通过负载能力测量得到证明。抓取实验表明，抓手可以抓取各种形状的物体。该夹具利用恒力弹簧施加的恢复力缠绕物体。因此，抓手无法举起在举升过程中容易旋转的重物。然而，已证实具有相反螺旋方向的双夹具可以抓取此类物体。还证实双夹具可以抓取重量为1660 N的物体，尽管其两个恒力弹簧具有43 N的小负载。这表明抓取负载力超过了弹簧卷绕力产生的力。最后，将夹具安装到建筑机械机器人上，并进行了取放演示。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10433741</guid>
      <pubDate>Tue, 13 Feb 2024 13:20:17 GMT</pubDate>
    </item>
    <item>
      <title>CLIPPER：无需初始猜测即可实现强大的数据关联</title>
      <link>http://ieeexplore.ieee.org/document/10432947</link>
      <description><![CDATA[识别噪声数据中的对应关系是估计过程中至关重要的一步。当信息丰富的初始估计猜测可用时，数据关联挑战就不那么尖锐了；然而，在大多数情况下很少存在高质量的初始猜测。我们探索数据关联的图论公式，它不需要初始估计猜测。现有的图论方法对未加权图进行优化，丢弃加权边中编码的重要一致性信息，并经常尝试准确解决 NP 难题。相反，我们提出了一个新的优化问题，充分利用加权图并寻找最密集的边缘加权团。我们对此问题引入了两种松弛：一种是凸半定松弛，我们发现它在经验上是严格的；另一种是称为 CLIPPER 的快速一阶算法，它经常在几毫秒内达到接近最优的解决方案。当评估点云配准问题时，我们的算法在至少 95% 的异常值下仍然保持鲁棒性，而现有算法在 80% 的异常值下开始崩溃。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10432947</guid>
      <pubDate>Mon, 12 Feb 2024 13:25:50 GMT</pubDate>
    </item>
    <item>
      <title>使用多波束成像声纳的自主水下航行器对移动物体进行 3D 检测和跟踪：实现海洋生物的连续观测</title>
      <link>http://ieeexplore.ieee.org/document/10430210</link>
      <description><![CDATA[生物记录一直是研究水生生物生态和行为的普遍方法。但其存在操作不便、对生物体造成应激等问题。最近，使用自主水下航行器（AUV）进行远程跟踪的研究越来越受到关注，特别是那些配备受水下光和浑浊度影响较小的多波束成像声纳（MBS）的水下航行器。然而，由于MBS固有的局限性，现有的研究主要集中在二维检测和跟踪上。在这封信中，我们提出了一种利用 AUV 上 MBS 的倾斜控制来 3D 检测和跟踪海洋生物调查移动目标的新方法。 YOLOv3 用于识别声纳图像中目标的位置。粒子滤波算法的结合提高了位置估计精度，并且还能够估计目标的状态、速度和方向。基于估计状态引入3D跟踪方法。该方法通过悬停型AUV和真人大小的海龟复制品的水箱实验得到验证，成功实现了水平和垂直运动目标的3D跟踪。该方法证明了位置估计的 RMSE 为 0.23 m，速度和方向的误差分别为 0.022 m/s 和 16.59 度。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10430210</guid>
      <pubDate>Fri, 09 Feb 2024 13:16:53 GMT</pubDate>
    </item>
    <item>
      <title>杂乱场景中的可抓取性物体姿态估计</title>
      <link>http://ieeexplore.ieee.org/document/10430220</link>
      <description><![CDATA[物体识别和姿态估计是自主机器人操纵系统的关键组成部分，在使机器人与环境有效交互方面发挥着至关重要的作用。在实际执行过程中，机器人必须识别当前场景中的物体，估计其位姿，然后从预定义的抓取配置中选择可行的抓取姿势。虽然大多数现有方法主要关注姿态估计，但它们经常忽略可抓握性和可达性方面。这种疏忽可能会导致执行过程中效率低下和失败。在这项研究中，我们引入了一种创新的可抓取性感知的物体姿态估计框架。我们提出的方法不仅可以估计集群场景中多个对象的姿态，还可以识别可抓取的区域。这使得系统能够将其精力集中在适合抓取的物体的特定点或区域上。它利用深度和彩色图像来提取几何和外观特征。为了有效地结合这些不同的特征，我们开发了自适应融合模块。此外，通过可抓取性感知特征增强模块进一步增强了融合特征。我们方法的关键创新在于提高用于物体姿态估计的特征的可辨别性和鲁棒性。与几种基线方法相比，我们在公共数据集上取得了最先进的结果。在配备英特尔实感摄像头和两指夹具的 Franka Emika 机器人手臂上进行的真实机器人实验中，我们始终取得很高的成功率，即使在杂乱的场景中也是如此。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10430220</guid>
      <pubDate>Fri, 09 Feb 2024 13:16:53 GMT</pubDate>
    </item>
    <item>
      <title>通过多个 IMU 进行稳健形状估计的肌腱驱动连续体机械臂</title>
      <link>http://ieeexplore.ieee.org/document/10427985</link>
      <description><![CDATA[在这封信中，开发和制造了一种具有三个独立连续体部分的腱驱动连续体机器人操纵器。主要贡献是，我们在 PCC（分段常曲率）假设下，提出了一种基于多 IMU 融合的稳健且准确的形状估计方法。为了直观地呈现机器人的配置空间，我们开发了一个可视化环境来展示实时连续体形状。为了使用估计方法验证所提出的系统，我们评估了弯曲范围、尖端速度、有效工作空间和耐用性等基本属性。此外，我们还进行了形状变形、动态跟踪、抗扰动等运动实验。结果表明，我们提出的估计方法经评估可在连续 3D 运动期间实现尖端运动小于 20 mm RMSE。同时，我们将所提出的系统与以前的连续机器人系统的机构特性进行了比较。我们提出的机器人系统具有更紧凑和高效的结构。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10427985</guid>
      <pubDate>Thu, 08 Feb 2024 13:19:34 GMT</pubDate>
    </item>
    <item>
      <title>离线强化学习中分布外泛化的扩散策略</title>
      <link>http://ieeexplore.ieee.org/document/10423845</link>
      <description><![CDATA[离线强化学习（RL）方法利用以前的经验来学习比用于数据收集的行为策略更好的策略。然而，由于培训期间缺乏在线互动，他们在处理分配转移方面面临挑战。为此，我们提出了一种名为扩散策略状态重建（SRDP）的新方法，该方法将状态重建特征学习融入到最近一类扩散策略中，以解决分布外（OOD）泛化问题。我们的方法促进了可泛化状态表示的学习，以减轻 OOD 状态引起的分布偏移。为了说明 SRDP 的 OOD 泛化和更快的收敛性，我们设计了一种新颖的 2D 多模态上下文 Bandit 环境，并在 6 自由度现实世界 UR10 机器人以及仿真中实现它，并将其性能与现有算法进行比较。特别是，我们展示了通过消融研究提出的状态重建的重要性。此外，我们还评估了模型在标准连续控制基准 (D4RL) 上的性能，即 8-DoF 蚂蚁的导航和半猎豹、hopper 和 walker2d 的向前运动，取得了最先进的结果。最后，我们证明了我们的方法可以在稀疏连续控制导航任务上比竞争基线实现 167% 的改进，其中状态空间的各个区域从离线 RL 数据集中删除，包括封装目标的区域。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10423845</guid>
      <pubDate>Wed, 07 Feb 2024 13:17:28 GMT</pubDate>
    </item>
    <item>
      <title>用于太空探索的可变形纳米漫游车</title>
      <link>http://ieeexplore.ieee.org/document/10423867</link>
      <description><![CDATA[这封信介绍了一种新颖的纳米漫游车，旨在改变其形状，以便在月球表面高效移动。该流动站类似于一个紧凑的球，直径约为 80 毫米，质量约为 250 克。其转换机制可在行星运输过程中实现紧凑性，并通过使用可伸缩轮、尾部稳定器和摄像头来增强移动性。为了有效地穿越松软地形，流动站采用偏心轮机构，提供两种基于轮同步的不同运动模式。该机构可在平面上提供 20 mm/s 或更高的运动速度。此外，它还具有机载图像处理功能，可检测多层绝缘（MLI）薄膜屏蔽的航天器，从而促进自主控制和选择性图像传输。该漫游车已安装在月球着陆器上，用于实际的太空任务。这封信介绍了这款可变形漫游车的设计细节以及模拟月球条件的现场测试结果。这些测试证实了所提出的运动机制和机载图像处理的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10423867</guid>
      <pubDate>Wed, 07 Feb 2024 13:17:28 GMT</pubDate>
    </item>
    <item>
      <title>RESPRECT：通过残差强化学习加速多指抓取</title>
      <link>http://ieeexplore.ieee.org/document/10423830</link>
      <description><![CDATA[深度强化学习（DRL）已被证明在使用机器人抓手学习控制策略方面是有效的，但由于问题的高维性，对于解决灵巧的手抓取问题（尤其是在真实的机器人平台上）的实用性要差得多。在这封信中，我们重点关注 iCub 人形机器人拟人手的多指抓取任务。我们提出了RESidual Learning with PREtrained CriTics (RESPRECT)方法，该方法从在大量对象上预训练的策略开始，可以学习残差策略以一小部分的速度掌握新对象（$\sim 5 \times$） ）从头开始训练策略所需的时间步长，无需任何任务演示。据我们所知，这是第一个残差强化学习 (RRL) 方法，该方法在使用 DRL 预训练的另一个策略之上学习残差策略。我们在残差学习期间利用预训练策略的一些组成部分，进一步加快训练速度。我们在 iCub 模拟环境中对结果进行了基准测试，结果表明 RESPRECT 可以有效地用于学习真实 iCub 机器人上的多指抓取策略。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10423830</guid>
      <pubDate>Wed, 07 Feb 2024 13:17:27 GMT</pubDate>
    </item>
    <item>
      <title>运动学信息神经网络：增强软机器人模型识别的泛化性能</title>
      <link>http://ieeexplore.ieee.org/document/10423093</link>
      <description><![CDATA[结合刚性和软体机器人（例如，连接到刚性手臂的软手指）的混合系统确保与人类的安全和灵巧的交互。然而，对涉及软机器人和刚性机器人的复杂运动进行建模提出了挑战。此外，由于重复和极端驱动造成损坏的风险，获取软机器人的大型数据集很困难，这阻碍了数据驱动方法的利用。在这项研究中，我们提出了一种运动学信息神经网络（KINN），它将刚体运动学作为归纳偏差，以提高样本效率并为混合系统提供整体控制。使用气动和腱驱动软机器人在模拟和现实环境中对所提出方法的模型识别性能进行了广泛评估。评估结果表明，在现实世界的腱驱动软机器人的外推任务中，采用运动学先验可以使 L1 范数中测得的位置误差降低 80.84%。我们还通过打开瓶子和画字母来演示用柔软的手指对刚性手臂的灵巧和整体控制。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10423093</guid>
      <pubDate>Tue, 06 Feb 2024 13:19:50 GMT</pubDate>
    </item>
    <item>
      <title>FGDSNet：用于人机交互的轻量级手势识别网络</title>
      <link>http://ieeexplore.ieee.org/document/10420430</link>
      <description><![CDATA[基于计算机视觉的手势识别方法在机器人视觉手势交互中发挥着重要作用。现有的手势分割和识别方法由于特征表示和融合不足而导致精度低，无法满足实际应用的要求。为了解决这些问题，提出了一种轻量级两级端到端手势识别网络，称为融合门双级网络（FGDSNet）。该网络在分段阶段采用双分支网络结构。现有的双分支网络模型往往直接融合细节特征和语义特征，导致详细信息被模糊的语义信息掩盖。此外，在网络推理过程中，不同级别的特征图存在冗余问题。因此，我们在局部细节分支和上下文语义分支之间嵌入了余弦相似度-KL散度注意力模块（CoSKLAM）和门过滤模块（GFM）。这两个模块的作用是便于特征提取过程中局部特征和全局特征的融合，过滤掉冗余信息。最后，分割结果和原始手势图像作为识别网络的输入来预测手势类别。相关实验表明，所提出的网络在手势分割和手势识别方面都表现良好，同时还具有实时推理速度和较小的参数大小。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10420430</guid>
      <pubDate>Mon, 05 Feb 2024 13:16:59 GMT</pubDate>
    </item>
    <item>
      <title>用于高延迟遥控操作的模型增强能量流参考</title>
      <link>http://ieeexplore.ieee.org/document/10419892</link>
      <description><![CDATA[随着机器人操纵系统的灵活性和鲁棒性不断提高，其应用领域不断扩大。由于自主代理的能力仍然有限，并且需要在出现故障时提供后备解决方案，因此远程操作仍然是远程系统或人类无法到达的地区的系统的基本功能。最近，开发了一种新的控制方法（TDPA-HD），用于极端延迟的远程操作，这确保了安全交互，但导致机器人在其环境中保守且较晚的施力。在这项工作中，我们将 TDPA-HD 与模型增强方法相结合，以克服这一限制并加速力的应用，而不牺牲远程机器人交互的安全性。为此，我们利用远程环境的本地虚拟模型，该模型是预先已知的或在运行时感知和创建的。考虑到操作员与该本地模型的触觉交互的能量行为作为远程交互的参考，与纯 TDPA-HD 相比，机器人可以更早地施加交互力。同时，确保在与远程环境中的未建模对象发生意外接触时的安全交互。该方法在 6-DoF 中引入，并在刚性和弹性环境中的 3-DoF 实验中得到验证，涉及复杂的交互任务，往返延迟高达 1.6 s。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10419892</guid>
      <pubDate>Mon, 05 Feb 2024 13:16:59 GMT</pubDate>
    </item>
    <item>
      <title>使用定制音圈驱动的腕戴式触觉的手部优势和一致性</title>
      <link>http://ieeexplore.ieee.org/document/10417076</link>
      <description><![CDATA[在虚拟交互过程中，在远程位置（如手腕）而不是指尖呈现触觉反馈，可以将用户的双手从机械设备中解放出来。这允许真实的交互，同时仍然提供有关虚拟对象的机械属性的信息。在这封信中，我们研究了使用惯用手或非惯用手进行虚拟交互的影响，以及主动手和接收触觉反馈的手腕之间的最佳映射，这可以通过基于用户实验来定义为手腕一致性。刚度判别任务。为了提供力反馈，我们推出了 CoWrHap——一种带有定制音圈驱动的新型腕戴式触觉设备。我们的结果表明，参与者（i）使用非全等映射更好地执行任务，但使用全等映射报告了更好的体验，（ii）在手部优势方面没有统计差异，但具有更好的用户体验（享受、愉悦等）。 ）使用他们的优势手。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10417076</guid>
      <pubDate>Wed, 31 Jan 2024 13:28:37 GMT</pubDate>
    </item>
    <item>
      <title>立方体可逆机器人CuRobot的设计与轨迹跟踪控制</title>
      <link>http://ieeexplore.ieee.org/document/10415501</link>
      <description><![CDATA[在现场环境中，许多机器人需要人工干预才能在人员更替后恢复功能，从而导致运营效率下降。这项研究提出了一种创新的设计解决方案，用于可逆全向移动机器人，称为CuRobot，具有立方体结构，因此即使在翻转的情况下也能实现不间断的全向运动。立方体顶点处的八个锥形轮的结合确保了无论立方体的哪个面接触地面，都能实现一致的全向运动。此外，还为 CuRobot 制定了运动学模型，同时开发了利用模型预测控制的轨迹跟踪控制器。通过仿真实验，检验轨迹跟踪精度与机器人运动方向之间的相关性。此外，该机器人在全向移动和翻转后持续运动方面的熟练程度通过模拟和原型实验得到了证实。这种设计减少了与人工干预相关的低效率，从而提高了机器人在现场环境中的操作稳健性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10415501</guid>
      <pubDate>Mon, 29 Jan 2024 13:17:33 GMT</pubDate>
    </item>
    <item>
      <title>基于视觉几何的PnP问题高效解决</title>
      <link>http://ieeexplore.ieee.org/document/10319768</link>
      <description><![CDATA[透视 n 点 (PnP) 问题旨在根据已知的 3D 地图点及其投影来估计姿态。高效 PnP (EPnP) 是经典 PnP 求解器之一，用控制点表示相机位姿，利用最小二乘 (LS) 公式更容易估计。然而，大多数基于 EPnP 的方法执行的几何细化过程与 LS 公​​式的解决方案是分开的，这在最小化损失函数和保留控制点的基本几何属性之间造成了平衡。为了解决这个问题，我们提出了一种新方法，将几何约束集成到控制点公式中，并将 LS 重新公式化为二次约束二次规划 (QCQP)。我们针对约束 EPnP 问题推出了一种创新的解析解（称为 ACEPnP），该解比通常应用的数值方法更快。 ACEPnP 中设计了一种不确定性感知最小二乘配准程序，用于根据控制点计算相机位姿。我们的方法是即插即用的，可以嵌入到 EPnP 的各种变体中。合成数据和真实数据的实验表明，我们的方法优于其他最先进的方法。与最好的 PnP 求解器 EPnPU* 相比，我们的方法将旋转误差减少了 12.2%，平移误差减少了 34.8%，并且在 KITTI 里程计数据集上消耗的时间相似。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10319768</guid>
      <pubDate>Thu, 16 Nov 2023 13:21:27 GMT</pubDate>
    </item>
    <item>
      <title>一种用于小规模操作的磁流体液体机器人的设计与实现</title>
      <link>http://ieeexplore.ieee.org/document/10301531</link>
      <description><![CDATA[能够变形的微型软体或液体机器人的磁操纵越来越受到关注，并在小规模应用中展现出巨大的潜力，例如药物输送、微创手术和精致物体的操纵。在这项研究中，我们介绍了一种由铁磁流体组成的液体机器人，它在小规模磁操纵应用中显示出了前景。这项工作的目标是实现机器人更灵活的操纵能力。为此，我们利用由五个电磁体组成的冗余磁驱动系统，在平面空间中实现液体机器人的四自由度（4-DOF）控制。基于平面四自由度控制，液体机器人能够执行各种动作并实现多种操纵任务，例如运输物体、分离或组装微型零件以及操作定制工具。此外，我们建议采用自动运输方法来提高操作精度。通过一系列实验验证了该方法的有效性以及机器人完成多样化操作任务的能力。所提出的液体机器人表现出灵活性，并为小规模不受束缚的操纵提供了新颖的解决方案。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10301531</guid>
      <pubDate>Mon, 30 Oct 2023 13:20:37 GMT</pubDate>
    </item>
    </channel>
</rss>