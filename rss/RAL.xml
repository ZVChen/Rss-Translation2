<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
  <channel>
    <title>IEEE 机器人与自动化快报 - 新目录</title>
    <link>http://ieeexplore.ieee.org</link>
    <description>出版物目录提醒# 7083369</description>
    <lastBuildDate>Mon, 26 Aug 2024 04:00:00 GMT</lastBuildDate>
    <item>
      <title>通过模仿和效仿仅状态的观察来学习抓握灵活性</title>
      <link>http://ieeexplore.ieee.org/document/10637688</link>
      <description><![CDATA[当人类从专家那里获得身体技能（例如，使用工具）时，我们倾向于首先通过观察专家来学习。但这往往是不够的。然后我们进行实践，尝试模仿专家并确保我们的行为对环境产生类似的影响。受此观察的启发，我们引入了结合模仿和仿真进行运动细化 (CIMER) - 一个两阶段框架，用于从仅状态观察中学习灵巧的抓握操作技能。CIMER 的第一阶段涉及模仿：在结构化动态系统中同时编码机器人手和物体的复杂相互依赖运动。这会产生一种反应性运动生成策略，该策略提供合理的运动先验，但由于缺乏动作标签而缺乏推理接触效应的能力。第二阶段涉及模拟：通过强化学习运动细化策略，调整机器人手的运动先验，以便重新演绎学习到的物体运动。 CIMER 既与任务无关（没有特定于任务的奖励设计或塑造），又无需干预（没有额外的遥控或标记演示）。对灵巧性进行的详细实验表明：i）仅靠模仿是不够的，但增加模拟可以大大提高性能；ii）CIMER 在样本效率和生成逼真稳定运动的能力方面优于现有方法；iii）CIMER 可以零样本泛化或学习适应 YCB 数据集中的新对象，甚至在大多数情况下优于使用动作标签训练的专家策略。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10637688</guid>
      <pubDate>Fri, 16 Aug 2024 13:16:40 GMT</pubDate>
    </item>
    <item>
      <title>DiPGrasp：高效可微分抓取规划的并行局部搜索</title>
      <link>http://ieeexplore.ieee.org/document/10637664</link>
      <description><![CDATA[抓取规划是机器人操作的一项重要任务。尽管这是一个研究丰富的领域，但尚未报道过可以与不同自由度的机器人夹持器配合使用的独立、快速且可微分的抓取规划器。在这项工作中，我们提出了 DiPGrasp，一个满足所有这些目标的抓取规划器。DiPGrasp 采用力闭合几何表面匹配抓取质量度量。它采用基于梯度的度量优化方案，还考虑了并行采样和碰撞处理。这不仅大大加快了物体表面的抓取搜索过程，而且使其可微分。我们将 DiPGrasp 应用于三个应用，即抓取数据集构建、掩模条件规划和姿势细化。对于数据集生成，作为独立规划器，DiPGrasp 在速度和质量方面与几个经典规划器相比具有明显优势。对于掩模条件规划，它可以立即将 3D 感知模型转变为 3D 抓取检测模型。作为姿势优化器，它可以优化神经网络的粗抓握预测以及神经网络参数。最后，我们使用 Barrett 手和 Schunk SVH 5 指手进行真实世界实验。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10637664</guid>
      <pubDate>Fri, 16 Aug 2024 13:16:40 GMT</pubDate>
    </item>
    <item>
      <title>具有信号时序逻辑的多样化可控扩散策略</title>
      <link>http://ieeexplore.ieee.org/document/10638176</link>
      <description><![CDATA[生成逼真的模拟对于自动驾驶和人机交互等自主系统应用至关重要。然而，如今的驾驶模拟器仍然难以为道路参与者生成可控、多样且符合规则的行为：基于规则的模型无法产生多样化的行为，需要仔细调整，而基于学习的方法模仿来自数据的策略，但并非旨在明确遵循规则。此外，现实世界的数据集本质上是“单一结果”，这使得学习方法难以产生多样化的行为。在这封信中，我们利用信号时序逻辑 (STL) 和扩散模型来学习可控、多样且规则感知的策略。我们首先在现实世界数据上校准 STL，然后使用轨迹优化生成多样化的合成数据，最后在增强数据集上学习修正后的扩散策略。我们在 NuScenes 数据集上进行了测试，与其他基线相比，我们的方法可以实现最多样化的符合规则的轨迹，运行时间是第二佳方法的 1/17 倍。在闭环测试中，我们的方法达到了最高的多样性、规则满足率和最低的碰撞率。我们的方法可以在测试中根据不同的 STL 参数生成不同的特征。人机相遇场景的案例研究表明，我们的方法可以生成多样化且接近 oracle 的轨迹。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10638176</guid>
      <pubDate>Fri, 16 Aug 2024 13:16:40 GMT</pubDate>
    </item>
    <item>
      <title>AMVP：用于自动驾驶新视图合成的自适应多体积基元</title>
      <link>http://ieeexplore.ieee.org/document/10637691</link>
      <description><![CDATA[合成高质量的新视图对于扩展自动驾驶场景的训练数据至关重要。然而，现有的新视图合成技术依赖于具有均匀空间分辨率的单体积辐射场，限制了它们的模型容量并导致合成的自动驾驶视图中出现伪影。这封信介绍了 AMVP，这是一种新颖的神经表示，它使用具有自适应空间分辨率的多个局部基元对自动驾驶场景进行建模。AMVP 通过自适应地将场景细分为多个局部体积来解决缺乏细节丰富区域的表示能力的问题。每个局部体积都根据其几何复杂性分配一个定制的分辨率，由密度先验确定。随后，引入了多体积基元以在局部体积之间共享全局特征表，解决了重复分配导致的 GPU 内存效率低下的问题。此外，这封信还提出了分辨率感知置信度，这是一种抑制频率模糊引起的伪影的机制。该机制根据每个局部体积的空间分辨率和采样点与光学中心的距离自适应地减少高频分量。在基准自动驾驶数据集上的实验结果表明，与现有方法相比，所提出的 AMVP 在使用相似数量的参数的情况下实现了卓越的渲染质量。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10637691</guid>
      <pubDate>Thu, 15 Aug 2024 13:17:26 GMT</pubDate>
    </item>
    <item>
      <title>PRIME：利用行为基元搭建操作任务支架，实现数据高效的模仿学习</title>
      <link>http://ieeexplore.ieee.org/document/10637675</link>
      <description><![CDATA[模仿学习已显示出使机器人获得复杂操作行为的巨大潜力。然而，这些算法在长期任务中样本复杂度高，复合误差会在任务范围内累积。我们提出了 PRIME（基于 PRimitive 的数据效率模仿），这是一个基于行为原语的框架，旨在提高模仿学习的数据效率。PRIME 通过将任务演示分解为原语序列来支持机器人任务，然后通过模仿学习学习高级控制策略对原语进行排序。我们的实验表明，PRIME 在多阶段操作任务中实现了显著的性能提升，与最先进的基线相比，模拟成功率高出 10-34%，在物理硬件上高出 20-48%。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10637675</guid>
      <pubDate>Thu, 15 Aug 2024 13:17:26 GMT</pubDate>
    </item>
    <item>
      <title>SEG-Net：利用软包夹进行深度学习抓取</title>
      <link>http://ieeexplore.ieee.org/document/10637663</link>
      <description><![CDATA[无指软仿生夹持器的出现对基于学习的抓握控制提出了挑战，因为缺乏描述抓握稳健性的模型和用于训练的数据集。在本信中，我们提出了一个全面的流程，包括抓握评估、数据集生成、深度神经网络构建和训练，以及对软包覆夹持器的实验验证，以研究其基于学习的抓握方法。我们方法的核心在于开发一个基于物体和变形夹持器之间的力平衡的抓握质量模型，使我们能够评估抓握的稳健性。使用该模型，我们为我们的数据集合成了大约 10K 个抓握场景和 30K 个抓握姿势，每个场景包含四个像素级热图，分别表示深度信息、抓握深度、​​抓握轴和质量评估。随后，我们构建了 SEG-Net，它将深度图像作为输入，并输出最佳抓握点以及相应的抓握轴和深度。在使用我们的数据集进行训练和微调后，我们通过模拟和实验验证了性能。结果表明，我们提出的方法可以有效地实现软包络夹持器的自动抓取。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10637663</guid>
      <pubDate>Thu, 15 Aug 2024 13:17:26 GMT</pubDate>
    </item>
    <item>
      <title>基于相关平衡的 V2I 路口多车辆轨迹规划</title>
      <link>http://ieeexplore.ieee.org/document/10637682</link>
      <description><![CDATA[在路口生成既能保证车辆安全又能提高交通效率的轨迹仍然是一项艰巨的任务。许多现有的研究都利用纳什均衡 (NE) 进行路口的轨迹规划。然而，基于 NE 的规划很难保证所有车辆都处于相同的平衡状态，从而导致碰撞风险。在本文中，我们提出了一种基于相关平衡 (CE) 的轨迹规划框架，同时启用了车辆与基础设施 (V2I) 通信。CE 的建议允许所有车辆达到安全和一致的平衡，同时保持了基于 NE 的方法的合理性，即没有车辆有偏离的动机。路口管理器 (IM) 首先在低分辨率时空网格图中从每辆车收集轨迹库和对该库的个人偏好概率。然后，IM 通过在 CE 约束下最小化总体碰撞概率来优化每辆车轨迹的推荐概率分布。最后，每辆车在低分辨率地图上采样一条轨迹，构建安全走廊，并通过局部细化优化得到平滑轨迹。我们在十字路口进行了两辆车和四辆车的对比实验，验证了我们的方法在平衡车辆安全性和交通效率方面的有效性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10637682</guid>
      <pubDate>Thu, 15 Aug 2024 13:17:26 GMT</pubDate>
    </item>
    <item>
      <title>结合基于视觉和基于接近度的控制在拥挤空间中定位</title>
      <link>http://ieeexplore.ieee.org/document/10637689</link>
      <description><![CDATA[在本信中，我们考虑在基于传感器的控制框架内使用视觉和近距离传感器在拥挤空间中进行定位。视觉是执行定位任务的主要传感方式，而近距离传感器则通过确保机器人平台不会与工作空间中的物体发生碰撞来对其进行补充。使用 QP 形式以共享方式组合传感器信息，其中使用安全关键控制中的思想来表达不等式约束。所提出的方法已通过各种实际实验得到验证。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10637689</guid>
      <pubDate>Thu, 15 Aug 2024 13:17:26 GMT</pubDate>
    </item>
    <item>
      <title>通过并行时空轨迹搜索实现不确定动态场景中的多步连续决策与规划</title>
      <link>http://ieeexplore.ieee.org/document/10636263</link>
      <description><![CDATA[城市场景中的自动驾驶面临着不确定的动态变化，尤其是在中国，道路上汽车、自行车和行人密集混合，行为随机不确定，过马路风险高。本信提出了一种多步骤连续决策和时空轨迹规划框架，以在这种不确定和高度动态的环境中实现稳定的连续决策和高质量的轨迹规划。首先，构建一个三维时空概率地图来表示不确定的未来驾驶环境。基于地图进行并行时空轨迹搜索，获得满足短期确定性和长期不确定环境约束的多策略可行时空轨迹。然后考虑到决策的连续性和一致性，提出了风险感知的轨迹序列滚动融合，实现高效、探索性的远端规划和稳定安全的近端驾驶轨迹。为了验证所提出的框架，我们收集了来自中国真实城市道路的 Hard Case 数据，其中包含交通流量密集、人车混行道路和复杂路口等具有挑战性的场景，这些场景被广泛认为是成功部署自动驾驶的现实障碍。此外，我们使用 SMARTS 模拟器构建闭环仿真场景以验证框架的有效性。实验结果表明，我们提出的框架在复杂不确定的动态场景中具有出色的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10636263</guid>
      <pubDate>Wed, 14 Aug 2024 13:16:41 GMT</pubDate>
    </item>
    <item>
      <title>使用 LLM 生成在分层框架中混合左侧和右侧驾驶数据</title>
      <link>http://ieeexplore.ieee.org/document/10636276</link>
      <description><![CDATA[数据驱动的轨迹预测对于自动驾驶汽车至关重要，因为这需要高质量的数据。然而，关于从不同国家收集的数据的兼容性的讨论仍然有限，一个典型的问题是不同国家的驾驶规则不同。因此，我们提出了一个分层框架，用于混合左侧和右侧驾驶数据以支持轨迹预测。该框架与所提出的基于 LLM 的样本生成方法相结合，逐步利用镜像、MMD 和样本生成来减少数据集之间的领域差距。通过在两个典型的轨迹数据集上测试混合结果，我们证明了该方法在应用于右侧驾驶场景时提高了在左侧驾驶数据上训练的模型的性能。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10636276</guid>
      <pubDate>Wed, 14 Aug 2024 13:16:41 GMT</pubDate>
    </item>
    <item>
      <title>GOReloc：基于图形的 Visual SLAM 对象级重定位</title>
      <link>http://ieeexplore.ieee.org/document/10634741</link>
      <description><![CDATA[本信介绍了一种用于机器人系统对象级重新定位的新方法。它通过将当前帧中的对象检测与轻量级对象级地图中的 3D 对象稳健地关联来确定相机传感器的姿势。考虑到语义不确定性，为传入的相机帧和预建地图构建对象图。对象表示为图节点，每个节点都基于我们设计的图核采用唯一的语义描述符。我们通过识别每个对象检测的潜在对象关联从目标地图中提取子图，然后使用 RANSAC 启发策略优化这些关联和姿势估计。在各种数据集上进行的实验表明，与基线方法相比，我们的方法实现了更准确的数据关联，并显着提高了重新定位的成功率。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10634741</guid>
      <pubDate>Tue, 13 Aug 2024 13:16:48 GMT</pubDate>
    </item>
    <item>
      <title>SoftSling：一种利用圆形助跑抛掷物体的软机械臂控制策略</title>
      <link>http://ieeexplore.ieee.org/document/10634756</link>
      <description><![CDATA[在本信中，我们介绍了 SoftSling，这是一种软机器人控制策略，旨在通过圆形助跑准确地投掷物体。SoftSling 的灵感来自古代投石手，他们高速旋转装有抛射物的吊索进行战斗和狩猎，通过松开吊索的末端释放物体。我们的研究旨在通过利用软机器人在周期性驱动输入下的具身智能来复制这种行为，从而使它们能够产生自稳定运动。沿圆形路径移动的周期性输入参数由神经网络根据物体的重量和目标位置生成。随后，单独的神经网络模型通过考虑夹持器打开延迟和运动过程中的物体位置来预测释放时间。我们在模块化软机器人 I-Support 上测试了这一策略，将三个不同重量的物体扔进 140 毫米见方的目标盒中。我们对不同物体的成功率从 75% 到 88% 不等，最重的物体的成功率最高。我们的研究有助于将软机器人融入日常生活，使其能够执行复杂和动态的任务。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10634756</guid>
      <pubDate>Tue, 13 Aug 2024 13:16:48 GMT</pubDate>
    </item>
    <item>
      <title>AerialVL：基于空中的视觉定位数据集、基线和算法框架，带有参考图</title>
      <link>http://ieeexplore.ieee.org/document/10632587</link>
      <description><![CDATA[视觉定位在无人机 (UAV) 的自主飞行中起着至关重要的作用，尤其是在全球导航卫星系统 (GNSS) 无法导航的环境中。现有的空中视觉定位方法主要侧重于消除数据库地图和捕获帧之间的图像差异。然而，缺乏用于方法比较的公共数据集和基线，阻碍了空中视觉定位的发展。为了解决这个问题，我们构建了一个大规模数据集 AerialVL，该数据集是使用在不同高度、沿不同路线和在不同时间段飞行的无人机收集的。AerialVL 由 11 个图像序列组成，覆盖约 70 公里的轨迹，并包含与飞行区域相对应的参考卫星图像数据库。利用 AerialVL，我们首次对各种主流的空中视觉定位解决方案进行了全面评估。该评估包括视觉位置识别、视觉对齐定位和视觉里程计，作为比较基线。此外，我们提出了一个通用的空中视觉定位框架，该框架统一了各种方法并将它们集成到一个模块化架构中。我们注意到，在所有飞行轨迹中，与现有方法相比，所提出的框架实现了更高的定位精度和稳健性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10632587</guid>
      <pubDate>Fri, 09 Aug 2024 13:17:26 GMT</pubDate>
    </item>
    <item>
      <title>DrPlanner：使用大型语言模型诊断和修复自动驾驶汽车的运动规划器</title>
      <link>http://ieeexplore.ieee.org/document/10632622</link>
      <description><![CDATA[运动规划器对于自动驾驶汽车在各种场景中的安全运行至关重要。然而，在文献中，没有一种运动规划算法已经达到完美状态，而提高其性能通常既耗时又费力。为了解决上述问题，我们提出了 ${\mathtt {DrPlanner}}$，这是第一个旨在使用大型语言模型自动诊断和修复运动规划器的框架。最初，我们从自然语言和编程语言生成规划器及其规划轨迹的结构化描述。利用大型语言模型的强大功能，我们的框架返回修复后的规划器和详细的诊断描述。此外，我们的框架通过对修复结果的评估不断提供反馈，不断迭代改进。我们的方法已使用基于搜索和采样的自动驾驶汽车运动规划器进行了验证；实验结果强调了提示中演示的必要性，并展示了我们的框架有效识别和纠正难以捉摸的问题的能力。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10632622</guid>
      <pubDate>Fri, 09 Aug 2024 13:17:26 GMT</pubDate>
    </item>
    <item>
      <title>基于语言的动态场景图，用于通过移动操作进行交互式对象搜索</title>
      <link>http://ieeexplore.ieee.org/document/10632580</link>
      <description><![CDATA[为了充分利用移动操作机器人的功能，它们必须能够在大型未探索环境中自主执行长视界任务。虽然大型语言模型 (LLM) 已在任意任务上表现出新兴的推理技能，但现有工作主要集中在已探索环境中，通常专注于导航或操作任务。在这项工作中，我们提出了 MoMa-LLM，这是一种新颖的方法，它将语言模型置于从开放词汇场景图派生的结构化表示中，并随着环境的探索而动态更新。我们将这些表示与以对象为中心的动作空间紧密交织在一起。给定对象检测，所得方法是零样本、开放词汇的，并且可轻松扩展到一系列移动操作和家用机器人任务。我们展示了 MoMa-LLM 在大型现实室内环境中的新型语义交互式搜索任务中的有效性。在模拟和现实世界的大量实验中，我们展示了与传统基线和最先进方法相比显着提高的搜索效率，以及它对更抽象任务的适用性。]]></description>
      <guid>http://ieeexplore.ieee.org/document/10632580</guid>
      <pubDate>Fri, 09 Aug 2024 13:17:26 GMT</pubDate>
    </item>
    </channel>
</rss>